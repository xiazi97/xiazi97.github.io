<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[fork的使用]]></title>
    <url>%2F2019%2F05%2F24%2Ffork%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在牛客做题时遇到了这样一个问题： int main(){fork()||fork();}共创建几个进程：_ 回想之前一直在这里跌倒从来没有爬起来过的经历，痛定思痛，来好好的思考了一下fork()函数的使用 fork函数初识在linux中fork函数是非常重要的函数，它从已经存在的进程中创建一个新进程。新进程为子进程，而原进程为父进程。 123456#include &lt;unistd.h&gt;pid_t fork(void);返回值： 子进程中返回0 父进程中返回子进程id 出错返回-1 进程调用fork，当控制转移到内核中的fork代码后，内核会做这样的操作： 分配新的内存块和内存数据结构给子进程 将父进程部分数据结构内容拷贝到子进程中 添加子进程到系统进程列表中 fork返回，开始调度器调度 当一个进程调用fork后，就会有两个二进制代码相同的进程，而且他们都运行到相同的地方。 注意：fork后父进程还是子进程先执行决定于调度器 fork调用失败的原因 系统中有太多进程 实际用户的进程数超过了限制 fork常规用法 一个父进程希望复制自己，使父子进程同时执行不同的代码段。例如，父进程等待客户端请求，生成子进程来处理请求 一个进程要执行一个不同的程序。例如子进程从fork返回后，调用exec函数 子进程继承父进程使用fork函数得到的子进程从父进程的继承了整个进程的地址空间，包括：进程上下文、进程堆栈、内存信息、打开的文件描述符、信号控制设置、进程优先级、进程组号、当前工作目录、根目录、资源限制、控制终端等。 子进程与父进程的区别在于： 1、父进程设置的锁，子进程不继承（因为如果是排它锁，被继承的话，矛盾了） 2、各自的进程ID和父进程ID不同 3、子进程的未决告警被清除； 4、子进程的未决信号集设置为空集。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彩色的砖块]]></title>
    <url>%2F2019%2F05%2F23%2F%E5%BD%A9%E8%89%B2%E7%9A%84%E7%A0%96%E5%9D%97%2F</url>
    <content type="text"><![CDATA[题目描述小易有一些彩色的砖块。每种颜色由一个大写字母表示。各个颜色砖块看起来都完全一样。现在有一个给定的字符串s,s中每个字符代表小易的某个砖块的颜色。小易想把他所有的砖块排成一行。如果最多存在一对不同颜色的相邻砖块,那么这行砖块就很漂亮的。请你帮助小易计算有多少种方式将他所有砖块排成漂亮的一行。(如果两种方式所对应的砖块颜色序列是相同的,那么认为这两种方式是一样的。)例如: s = “ABAB”,那么小易有六种排列的结果:“AABB”,”ABAB”,”ABBA”,”BAAB”,”BABA”,”BBAA”其中只有”AABB”和”BBAA”满足最多只有一对不同颜色的相邻砖块。 输入描述 12&gt; 输入包括一个字符串s,字符串s的长度length(1 ≤ length ≤ 50),s中的每一个字符都为一个大写字母(A到Z)。&gt; 输出描述 12&gt; 输出一个整数,表示小易可以有多少种方式。&gt; 输入1ABAB 输出12 题目链接：https://www.nowcoder.com/questionTerminal/35086420bf464fedb5c0c1859982ae87?orderByHotValue=1&amp;mutiTagIds=149&amp;page=1&amp;onlyReference=false来源：牛客网 解题思路在审题时，我们看到题目要求——最多存在一对不同颜色的相邻砖块，那么对于所有满足题意的可能就只有两种——1.砖块颜色全部一样； 2.砖块只能有两种不同颜色，所以想到一种简单的方法——模仿哈希表 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; int cur=0; int res = 0; int hash[256] = &#123;0&#125;; string str; cin &gt;&gt; str; //最多存在一对不同颜色的相邻砖块，那么字符串中有超过两种不同的字符就绝对不行 for(int i=0;i&lt;str.size();i++) &#123; if(hash[str[i]] == 0) cur++; hash[str[i]]++; &#125; if(cur == 1) res = cur; if(cur == 2) res = cur; cout &lt;&lt; res &lt;&lt;endl; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程状态]]></title>
    <url>%2F2019%2F05%2F22%2F%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[众所周知，linux是一个多用户，多任务的系统，可以同时运行多个用户的多个程序，这样就必然会产生很多的进。而对于一个进程而言，它可以有如下几个状态 常见进程状态： R：运行状态（running） 并不意味着进程是一定在运行中的，它表明进程要么在运行要么在运行队列里。其实准确的说，这个状态应该叫可执行状态，也就是说，处于此状态的这些进程的task_struct结构被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。 S：可中断睡眠状态（sleeping） 处于这个状态的进程意味着在等待事件完成，这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。在大多数情况下，进程列表中的绝大多数进程都处于此状态 D：不可中断睡眠状态（Disk sleep） 运行的时候，进程会向内核请求一些服务，内核就会将程序挂起进程，并将进程放到parked队列，通常这些进程只会在parked队列中停留很短的时间，在ps(1)列表中是不会出现的。但是如果内核因为某些原因不能提供相应服务的话。例如，进程要读某一个特定的磁盘块，但是磁盘控制器坏了，这时，除非进程完成读磁盘，否则内核无法将该进程移出parked队列，此时该进程标志位就会被置为D。由于进程只有在运行的时候才能接受到signals，所以此时在parked队列上的进程也就无法接收到信号了。解决这个问题的方法要么是给资源给该进程，要么是reboot。通俗一点说，产生D状态的原因出现uninterruptible sleep状态的进程一般是因为在等待IO，例如磁盘IO、网络IO等。在发出的IO请求得不到相应之后，进程一般就会转入uninterruptible sleep状态 T：停止状态（stopped） 向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。） 向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态 X：死亡状态 这个状态只是一个返回状态，因为其维持时间非常短，所以不会在任务列表中看到这个状态 这里还有一种比较特殊的状态——僵尸状态（Zombies） Z：僵尸状态（Zombies）当进程退出并且父进程没有读取到子进程退出的返回代码时就会产生僵尸进程，也就是说，只要子进程退出，父进程还在运行，但父进程没有读取子进程状态，那么此时子进程就会进入Z状态 在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就会剩下task_struct这么个空壳，故称为僵尸。之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。 父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。 在上边我们可以看出，产生僵尸进程有可能会造成内存资源的浪费，内存泄漏，需要一直维护PCB 孤儿进程既然说到了僵尸进程，那么不得不提一提与之对应的孤儿进程——一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[组队竞赛问题]]></title>
    <url>%2F2019%2F05%2F21%2F%E7%BB%84%E9%98%9F%E7%AB%9E%E8%B5%9B%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[题目描述牛牛举办了一次编程比赛,参加比赛的有3*n个选手,每个选手都有一个水平值a_i.现在要将这些选手进行组队,一共组成n个队伍,即每个队伍3人.牛牛发现队伍的水平值等于该队伍队员中第二高水平值。例如:一个队伍三个队员的水平值分别是3,3,3.那么队伍的水平值是3一个队伍三个队员的水平值分别是3,2,3.那么队伍的水平值是3一个队伍三个队员的水平值分别是1,5,2.那么队伍的水平值是2为了让比赛更有看点,牛牛想安排队伍使所有队伍的水平值总和最大。如样例所示:如果牛牛把6个队员划分到两个队伍如果方案为:team1:{1,2,5}, team2:{5,5,8}, 这时候水平值总和为7.而如果方案为:team1:{2,5,8}, team2:{1,5,5}, 这时候水平值总和为10.没有比总和为10更大的方案,所以输出10. 输入描述 输入的第一行为一个正整数n(1 ≤ n ≤ 10^5)第二行包括3*n个整数a_i(1 ≤ a_i ≤ 10^9),表示每个参赛选手的水平值 输出描述 输出一个整数表示所有队伍的水平值总和最大值. 输入25 2 8 5 1 5 输出10 题目链接：https://www.nowcoder.com/questionTerminal/6736cc3ffd1444a4a0057dee89be789b?orderByHotValue=1&amp;page=1&amp;onlyReference=false来源：牛客网 解题思路通过题目描述，优先会想到先将数据进行排序，然后以便选出组队方式。 123456789101112131415例如：共有12 个数 组成4队 排序后的结果为：1 2 3 4 5 6 7 8 9 10 11 12 本题最优组队方式为，选择一个当前剩余最小的一个的和最大的两个为一对依次选择为：1 11 122 9 103 7 84 5 6 在选择时，我们可以看到，满足题意的组队最优选择为，排序好，然后选择倒数第二个、倒数第四个，倒数第六个，依次类推，直到选出n个值，结果为这些值得相加所得，也就是选择 第 3n - 1 3n - 3 3n - 5…个元素累加 123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; int num; long sum = 0; cin &gt;&gt; num; vector&lt;int&gt; arr(num*3); for(int i=0;i&lt;num*3;++i)&#123; cin &gt;&gt; arr[i]; &#125; sort(arr.begin(),arr.end()); for(int i=num;i&lt;=3*num-2;i+=2)&#123; sum += arr[i]; &#125; cout &lt;&lt; sum &lt;&lt; endl; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS查询和应答报文详解]]></title>
    <url>%2F2019%2F05%2F20%2FDNS%E6%9F%A5%E8%AF%A2%E5%92%8C%E5%BA%94%E7%AD%94%E6%8A%A5%E6%96%87%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[DNS查询和应答报文详解DNS是一套分布式的域名服务系统。每个DNS服务器上都存放着大量的机器名和 IP地址的映射，并且是动态更新的。众多网络客户端程序都使用DNS协议来向DNS服务器查询目标主机的IP地址。 DNS查询和应答报文的格式如下： 16位标识字段用于标记一对DNS查询和应答，以此区分一个DNS应答是哪个DNS查询的回应 16位标志字段用于协商具体的通信方式和反馈通信状态。DNS报文头部的16位标志字段的细节如图 QR：查询/应答标志。0表示这是一个查询报文，1表示这是一个应答报文 opcode，定义查询和应答的类型。0表示标准查询，1表示反向查询（由IP地址获得主机域名），2表示请求服务器状态 AA，授权应答标志，仅由应答报文使用。1表示域名服务器是授权服务器 TC，截断标志，仅当DNS报文使用UDP服务时使用。因为UDP数据报有长度限制，所以过长的DNS报文将被截断。1表示DNS报文超过512字节，并被截断 RD，递归查询标志。1表示执行递归查询，即如果目标DNS服务器无法解析某个主机名，则它将向其他DNS服务器继续查询，如此递归，直到获得结果并把该结果返回给客户端。0表示执行迭代查询，即如果目标DNS服务器无法解析某个主机名，则它将自己知道的其他DNS服务器的IP地址返回给客户端，以供客户端参考 RA，允许递归标志。仅由应答报文使用，1表示DNS服务器支持递归查询 zero，这3位未用，必须设置为0 rcode，4位返回码，表示应答的状态。常用值有0（无错误）和3（域名不存在） 接下来的4个字段则分别指出DNS报文的最后4个字段的资源记录数目。对查询报文而言，它一般包含1个查询问题，而应答资源记录数，授权资源记录数和额外资源记录数则为0.应答报文的应答资源记录数则至少为1，而授权资源记录数和额外资源记录数可为0或非0 查询问题的格式： 如图所示，查询名以一定的格式封装了要查询的主机域名。16位查询类型表示如何执行查询操作，常见的类型有如下几种： 类型A，值是1，表示获取目标主机的IP地址 类型CNAME，值是5，表示获得目标主机的别名 类型PTR，值是12，表示反向查询 应答字段，授权字段和额外信息字段都使用资源记录（Resource Record，RR）格式。 资源记录格式： 32位域名是该记录中与资源对应的名字，其格式和查询问题中的查询名字段相同。16位类型和16位类字段的含义也与DNS查询问题的对应字段相同。 32位生存时间表示该查询记录结果可被本地客户端程序缓存多长时间，单位是秒 16位资源数据长度字段和资源数据字段的内容取决于类型字段。对类型A而言。资源数据是32位的IPv4地址，而资源数据长度则为4（以字节为单位）]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vector与list的区别]]></title>
    <url>%2F2019%2F05%2F19%2Fvector%E4%B8%8Elist%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[概念：vector连续存储的容器，动态数组，在堆上分配空间 底层实现：数组 两倍容量增长： vector 增加（插入）新元素时，如果未超过当时的容量，则还有剩余空间，那么直接添加到最后（插入指定位置），然后调整迭代器。 如果没有剩余空间了，则会重新配置原有元素个数的两倍空间，然后将原空间元素通过复制的方式初始化新空间，再向新空间增加元素，最后析构并释放原空间，之前的迭代器会失效。 性能： 访问：O(1) 插入：在最后插入（空间够）：很快 在最后插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。 在中间插入（空间够）：内存拷贝 在中间插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。 删除：在最后删除：很快 在中间删除：内存拷贝 适用场景：经常随机访问，且不经常对非尾节点进行插入删除。 list动态链表，在堆上分配空间，每插入一个元数都会分配空间，每删除一个元素都会释放空间。 底层：双向链表 性能： 访问：随机访问性能很差，只能快速访问头尾节点。 插入：很快，一般是常数开销 删除：很快，一般是常数开销 适用场景：经常插入删除大量数据 区别：1）vector底层实现是数组；list是双向 链表。 2）vector支持随机访问，list不支持。 3）vector是顺序内存，list不是。 4）vector在中间节点进行插入删除会导致内存拷贝，list不会。 5）vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。 6）vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。 应用vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随即访问，而不在乎插入和删除的效率，使用vector。 list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL之list类]]></title>
    <url>%2F2019%2F05%2F16%2FSTL%E4%B9%8Blist%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[list的介绍和使用 list是可以在常数范围内在任意位置进行插入和删除的序列式容器，并且该容器可以前后双向迭代 list的底层是双向链表结构，双向链表中每个元素存储在互不相关的独立节点中，在节点中通过指针指向其前一个元素和后一个元素 list与forward_list非常相似：最主要的不同在于forward_list是单链表，只能朝前迭代，已让其更简单高效 与其他的序列式容器相比（array，vector，deque），list通常在任意位置进行插入，移除元素的执行效率更好 与其他序列式容器相比，list和forward_list最大的缺陷是不支持任意位置的随机访问，比如：要访问list的第6个元素，必须从已知的位置（比如头部或者尾部）迭代到该位置，在这段位置上迭代需要线性的时间开销；list还需要一些额外的空间，以保存每个节点的相关联信息（对于存储类型较小元素的大list来说这可能是一个重要的因素） list的使用list构造 构造函数 接口说明 list() 构造空的list list(size_type n,const value_type&amp; val = value_type()) 构造的list中包含n个值为val的元素 list(const list&amp; x) 拷贝构造函数 list(Inputiterator first,Inputiterator last) 用[first,last]区间中的元素构造list lIst iterator的使用 函数声明 接口说明 begin() 返回第一个元素的迭代器 end() 返回最后一个元素下一个位置的迭代器 rbegin() 返回第一个元素的reverse_iterator，即end位置 rend() 返回最后一个元素下一个位置的reverse_iterator,即begin位置 cbegin()(C++11) 返回第一个元素的const_iterator cend()(C++11) 返回最后一个元素下一个位置的const_iterator crbegin(C++11) 即crend()位置 crend(C++11) 即crbegin()位置 注意： begin与end为正向迭代器，对迭代器执行++操作，迭代器向后移动 rbegin(end)与rend(begin)为反向迭代器，对迭代器执行++操作，迭代器向前移动 cbegin与cend为const的正向迭代器，与cbegin和cend不同的是：该迭代器指向节点中的元素值不能修改 crbegin与crend为const的反向迭代器，与rbegin和rend不同的是：该迭代器指向节点中的元素值不能修改 list capacity 函数生命 接口说明 bool eempty() const 检测list是否为空，是返回true，否则返回false size_t size() const 返回list中有效节点个数 list element access 函数声明 接口说明 reference front() 返回list的第一个节点中值的引用 const_reference front() const 返回list的第一个节点中值的const引用 reference back() 返回list的最后一个节点中值的引用 const_reference back() const 返回list的最后一个节点中值的const引用]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单实现string类以及深浅拷贝问题]]></title>
    <url>%2F2019%2F05%2F15%2F%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0string%E7%B1%BB%E4%BB%A5%E5%8F%8A%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[对象之间可以进行复制操作，包括采用拷贝构造函数的方式用一个对象去构造另一个对象（用一个对象的值初始化一个新的构造的对象），如同指针的复制一样，对象复制也分为浅复制和深复制 对象浅拷贝：两个对象之间进行复制时，若复制完成后，他们还共同使用着某些资源（内存空间），其中一个对象的销毁会影响另一个对象（动态顺序表） 如果没有显式提供拷贝构造函数与赋值运算符重载，编译器会生成一个默认的拷贝构造函数和运算符重载（默认为位的拷贝，将一个对象中的内容原封不动的拷贝到到另一个对象中。如果类中涉及到资源管理，则会使得多个对象在底层共用同一块资源，在销毁对象时，就会导致一份资源释放多次引起程序崩溃） 如果一个类中涉及到资源，该类必须显式提供拷贝构造含糊，赋值运算符重载函数，析构函数 //类似系统生成的默认拷贝构造函数的方式 ​ //值的拷贝方式—–内存的拷贝 ​ //后果：多个对象共用同一份资源，在销毁时同一份资源被释放多次而引起程序的崩溃 12345String(const String&amp; s) :str(s.str) //当前对象的指针和s里的字符串共用同一段空间 &#123;&#125; ​ 对象深拷贝：当两个对象之间进行复制时，若复制完成后，它们不会共享任何资源（内存空间），其中一个对象的销毁不会影响另一个对象 ​ 123456789String(const String&amp; s) :str(new char[strlen(s.str) + 1]) //先分配一段空间 &#123; strcpy(str,s.str); &#125; 此时查看监视，发现s1与s2地址空间并不一样，不会产生内存泄露问题，也可以正常析构销毁 浅拷贝问题的String类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class String&#123;public: String(const char* str = "") //创建空的字符串 &#123; //assert(str); //断言检测是否为空 if(nullptr == str) str = ""; //如果为空那么就当作空字符串 _str = new char[strlen(str) + 1]; strcpy(_str,str); /* if(nullptr == str) &#123; //_str = new char //分配一个字节的空间,但在下边析构时需要与delete匹配起来使用，为了方便，将其设为以下形式 _str = new[1] char; *_str = "\0" &#125; else &#123; _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; */ &#125; //类似系统生成的默认拷贝构造函数的方式 //值的拷贝方式-----内存的拷贝 //后果：多个对象共用同一份资源，在销毁时同一份资源被释放多次而引起程序的崩溃 String(const String&amp; s) :_str(s._str) //当前对象的指针和s里的字符串共用同一段空间 &#123;&#125; //类似系统生成的默认的赋值运算符重载的方式 //问题：1.内存泄露 // 2.与拷贝构造函数类似 String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; _str = s._str; return *this; &#125; &#125; ~String() &#123; if(_str) //判断是否有空间 &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str;&#125;;void TestString()&#123; String s1("hello"); String s2(s1); //用s1拷贝构造s2，因为没有自己给出拷贝构造函数，系统会默认使用类生成的拷贝构造函数进行值的拷贝（浅拷贝）,销毁期间会对一段资源销毁两次产生程序而崩溃 String s2 = s1; //此时会看到s2本身有一个地址空间，但是在赋值时完全将s1中的东西拷贝，使得s2本来的空间找不到了，产生内存泄漏&#125; 使用深拷贝进行处理传统方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class String&#123;public: String(const char* str = "") //创建空的字符串 &#123; //assert(str); //断言检测是否为空 if(nullptr == str) str = ""; //如果为空那么就当作空字符串 _str = new char[strlen(str) + 1]; strcpy(_str,str); /* if(nullptr == str) &#123; //_str = new char //分配一个字节的空间,但在下边析构时需要与delete匹配起来使用，为了方便，将其设为以下形式 _str = new[1] char; *_str = "\0" &#125; else &#123; _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; */ &#125; String(const String&amp; s) :_str(new char[strlen(s._str) + 1]) //先分配一段空间 &#123; strcpy(_str,s._str); &#125; String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; /* 释放旧空间，开辟新空间，再进行字符串拷贝 delete[] _str; //因为先释放了原来空间，如果开辟新空间失败了，那么会造成影响 _str = new char[strlen(s._str) + 1]; strcpy(_str,s._str); */ char* pStr = new char[strlen(s._str) + 1]; strcpy(_str,s._str); delete[] _str; //释放掉旧空间 _str = pStr; &#125; return *this; &#125; ~String() &#123; if(_str) //判断是否有空间 &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str;&#125;;void Test()&#123; String s1("hello"); String s2(s1);&#125;int main()&#123; Test(); return 0;&#125; 现代写法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//代码较简洁class String&#123;public: String(const char* str = "") //创建空的字符串 &#123; if(nullptr == str) str = ""; //如果为空那么就当作空字符串 _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; String(const String&amp; s)//注意！本编译器下此时_str没有进行初始化，放的是一个随机值，所以在释放strTemp时出错，所以需要给一个初始值 :_str(nullptr) &#123; String strTemp(s._str); swap(_str,strTemp._str); &#125; /* String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; String strTemp(s); swap(_str,strTemp._str); &#125; return *this; //当前对象用的是临时对象的空间，出了作用域销毁临时对象，实际是将当前对象的地址空间释放了 &#125; */ String&amp; operator=(String s) &#123; swap(_str,s._str); return *this; &#125; ~String() &#123; if(_str) //判断是否有空间 &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str;&#125;;void Test()&#123; String s1("hello"); String s2(s1); String s3; s3 = s2; //此时实际是临时对象给s3赋值的&#125;int main()&#123; Test(); return 0;&#125; 写时拷贝1.在对象中定义一个成员变量来计数 12345678910111213141516171819202122232425262728293031class String&#123;public: String(const char* str = "") &#123; if(nullptr == str) str = ""; _str = new char[strlen(str) + 1]; strcpy(_str,str); _count = 1; &#125; String(String&amp; s) :_str(s._str) ,_count(++s._count) &#123;&#125; ~String() &#123; if(0 == --_count &amp;&amp; _str) &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str; int _count; //每个对象中均有一份，一个对象修改了其他对象不知道&#125;; 2.使用static修饰成员变量，但是所有对象共享的，而资源有可能会有多分，每调用一次构造就将_count置为1了，不能针对多份资源 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//static也不可以，是类中所有对象共享的class String&#123;public: String(const char* str = "") &#123; if(nullptr == str) str = ""; _str = new char[strlen(str) + 1]; strcpy(_str,str); _count = 1; &#125; String(String&amp; s) :_str(s._str) &#123; ++_count; &#125; ~String() &#123; if(0 == --_count &amp;&amp; _str) &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str; static int _count; //所有对象共享的，但资源有可能会有多分，每调用一次构造就将_count置为1了，不能针对多份资源，如 String s3;&#125;;int String::_count = 0;void Test()&#123; String s1("hello"); String s2(s1); String s3; //此时会出现问题，到这里时_count重新被置为1，导致只能将s3释放而无法释放s1和s2&#125;int main()&#123; Test(); return 0;&#125; 3.写时拷贝（COW copy on write）:浅拷贝+引用计数+在向对象写内容时，是否需要给当前对象独立空间 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class String&#123;public: String(const char* str = "") :_pCount(new int(1)) &#123; if(nullptr == str) str = ""; _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; String(String&amp; s) :_str(s._str) ,_pCount(s._pCount) &#123; ++*(_pCount); &#125; String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; if(0 == --(*_pCount) &amp;&amp; _str) //检测拷贝以后自己的资源需不需要释放 &#123; delete[] _str; _str = nullptr; delete _pCount; _pCount = nullptr; &#125; //与被拷贝的资源共享资源 _str = s._str; _pCount = s._pCount; //新资源计数+1 ++(*_pCount); &#125; return *this; &#125; char&amp; operator[](size_t index) //返回引用是因为有可能返回后作为左值 &#123; if(*_pCount &gt; 1) &#123; String str(_str); this-&gt;Swap(str); &#125; return _str[index]; &#125; const char&amp; operator[](size_t index)const &#123; return _str[index]; &#125; ~String() &#123; if(0 == --(*_pCount) &amp;&amp; _str) &#123; delete[] _str; _str = nullptr; delete _pCount; _pCount = nullptr; &#125; &#125; void Swap(String&amp; s) &#123; swap(_str,s._str); swap(_pCount,s._pCount); &#125;private: char* _str; int* _pCount; &#125;;void Test()&#123; String s1("hello"); String s2(s1); String s3; //s3 = s1; s1 = s3; s1[0] = 'H'; //此时一改变会全改变，s1,s2,s3共用一份资源&#125;int main()&#123; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL之vector类]]></title>
    <url>%2F2019%2F05%2F14%2FSTL%E4%B9%8Bvector%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[vector的介绍 vector是表示可变大小数组的序列容器 就像数组一样，vector也采用的连续存储空间来存储元素。也就是意味着可以采用下标对vector的元素进行访问，和数组一样高效，但是又不像数组一样，它的大小是可以动态改变的，而且它的大小会被容器自动处理 本质讲，vector使用动态分配数组来存储它的元素。当新元素插入时，这个数组需要被重新分配大小来增加存储空间。其做法是，分配一个新的数组，然后将全部元素移到这个数组。就时间而言，这是一个相对代价高的任务，因为每当一个新的元素加入到容器的时候，vector并不会每次都重新分配大小 vector分配空间策略：vector会分配一些额外的空间以适应可能的增长，因为存储空间比实际需要的存储空间更大。不同的库采用不同的策略权衡空间的使用和重新分配。但是无论如何，重新分配都应该是对数增长的间隔大小，以至于在末尾插入一个元素的时候是在常数时间的复杂度完成的 因此，vector占用了更多的存储空间，为了获得管理存储空间的能力，并且以一种有效的方式动态增长 与其他动态序列容器（deques,lists和forward_lists）相比，vector在访问元素的时候更加高效，在末尾添加和删除元素相对高效。对于其他不在末尾的删除和插入操作效率更低，比起lists和forward_lists统一的迭代器和引用更好 vector的使用vector的定义 构造函数声明 接口说明 vector() 无参构造 vector(size_type n,const value_type&amp; val=value_type()) 构造并初始化n个val vector(const vector&amp; x) 拷贝构造 vector(InputIterator first,InputIterator last) 使用迭代器进行初始化构造 vector iterator的使用 iterator的使用 接口说明 begin() 获取第一个数据位置的iterator end() 获取最后一个数据的下一位置的iterator rbegin() 获取最后一个数据位置的reverse_iterator rend() 获取第一个数据前一个位置的reverse_iterator cbegin() 获取第一个数据位置的const_iterator cend() 获取最后一个数据的下一个位置的const_iterator vector空间增长问题 容量空间 接口说明 size() 获取数据个数 capacity() 获取容量大小 empty() 判断是否为空 void resize(size_type n,value_type val=value_type()) 改变vector的size void reserve(size_type n) 改变vector放入capacity capacity的代码在VS和g++下分别运行时会发现，VS下capacity是按1.5倍增长的，g++是按2倍增长的 reserve只负责开辟空间，如果确定知道需要用多少空间，reserve可以缓解vector增容的代价缺陷问题 resize在开空间的同时还会进行初始化，影响size vector的增删改查 vector增删改查 接口说明 void push_back(const value_type&amp; val) 尾插 void pop_back() 尾删 InputIterator find(InputIterator first,InoutIterator last,const T&amp; val) 查找 Iterator insert(iterator position,const value_type&amp; val) 在position之前插入val iterator erase(iterator position) 删除position位置的数据 void swap(vector&amp; x) 交换两个vector的数据空间 reference operator[] (size_type n) 像数组一样通过下标访问]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL之string类]]></title>
    <url>%2F2019%2F05%2F12%2FSTL%E4%B9%8Bstring%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[为什么要用string类在C语言中，字符串是以’\0’结尾的一些字符的集合，为了操作方便，C标准库中提供了一些str系列的库函数，但是这些库函数与字符串是分割开的，不太符合OOP的思想，而且底层空间需要用户自己管理，稍不留神可能还会造成越界访问。 之所以抛弃char*的字符串而选用C++标准程序库中的string类，是因为他和前者比较起来，不必担心内存是否足够、字符串长度等等，而且作为一个泛型类出现，他集成的操作函数足以完成我们大多数情况下(甚至是100%)的需要。我们可以用 = 进行赋值操作，== 进行比较，+ 做串联（是不是很简单?）。我们尽可以把它看成是C++的基本数据类型。 C++中对于strinig的定义为：typedef basic_string string; 也就是说C++中的string类是一个泛型类，由模板而实例化的一个标准类，本质上不是一个标准数据类型。C++中对于strinig的定义为：typedef basic_string string; 也就是说C++中的string类是一个泛型类，由模板而实例化的一个标准类，本质上不是一个标准数据类型。 总结如下： string是表示字符序列的类 标准的string提供了对此类对象的支持，其接口类似于标准字符容器的接口，但添加了专门用于操作单字节字符字符串的设计特性 string类是使用char(即作为它的字符类型，使用它的默认char_traits和分配器类型) string类是basic_string模板类的一个实例，它使用char来实例化basic_string模板类，并用char_traits和allocator作为basic_string的默认参数 string类的常用接口1.string类对象的常见构造 函数名称 功能说明 string() 构造空的string类对象，即空字符串 string(const char* s) 用C-string来构造string类对象 string(size_t n,char c) string类对象中包含n个字符c string(const string&amp; s) 拷贝构造函数 string(const string&amp; s,size_t n) 用s中的前n个字符构造新的string类对象 2.string类对象的容量操作 函数名称 功能说明 size_t size() const 返回字符串有效字符长度 size_t length() const 返回字符串有效字符长度 size_t capacity() const 返回空间总大小 bool empty() const 检测字符串释放为空串，是返回true，否则返回false void clear() 清空有效字符 void resize(size_t n,char c) 将有效字符的个数改成n个，多出的空间用字符c填充 void resize(size_t n) 将有效字符的个数改成n个，多出的空间用0填充 void reserve(size_t res_arg=0) 为字符串预留空间 size()与length()方法的底层实现原理完全相同，引入size()的原因是为了与其他容器的接口保持一致，一般情况下基本都是用size() clear()只是将string中有效字符清空，不改变底层空间大小 resize(size_t n)与resize(size_t n,char c)都是将字符串中有效字符个数改变到n个，不同的是当字符个数增多时，resize(n)用0来填充多出的元素空间，resize(size_t n,char c)用字符c来填充多出的元素空间 注意：resize在改变元素个数时，如果是将元素个数增多，可能会改变底层容量的大小，如果是元素个数减少底层空间大小不改变 reserve(size_t res_arg=0)：为string预留空间，不改变有效元素个数，当reserve的参数小于string的底层空间总大小时，reserver不会改变容量大小 3.string类的访问操作 函数名称 功能说明 char&amp; operator[] (size_t pos) 返回pos位置的字符，const string类对象调用 const char&amp; operator[] (size_t pos) const 返回pos位置的字符，非const string类对象调用 4.string类对象的修改操作 函数名称 功能说明 void push_back(char c) 在字符串后尾插字符c string&amp; append(const char* s) 在字符串后追加一个字符串 string&amp; operator+=(const string&amp; str) 在字符串后追加字符串str string&amp; operator+=(const char* s) 在字符串后追加c个数字符串 string&amp; operator+=(char c) 在字符串后追加字符c string&amp; char* c_str() cosnt 返回C格式字符串 size_t find(char c,size_t pos = 0)const 从字符串pos位置开始往后找字符c，返回该字符在字符串中的位置 size_t rfind(char c,size_t pos=npos) 从字符串pos位置开始往前找字符c，返回该字符在字符串中的位置 string substr(size_t pos=0,size_t n=npos) const 在str中从pos位置开始，截取n个字符，然后将其返回]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式就是保证一个类只有一个实例，并提供一个访问它的全局访问点。首先，需要保证一个类只有一个实例；在类中，要构造一个实例，就必须调用类的构造函数，如此，为了防止在外部调用类的构造函数而构造实例，需要将构造函数的访问权限标记为protected或private；最后，需要提供要给全局访问点，就需要在类中定义一个static函数，返回在类内部唯一构造的实例 饿汉模式程序启动时就创建一个唯一的实例对象 1234567891011121314151617优点：简单缺点：可能导致进程启动慢，且如果有多个单例类对象实例则启动顺序不确定（涉及到资源问题）class singleton&#123; public: static singleton* GetInstance() &#123; return &amp;m_instance; &#125; private: singleton()&#123;&#125; singleton(const singleton&amp;) = delete; singleton&amp; operator=(singleton const&amp;) = delete; static singleton m_instance;&#125;；singleton singleton::m_instance; 懒汉模式第一次使用实例对象时创建对象（延迟加载） 12345678910111213141516171819202122232425262728293031323334353637383940class singleton&#123; public: //在外部调用singleton::GetInstance()时才会初始化对象 static singleton* GetInstance() &#123; if(nullptr == m_pInstance)&#123; m_mtx.lock(); if(nullptr == m_pInstance)&#123; m_pInstance new singleton(); &#125; m_mtx.unlock(); &#125; return m_pInstance; &#125; class CGarbo&#123; public: ~CGarbo()&#123; if(singleton::m_Instance) delete singleton::m_Instance; &#125; &#125;; //定义一个静态成员变量，在程序结束时系统会自动调用它的析构函数从而释放单例对象 static CGarbo Garbo; private: singleton()&#123;&#125; //防拷贝 singleton(const singleton&amp;); singleton operator=(const singleton&amp;); static singleton* m_pInstance; //单例对象指针 static mutex m_mtx; //互斥锁&#125;;singleton* singleton::m_pInstance = nullptr;singleton::CGarbo Garbo;mutex singleton::m_mtx;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类和对象经典面试题（一）]]></title>
    <url>%2F2019%2F05%2F10%2F%E7%B1%BB%E5%92%8C%E5%AF%B9%E8%B1%A1%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[定位new表达式在已分配的原始内存空间中调用构造函数初始化一个对象 格式： new(place_address) type 或者new(place_address) type(initializer_list) 其中place_address必须是一个指针，initializer_list是类型的初始化列表 使用场景： 一般配合内存池使用，因为内存池分配出的内存没有初始化，所以如果是自定义类型的对象，需要使用new的定义表达式进行显式调用构造函数进行初始化 12345void Test()&#123; Test* pt = (Test*)malloc(sizeof(Test)); new(pt) Test; //如果Test类的构造函数有参数时此处则需要传参&#125; 对象创建的方式在C++中类的对象创建分两种，一种是静态的建立如A a，另一种是动态建立，如A* ptr = new A; 区别： 静态建立一个对象，是由编译器为对象在栈空间中分配内存。是通过移动栈顶指针挪出适当的空间然后在这片内存空间上调用构造函数形成一个栈对象（直接调用构造函数） 动态建立类对象，是使用new运算符将对象建立在堆空间中 执行operator new()函数，在堆空间中分配合适空间 调用构造函数构造对象，初始化这片内存空间 由此引出了一个经典的面试题： 创建一个类，只能在堆上创建对象 创建一个类，只能在栈上创建对象 一.只能在堆上创建对象 方法一：容易想到将构造函数私有化 构造函数私有化之后无法在类外部调用构造函数来构造类对象，只能用new运算符来建立对象，但是new运算符实际底层分两步，在调用构造函数时因其已私有化所以无法调用 方法二： 当对象建立在栈上面时是由编译器分配内存空间，调用构造函数来构造栈对象，当对象使用完之后编译器会调用析构函数来释放栈对象所占的空间 假设类的析构函数私有，编译器无法调用析构函数来释放内存。所以在为类对象分配栈空间时会先检查类的析构函数的访问性。**如果类的析构函数是私有的则编译器不会在栈空间上为类对象分配内存** 123456789class A&#123; public: A()&#123;&#125; void destroy()&#123;delete this;&#125; private: ~A()&#123;&#125; &#125;; 提供一个static函数来完成构造 1234567891011121314151617class A&#123; public: static A* create() &#123; return new A(); &#125; void destroy() &#123; delete this; &#125; private: A()&#123;&#125; ~A()&#123;&#125; A(const A&amp;) = delete; //将编译器默认生成的拷贝构造函数删除掉，防止别人 //调用拷贝构造函数生成对象&#125; 二.只能在栈上创建对象只有使用new运算符对象才会建立在堆上。因此只要禁用new运算符就可以实现类对象只能建立在栈上，将operator new()设为私有即可。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构体对齐规则]]></title>
    <url>%2F2019%2F05%2F09%2F%E7%BB%93%E6%9E%84%E4%BD%93%E5%AF%B9%E9%BD%90%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[为什么要进行内存对齐123456789101112131415161718192021#include &lt;iostream&gt;using namespace std;struct A&#123; char a; int b; short c;&#125;;struct B&#123; short c; char a; int b;&#125;;int main()&#123; cout &lt;&lt; sizeof(A) &lt;&lt; endl; cout &lt;&lt; sizeof(B) &lt;&lt; endl; return 0;&#125; 以上结构体变量数量类型相同，但是sizeof计算出来的却不同，计算之后：sizeof(A) is 12,sizeof(B) is 8，此时我们会发现一个问题，为什么两个一样的结构体，但是sizeof大小却不同？ 答案就是内存对齐导致的结果不同 那么编译器为什么要进行内存对齐呢？本来sizeof(int + char + short)应该就是7，结果对齐之后反而更大了，为什么？ 内存对齐规则我们先来看看内存对齐的规则 第一个成员在与结构体偏移量0的地址处 其他成员变量必须是要对齐min(#pragma pack()指定的数,这个数据成员的自身长度)的倍数 在所有的数据成员完成各自对齐之后，结构或联合体本身也要进行对齐，对齐将按照 #pragram pack 指定的数值和结构或者联合体最大数据成员长度中比较小的那个 也就是 min(#pragram pack() , 长度最长的数据成员)； gcc默认对齐数为4，VS下默认对齐数为8 以第一个结构体A为例： char占一个字节，起始偏移量为0；int占4个字节，min(8,4) = 4，所以偏移量为4，所以应该在char后面加上三个字节，不存放任何东西；short 占两个字节，min(8,2)=2，所以偏移量是2的倍数，而short偏移量是8，是2的倍数，所以无需添加任何字节；此时就像这样一样共占了10个字节：0xxx 0000 00 ；那么此时就要考虑一下结构体本身的对齐，min(8,4)=4；所以总体应该是4的倍数，所以还需要添加两个字节在最后面，所以内存存储状态变为了 0xxx 0000 00xx ，一共占据了12个字节 怎样让结构体按照指定的对齐参数进行对齐 pragram pack(4) 设定为4字节对齐 如何知道结构体中某个成员相对于结构体起始位置的偏移量 偏移量 = 成员自己的地址 - 结构体的地址 int num = (int)&amp;s.student - (int)&s; 使用宏offsetof 格式：offsetof(结构体.结构体中的成员变量) offsetof(s.student)]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Makefile基本使用]]></title>
    <url>%2F2019%2F05%2F08%2FMakefile%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[为什么要使用Makefile 会不会使用Makefile从一个侧面说明了是否具备完成大型工程的能力 一个工程中的文件不计其数，按类型，功能，模块分别放在若干个目录中，Makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件选哟重新编译，以及更加复杂的操作 Makefile带来的好处就是——“自动化编译”，一旦写好就只需要一个make命令整个工程就可以完全自动编译，极大的提高了软件开发的效率 make是一个命令工具，是一个解释Makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GUN的make。可见，Makefile已经成为了一种在工程方面的编译方法 make是一条指令，makefile是一个为你教案，两个搭配使用完成项目的自动化构建 Makefile的理解首先我们先来看一个示例代码 C++代码 123456789/*hello.c*/#include &lt;iostream&gt;using namespace std;int main()&#123; cout &lt;&lt; "Learn to use makefile" &lt;&lt; endl; return 0;&#125; Makefile文件 123456789101112hello:hello.o g++ hello.o -o hellohello.o:hello.s g++ -c hello.s -o hello.ohello.s:hello.i g++ -S hello.i -o hello.shello.i:hello.c g++ -E hello.c -o hello.i .PHONY:cleanclean: rm -f hello.i hello.s hello.o hello 依赖关系 上边的文件中，hello依赖hello.o hello.o依赖hello.s hello.s依赖hello.i hello.i依赖hello.c 依赖方法 g++ hello. -option hello. 看到上边的简单例子，很容易发现它主要分成了三个部分，冒号之前的hello（hello.o,hello.s,hello.i），我们称之为目标文件（target），被认为是这条语句所要生成的目标对象；冒号后面的部分hello.o（hello.s,hello.i,hello.c），我们称之为依赖关系表，也就是需要编译target文件所需要的文件，这些文件只要有一个发生了变化就会触发该语句的第三部分，我们称之为命令部分，相信你也可以看得出这是一条编译命令。 请注意！在gcc命令之前必须是一个tab缩进，而不能是空格 语法规定Make file中的命令之前必须要有一个tab缩进，否则make时会报错 原理 在我们输入make命令后，make会在当前目录下找名字叫做“makefile”或者”Makefile“的文件 如果找到，它会找文件中的第一个目标文件（target），在上边的例子中，它会找到”hello”这个文件，并把这个文件当作最终的目标文件 如果hello文件不存在，或是hello所依赖的后面的hello.o文件的文件修改时间要比hello这个文件新，那么它就会去执行后面所定义的命令去生成这个hello文件 如果hello所依赖的hello.o文件不存在，那么make会在当前文件中找hello.o文件的依赖性，如果找到则再根据那一个规则去生成hello.o文件 这就是make的依赖性，make会一层又一层地去找文件的依赖关系，直到最终编译出第一个目标文件 在找寻的过程中，如果出现错误，比如最后被依赖的文件找不到，那么make就会直接退出，并报错，而对于所定义的命令的错误，或者是编译不成功，make则不会理会 Makefile的简便使用学会了上边的基础使用后，我们来看一看下边的代码 123456cc = g++prom = hellosource = hello.c$(prom):$(source) $(cc) $(source) -o $(prom) 如你所见，我们在上述代码中定义了 三个常量cc,prom,source。它们分别告诉了make我们所要使用的编译器，要编译的文件以及源文件。这样我们在需要修改这三者中的任何一项时只需要修改常量的定义即可，而不用去管后面的代码 在这里再介绍几个特殊的宏： %.o:%.c 这是一个模式规则，表示所有的.o目标都依赖于与它同名的.c文件 $^ 引用的是整个关系表 $&lt; 代表的是依赖关系表中的第一项 $@ 代表的是目标文件 Makefile中的伪目标像clean这种，没有被第一个目标文件直接或间接关联，那么它后面所定义的命令将不会被自动执行，不过，我们可以显式用make来执行，即命令——“make clean”，以此来清楚所有的目标文件，以便重新编译。 但是一般这种clean的目标文件，我们会将它设置为伪目标，用.PHONY修饰，伪目标的特性是——它是被执行的]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcc编译过程]]></title>
    <url>%2F2019%2F05%2F07%2Fgcc%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[程序的编译过程预处理（宏替换） 将所有的#define删除，并展开所有的宏定义 处理所有的条件预编译指令，如：#if，#ifdef,#elif,#else,#endif 处理所有的#include预编译指令，将被包含的文件插进到该指令的位置（这个过程是递归的） 删除所有的注释 保留所有的#pragma编译器指令，因为编译器需要他们 实例：gcc -E hello.c -o hello.i 选项-E的作用是让gcc在预处理结束后停止编译过程 选项-o是指目标文件 .i文件为已经预处理过的C原始程序 编译（生成汇编）在这个阶段，gcc首先要检查代码的规范性，是否有语法错误等，以确定代码实际要做的工作，在检查无误后，gcc把代码翻译成汇编语言 实例：gcc -S hello.i -o hello.s 选项-S的作用是只进行编译而不进行汇编，生成汇编代码 汇编（生成机器可识别代码）汇编阶段是指把编译阶段所生成的.s文件转成目标文件 实例：gcc -c hello.s -o hello.o 选项-c可以就看到汇编代码已经转化为.o的二进制目标代码了 链接（生成可执行文件或库文件）在成功编译后就进入了链接阶段 实例：gcc hello.o -o hello 函数库在这里涉及到一个重要的概念：函数库 C程序中，并没有定义”printf”的函数实现，且在预编译中包含的”stdio.h”中也只有该函数的声明，而没有定义函数的实现，那么是在哪里实现”printf”函数的呢？ 答案是：系统把这些函数实现都被做到名为libc.so.6的库文件中去了，在没有特别指定时，gcc会到系统默认的搜索路径”/usr/lib”下进行查找，也就是链接到libc.so.6库函数中去，这样就能实现函数”printf”了。 函数库分为静态库和动态库两种 静态库是指编译链接时，把库文件的代码全部加入到可执行文件中，因此生成的文件比较大，但在运行时也就不需要库文件了。其后缀名一般为.a 动态库与之相反，在编译链接时并没有把库文件的代码加入到可执行文件中，而是在程序执行时由运行时链接文件加载库，这样可以节省系统的开销。动态库一般后缀名为”.so”，如前面所述的libc.so.6就是动态库。gcc在编译时默认使用动态库。完成了链接之后，gcc就可以生成可执行文件，如：gcc hello.o -o hello gcc默认生成的二进制程序，是动态链接的 gcc选项 -E只激活预处理，这个不会另外生成文件 -S编译到汇编语言不进行汇编和链接 -c编译到目标代码 -o文件输出到文件，也就是指定要生成的文件名称 -static对生成的文件采用静态链接 -g生成调试信息。GUN调试器可利用该信息 -share将尽量使用动态库，所以生成文件比较小 -O0，-O1，-O2，-O3 -O3编译器的优化选项的4个级别，-O0表示没有优化，-O1为缺省值，-O3优化级别最高 -w不生成任何警告信息 -Wall生成所以警告信息]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的引用和指针]]></title>
    <url>%2F2019%2F05%2F06%2FC-%E4%B8%AD%E7%9A%84%E5%BC%95%E7%94%A8%E5%92%8C%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[引用的定义：C++是C语言的继承，它可以进行过程化程序设计，又可以进行以抽象数据类型为特点的基于对象的程序设计，还可以进行以继承和多态为特点的面向对象的程序设计。引用就是C++对C语言的重要扩充。引用就是某一变量的一个别名，对引用的操作与对变量直接操作完全一样。 引用的声明方法：类型标识符 &amp; 引用名 = 目标变量名 定义引用的表示方法与定义指针相似，只是用&amp;代替了* 引用的特性： 引用在定义时必须初始化 一个变量可以有多个引用 引用一旦引用一个实体后，就再不能引用其他实体 常量引用：给常量取别名时应加const，例如：const int&amp; b = 10 而int&amp; b = 10是不对的 指针的定义：指针利用地址，它的值直接指向存在电脑存储器中另一个地方的值。由于通过地址能找到所需的变量单元，可以说，地址指向该变量单元。因此，将地址形象化的称为“指针”。意思是通过它能找到以它为地址的内存单元。 指针的特性： 指针变量的值并非它所指向的内存位置所存储的值。我们必须使用间接访问来获取它所指向位置存储的值——即解引用 * 声明一个指针变量并不会自动分配任何内存。在对指针执行间接访问之前，指针必须进行初始化：或者使它指向一块现有的内存，或者给它分配动态内存。对未初始化的指针变量执行间接访问操作是非法的，而且这种错误常常难以检测到——不能对未初始化的指针变量解引用 NULL指针就是不指向任何东西的指针。它可以赋值给一个指针，用于表示该指针并不指向任何值。对NULL指针执行间接访问操作的后果因编译器而异，两个常见的后果分别是返回内存位置零的值以及终止程序 引用与指针的区别： 引用在定义时必须初始化，指针没有要求 引用在初始化时引用一个实体后不能再引用其他实体，而指针可以在任何时候指向任何一个同类型实体 没有NULL引用，但有NULL指针 在sizeof中含义不同：引用的结果为引用类型的大小，指针始终是地址空间所占字节的个数（32位平台下为4个字节） 引用++是引用的实体增加1，指针++是指针向后偏移一个指针类型的大小 有多级的指针没有多级的引用 访问实体方式不同（指针需要显式解引用，引用则是编译器进行处理） 如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中四种cast转换]]></title>
    <url>%2F2019%2F05%2F05%2FC-%E4%B8%AD%E5%9B%9B%E7%A7%8Dcast%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast const_cast用于将const变量转为非const static_cast用于各种隐式转换，比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知； dynamic_cast用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。 向上转换：指的是子类向基类的转换 向下转换：指的是基类向子类的转换 它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。 reinterpret_cast几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用； 为什么不使用C的强制转换？C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static关键字的作用]]></title>
    <url>%2F2019%2F05%2F04%2Fstatic%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[全局静态变量在全局变量前加上关键字static，全局变量就定义成一个全局静态变量. 静态存储区，在整个程序运行期间一直存在。 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）； 作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。 局部静态变量在局部变量之前加上关键字static，局部变量就成为一个局部静态变量。 内存中的位置：静态存储区 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）； 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变； 静态函数在函数返回类型前加static，函数就定义为静态函数。函数的定义和声明在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。 函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突； warning：不要再头文件中声明static的全局函数，不要在cpp内声明非static的全局函数，如果你要在多个cpp中复用该函数，就把它的声明提到头文件里去，否则cpp内部声明需加上static修饰； 类的静态成员在类中，静态成员可以实现多个对象之间的数据共享，并且使用静态数据成员还不会破坏隐藏的原则，即保证了安全性。因此，静态成员是类的所有对象中共享的成员，而不是某个对象的成员。对多个对象来说，静态数据成员只存储一处，供所有对象共用 类的静态函数静态成员函数和静态数据成员一样，它们都属于类的静态成员，它们都不是对象成员。因此，对静态成员的引用不需要用对象名。 在静态成员函数的实现中不能直接引用类中说明的非静态成员，可以引用类中说明的静态成员（这点非常重要）。如果静态成员函数中要引用非静态成员时，可通过对象来引用。从中可看出，调用静态成员函数使用如下格式：&lt;类名&gt;::&lt;静态成员函数名&gt;(&lt;参数表&gt;);]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数重载，重定义，重写]]></title>
    <url>%2F2019%2F05%2F03%2F%E5%87%BD%E6%95%B0%E9%87%8D%E8%BD%BD%EF%BC%8C%E9%87%8D%E5%AE%9A%E4%B9%89%EF%BC%8C%E9%87%8D%E5%86%99%2F</url>
    <content type="text"><![CDATA[函数重载在一个类中声明多个名称相同但是参数列表不同的函数，这些的参数可能个数或顺序，类型不同，但是不能靠返回类型来判断，也就是说，在同一作用域中声明了名称相同，参数列表不同，返回值可以相同可以不同的函数。 特征： 相同的范围（在同一个作用域中） 函数名字相同 参数不同 virtual 关键字可有可无（注：函数重载与有无virtual修饰无关） 返回值可以不同； 函数重写（覆盖）子类继承了父类，父类中的函数是虚函数，在子类中重新定义了这个虚函数 特征： 不在同一个作用域（分别位于派生类与基类） 函数名字相同 参数相同 基类函数必须有 virtual 关键字，不能有 static 返回值相同，否则报错 重写函数的访问修饰符可以不同； 函数重定义子类重新定义父类中有相同名称的非虚函数，参数列表可以相同可以不同，会覆盖其父类的方法，未体现多态。 特征： 不在同一个作用域（分别位于派生类与基类） 函数名字相同 返回值可以不同 参数不同,此时，不论有无 virtual 关键字，基类的函数将被隐藏（注意别与重载以及覆盖混淆） 参数相同，但是基类函数没有 virtual关键字。此时，基类的函数被隐藏（注意别与覆盖混淆） 重载与覆盖的区别： 覆盖是子类和父类之间的关系，是垂直关系；重载是同一个类中不同方法之间的关系，是水平关系 覆盖要求参数列表相同，重载要求参数列表不同；覆盖要求返回类型相同，重载则不要求 覆盖关系中，调用方法体是根据对象的类型（基类类型还是派生类类型）来决定的，重载关系是根据调用时的实参表与形参表来选择方法体的。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树]]></title>
    <url>%2F2019%2F04%2F28%2F%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[红黑树，是一种二叉搜索树，但在每个结点增加一个存储位表示结点的颜色，可以是Red和Black，通过对任何一条从根到叶子结点着色方式的限制，红黑树确保没有一条路径会比其他路径长出两倍，因而是接近平衡的。 红黑树的性质 每个结点不是红色就是黑色 根节点是黑色的 如果一个节点是红色的，则它的两个孩子结点是黑色的 对于每个结点，从该结点到其所有后代叶结点的简单路径上，均包含相同数目的黑色结点 每个叶子结点都是黑色的(此处的叶子结点指的是空结点) 红黑树结点的定义12345678910111213141516171819// 节点的颜色enum Color&#123;RED, BLACK&#125;;// 红黑树节点的定义template&lt;class ValueType&gt;struct RBTreeNode &#123; RBTreeNode(const ValueType&amp; data = ValueType()，Color color = RED) : _pLeft(nullptr) , _pRight(nullptr) , _pParent(nullptr) , _data(data) , _color(color) &#123;&#125; RBTreeNode&lt;ValueType&gt;* _pLeft; // 节点的左孩子 RBTreeNode&lt;ValueType&gt;* _pRight; // 节点的右孩子 RBTreeNode&lt;ValueType&gt;* _pParent; // 节点的双亲(红黑树需要旋转，为了实现简单给出该字段) ValueType _data; // 节点的值域 Color _color; // 节点的颜色 &#125;; 在定义节点时将节点的默认颜色给成红色的，是因为插入之前所有根至外部节点的路径上黑色节点数目都相同，所以如果插入的节点是黑色肯定错误（黑色节点数目不相同），而相对的插入红节点可能会也可能不会违反“没有连续两个节点是红色”这一条件，所以插入的节点为红色，如果违反条件再调整 红黑树结构为了能够简单的实现后续的关联式容器，所以我们在红黑树中增加一个头节点，因为根节点必须是黑色的，为了与根节点进行区分，将头结点给成红色，并且让头结点的 pParent 域指向红黑树的根节点，pLeft域指向红黑树中最小的节点，_pRight域指向红黑树中最大的节点 123456789101112131415161718192021template&lt;class ValueType&gt;class RBTree&#123; typedef RBTreeNode&lt;ValueType&gt; Node; typedef Node* PNode;public: RBTree() : _pHead(new Node) &#123; _pHead-&gt;_pParent = nullptr; _pHead-&gt;_pLeft = _pHead; _pHead-&gt;_pRight = _pHead; &#125; PNode&amp; GetRoot() &#123; return _pHead-&gt;_pParent; &#125;private: PNode _pHead;&#125;; 红黑树的插入 按照二叉搜索的树规则插入新节点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182template&lt;class ValueType&gt;class RBTree&#123; //…… bool Insert(const ValueType&amp; data) &#123; PNode&amp; pRoot = GetRoot(); // 1. 按照二叉搜索的树方式插入新节点 if (nullptr == pRoot) &#123; pRoot = new Node(data, BLACK); // 根的双亲为头节点 pRoot-&gt;_pParent = _pHead; &#125; else &#123; // 按照二叉搜索树的特性，找节点在红黑树中的插入位置 PNode pCur = pRoot; PNode pParent = nullptr; while (pCur) &#123; pParent = pCur; if (data &lt; pCur-&gt;_data) pCur = pCur-&gt;_pLeft; else if (data &gt; pCur-&gt;_data) pCur = pCur-&gt;_pRight; else return false; &#125; // 插入新节点 pCur = new Node(data); if (data &lt; pParent-&gt;_data) pParent-&gt;_pLeft = pCur; else pParent-&gt;_pRight = pCur; // 更新新节点的双亲 pCur-&gt;_pParent = pParent; // 2. 检测新节点插入后，红黑树的性质是否造到破坏， // 若满足直接退出，否则对红黑树进行旋转着色处理 //... &#125; // 根节点的颜色可能被修改，将其改回黑色 pRoot-&gt;_color = BLACK; _pHead-&gt;_pLeft = LeftMost(); _pHead-&gt;_pRight = RightMost(); return true; &#125;private: PNode&amp; GetRoot() &#123; return _pHead-&gt;_pParent; &#125; // 获取红黑树中最小节点，即最左侧节点 PNode LeftMost() &#123; PNode pCur = GetRoot(); if (nullptr == pCur) return _pHead; // 获取红黑树中最左侧节点 while (pCur-&gt;_pLeft) &#123; pCur = pCur-&gt;_pLeft; &#125; return pCur; &#125; // 获取红黑树中最大节点，即最右侧节点 PNode RightMost() &#123; PNode pCur = GetRoot(); if (nullptr == pCur) return _pHead; // 获取红黑树中最右侧节点 while (pCur-&gt;_pRight) &#123; pCur = pCur-&gt;_pRight; &#125; return pCur; &#125;private: PNode _pHead;&#125;; 检测新节点插入后，红黑树的性质是否造到破坏因为新节点的默认颜色是红色，因此：如果其双亲节点的颜色是黑色，没有违反红黑树任何性质，则不需要调整；但当新插入节点的双亲节点颜色为红色时，就违反了性质三不能有连在一起的红色节点，此时需要对红黑树分情况来讨论 约定:cur为当前节点，p为父节点，g为祖父节点，u为叔叔节点 情况一: cur为红，p为红，g为黑，u存在且为红 cur和p均为红，违反了性质三，此处能否将p直接改为黑？解决方式：将p,u改为黑，g改为红，然后把g当成cur，继续向上调整 情况二: cur为红，p为红，g为黑，u不存在/u为黑 p为g的左孩子，cur为p的左孩子，则进行右单旋转；相反，p为g的右孩子，cur为p的右孩子，则进行左单旋转p、g变色–p变黑，g变红 情况三: cur为红，p为红，g为黑，u不存在/u为黑 p为g的左孩子，cur为p的右孩子，则针对p做左单旋转；相反，p为g的右孩子，cur为p的左孩子，则针对p做右单旋转则转换成了情况2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849bool Insert(const ValueType&amp; data)&#123; // 1. 按照二叉搜索树的性质将新节点插入 // ...... // 2. 检测新节点插入后，红黑树的性质是否造到破坏 // 更新结点颜色-- // 违反性质3：不能有连在一起的红色结点 while(pParent &amp;&amp; RED == pParent-&gt;_color) &#123; // 注意：grandFather一定存在 // 因为pParent存在，且不是黑色节点，则pParent一定不是根，则其一定有双亲 PNode grandFather = pParent-&gt;_pParent; // 先讨论左侧情况 if(pParent == grandFather-&gt;_pLeft) &#123; PNode unclue = grandFather-&gt;_pRight; // 情况三：叔叔节点存在，且为红 if(unclue &amp;&amp; RED == unclue-&gt;_color) &#123; pParent-&gt;_color = BLACK; unclue-&gt;_color = BLACK; grandFather-&gt;_color = RED; pCur = grandFather; pParent = pCur-&gt;_pParent; &#125; else &#123; // 情况五：叔叔节点不存在，或者叔叔节点存在且为黑 if(pCur == pParent-&gt;_pRight) &#123; _RotateLeft(pParent); swap(pParent, pCur); &#125; // 情况五最后转化成情况四 grandFather-&gt;_color = RED; pParent-&gt;_color = BLACK; _RotateRight(grandFather); &#125; &#125; else &#123; // 右侧请学生们自己动手完成 &#125; &#125; // 旋转完成后，将根节点的颜色改成黑叔 _pRoot-&gt;_color = BLACK; return true;&#125; 红黑树的验证红黑树的检测分为两步： 检测其是否满足二叉搜索树(中序遍历是否为有序序列) 检测其是否满足红黑树的性质 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152bool IsValidRBTree()&#123; PNode pRoot = GetRoot(); // 空树也是红黑树 if (nullptr == pRoot) return true; // 检测根节点是否满足情况 if (BLACK != pRoot-&gt;_color) &#123; cout &lt;&lt; "违反红黑树性质二：根节点必须为黑色" &lt;&lt; endl; return false; &#125; // 获取任意一条路径中黑色节点的个数 size_t blackCount = 0; PNode pCur = pRoot; while (pCur) &#123; if (BLACK == pCur-&gt;_color) blackCount++; pCur = pCur-&gt;_pLeft; &#125; // 检测是否满足红黑树的性质，k用来记录路径中黑色节点的个数 size_t k = 0; return _IsValidRBTree(pRoot, k, blackCount); &#125;bool _IsValidRBTree(PNode pRoot, size_t k, const size_t blackCount)&#123; if (nullptr == pRoot) return true; // 统计黑色节点的个数 if (BLACK == pRoot-&gt;_color) k++; // 检测当前节点与其双亲是否都为红色 PNode pParent = pRoot-&gt;_pParent; if (pParent &amp;&amp; RED == pParent-&gt;_color &amp;&amp; RED == pRoot-&gt;_color) &#123; cout &lt;&lt; "违反性质三：没有连在一起的红色节点" &lt;&lt; endl; return false; &#125; // 如果pRoot是因子节点，检测当前路径中黑色节点的个数是否有问题 if (nullptr == pRoot-&gt;_pLeft &amp;&amp; nullptr == pRoot-&gt;_pRight) &#123; if (k != blackCount) &#123; cout &lt;&lt; "违反性质四：每条路径中黑色节点的个数必须相同" &lt;&lt; endl; return false; &#125; &#125; return _IsValidRBTree(pRoot-&gt;_pLeft, k, blackCount) &amp;&amp; _IsValidRBTree(pRoot-&gt;_pRight, k, blackCount);&#125; 红黑树与AVL树的比较红黑树和AVL树都是高效的平衡二叉树，增删改查的时间复杂度都是O( )，红黑树不追求绝对平衡，其只需保证最长路径不超过最短路径的2倍，相对而言，降低了插入和旋转的次数，所以在经常进行增删的结构中性能比AVL树更优，而且红黑树实现比较简单，所以实际运用中红黑树更多。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AVL树]]></title>
    <url>%2F2019%2F04%2F23%2FAVL%E6%A0%91%2F</url>
    <content type="text"><![CDATA[上一篇所写的二叉搜索树虽可以缩短查找的效率，但如果数据有序或接近有序二叉搜索树将退化为单支树，查找元素相当于在顺序表中搜索元素，效率低下。因此，两位俄罗斯的数学家G.M.Adelson-Velskii和E.M.Landis在1962年发明了一种解决上述问题的方法：当向二叉搜索树中插入新结点后，如果能保证每个结点的左右子树高度之差的绝对值不超过1(需要对树中的结点进行调整)，即可降低树的高度，从而减少平均搜索长度。 也就是说，AVL树本质上是一颗二叉查找树。 对于一棵AVL树，要么是一棵空树，要么需要具有如下性质： 它的左右子树都是AVL树 左右子树的高度之差（平衡因子）的绝对值不超过1 AVL节点的定义12345678910111213141516template&lt;class T&gt;struct AVLTreeNode&#123; AVLTreeNode(const T&amp; data) :_pLeft(nullptr) ,_pRight(nullptr) ,_pParent(nullptr) ,_data(data) ,_bf(0) &#123;&#125; AVLTreeNode&lt;T&gt;* _pLeft; AVLTreeNode&lt;T&gt;* _pRight; AVLTreeNode&lt;T&gt;* _pParent; T _data; int _bf; //平衡因子&#125;; AVL节点的插入AVL树就是在二叉搜索树的基础上引入了平衡因子，因此AVL树也可以看成是二叉搜索树。那么AVL树的插入过程可以分为两步： 按照二叉搜索树的方式插入新节点 更新平衡因子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657bool Insert(const T&amp; data)&#123; // 1. 先按照二叉搜索树的规则将节点插入到AVL树中 // ... // 2. 新节点插入后，AVL树的平衡性可能会遭到破坏，此时就需要更新平衡因子，并检测是否破坏了AVL树 // 的平衡性 /* pCur插入后，pParent的平衡因子一定需要调整，在插入之前，pParent 的平衡因子分为三种情况：-1，0, 1, 分以下两种情况： 1. 如果pCur插入到pParent的左侧，只需给pParent的平衡因子-1即可 2. 如果pCur插入到pParent的右侧，只需给pParent的平衡因子+1即可 此时：pParent的平衡因子可能有三种情况：0，正负1， 正负2 1. 如果pParent的平衡因子为0，说明插入之前pParent的平衡因子为正负1，插入后被调整成0，此时满足 AVL树的性质，插入成功 2. 如果pParent的平衡因子为正负1，说明插入前pParent的平衡因子一定为0，插入后被更新成正负1，此 时以pParent为根的树的高度增加，需要继续向上更新 3. 如果pParent的平衡因子为正负2，则pParent的平衡因子违反平衡树的性质，需要对其进行旋转处理 */ while (pParent) &#123; // 更新双亲的平衡因子 if (pCur == pParent-&gt;_pLeft) pParent-&gt;_bf--; else pParent-&gt;_bf++; // 更新后检测双亲的平衡因子 if (0 == pParent-&gt;_bf) break; else if (1 == pParent-&gt;_bf || -1 == pParent-&gt;_bf) &#123; // 插入前双亲的平衡因子是0，插入后双亲的平衡因为为1 或者 -1 ，说明以双亲为根的二叉树 // 的高度增加了一层，因此需要继续向上调整 pCur = pParent; pParent = pCur-&gt;_pParent; &#125; else &#123; // 双亲的平衡因子为正负2，违反了AVL树的平衡性，需要对以pParent // 为根的树进行旋转处理 if(2 == pParent-&gt;_bf) &#123; // ... &#125; else &#123; // ... &#125; &#125; &#125; return true;&#125; AVL树的旋转如果在一棵原本是平衡的AVL树中插入一个新节点，可能会造成不平衡，此时必须调整树的结构，使之平衡化。根据节点插入位置的不同，AVL树的旋转分为四种： 新节点插入较高左子树的左侧—左左：右单旋 1234567891011121314151617181920212223242526void RotateR(PNode pParent) &#123; PNode pSubL = pParent-&gt;_pLeft; PNode pSubLR = pSubL-&gt;_pRight; pParent-&gt;_pLeft = pSubLR; if(pSubLR) pSubLR-&gt;_pParent = pParent; pSubL-&gt;_pRight = pParent; PNode pPParent = pParent-&gt;_pParent; pParent-&gt;_pParent = pSubL; pSubL-&gt;_pParent = pPParent; if(nullptr == pPParent) _pRoot = pSubL; else &#123; if(pParent == pPParent-&gt;_pLeft) pPParent-&gt;_pLeft = pSubL; else pPParent-&gt;_pRight = pSubL; &#125; pParent-&gt;_bf = pSubL-&gt;_bf = 0; &#125; 新节点插入较高右子树的右侧—右右：左单旋 1234567891011121314151617181920212223242526void RotateL(PNode pParent) &#123; PNode pSubR = pParent-&gt;_pRight; PNode pSubRL = pSubR-&gt;_pLeft; pParent-&gt;_pRight = pSubRL; if(pSubRL) pSubRL-&gt;_pParent = pParent; pSubR-&gt;_pLeft = pParent; PNode pPParent = pParent-&gt;_pParent; pParent-&gt;_pParent = pSubR; pSubR-&gt;_pParent = pPParent; if(nullptr == pPParent) _pRoot = pSubR; else &#123; if(pParent == pPParent-&gt;_pLeft) pPParent-&gt;_pLeft = pSubR; else pPParent-&gt;_pRight = pSubR; &#125; pParent-&gt;_bf = pSubR-&gt;_bf = 0; &#125; 新节点插入较高左子树的右侧—左右：先左单旋再右单旋 12345678910111213141516171819void RotateLR(PNode pParent) &#123; PNode pSubL = pParent-&gt;_pLeft; PNode pSubLR = pSubL-&gt;_pRight; int bf = pSubLR-&gt;_bf; RotateL(pParent-&gt;_pLeft); RotateR(pParent); //更新平衡因子 if(1 == bf) &#123; pSubL-&gt;_bf = -1; &#125; else if(-1 == bf) &#123; pParent-&gt;_bf = 1; &#125; &#125; 新节点插入较高右子树的左侧—右左：先右单旋再左单旋 1234567891011121314void RotateRL(PNode pParent) &#123; PNode pSubR = pParent-&gt;_pRight; PNode pSubRL = pSubR-&gt;_pLeft; int bf = pSubRL-&gt;_bf; RotateR(pParent-&gt;_pRight); RotateL(pParent); if(1 == bf) pParent-&gt;_bf = -1; else if(-1 == bf) pSubR-&gt;_bf = 1; &#125; 总结：假如以pParent为根的子树不平衡，即pParent的平衡因子为2或者-2，分以下情况考虑 pParent的平衡因子为2，说明pParent的右子树高，设pParent的右子树的根为pSubR当pSubR的平衡因子为1时，执行左单旋当pSubR的平衡因子为-1时，执行右左双旋 pParent的平衡因子为-2，说明pParent的左子树高，设pParent的左子树的根为pSubL当pSubL的平衡因子为-1是，执行右单旋当pSubL的平衡因子为1时，执行左右双旋旋转完成后，原pParent为根的子树个高度降低，已经平衡，不需要再向上更新。 AVL树的验证AVL树是在二叉搜索树的基础上加入了平衡性的限制，因此要验证AVL树，可以分两步： 验证其为二叉搜索树如果中序遍历可得到一个有序的序列，就说明为二叉搜索树 验证其为平衡树每个节点子树高度差的绝对值不超过1(注意节点中如果没有平衡因子)节点的平衡因子是否计算正确 123456789101112131415161718192021int _Height(PNode pRoot) &#123; if(nullptr == pRoot) return 0; int leftHeight = _Height(pRoot-&gt;_pLeft); int rightHeight = _Height(pRoot-&gt;_pRight); return leftHeight&gt;rightHeight ? leftHeight+1 : rightHeight+1; &#125;bool _IsAVLTree(PNode pRoot) &#123; if(nullptr == pRoot) return true; int leftHeight = _Height(pRoot-&gt;_pLeft); int rightHeight = _Height(pRoot-&gt;_pRight); if(abs(pRoot-&gt;_bf)&gt;1 || rightHeight - leftHeight != pRoot-&gt;_bf) return false; return _IsAVLTree(pRoot-&gt;_pLeft) &amp;&amp; _IsAVLTree(pRoot-&gt;_pRight); &#125; AVL树的性能AVL树是一棵绝对平衡的二叉搜索树，其要求每个节点的左右子树高度差的绝对值都不超过1，这样可以保证查询时高效的时间复杂度，即 。但是如果要对AVL树做一些结构修改的操作，性能非常低下，比如：插入时要维护其绝对平衡，旋转的次数比较多，更差的是在删除时，有可能一直要让旋转持续到根的位置。因此：如果需要一种查询高效且有序的数据结构，而且数据的个数为静态的(即不会改变)，可以考虑AVL树，但一个结构经常修改，就不太适合]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉搜索树]]></title>
    <url>%2F2019%2F04%2F20%2F%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%2F</url>
    <content type="text"><![CDATA[顾名思义，二叉搜索树是以一棵二叉树来组织的，这样的一棵树可以用一个链表结构来表示，每个节点除了data还有left、right、parent，分别指向节点的左孩子，右孩子和父节点。如果对应的节点不存在则指向NIL节点。（因为最简单的二叉搜索树中的NIL节点里并没有有用信息，所以在实现时简单的指向NULL也是可以的，本文中就会这么实现） 二叉搜索树的性质 若它的左子树不为空，则左子树上所有节点的值都小于根节点的值 若它的右子树不为空，则右子树上所有节点的值都大于根节点的值 它的左右子树也分别是二叉搜索树 二叉树的常用操作二叉树的查找 若根节点不为空，则： 如果要查找的值与根节点的值相同，即要查找data==根节点data，则返回true; 如果要查找的值比根节点的值小，即要查找data&lt;根节点data，则在其左子树进行查找 如果要查找的值比根节点的值大，即要查找data&gt;根节点data，则在其右子树进行查找 二叉树的插入 树为空，则直接进行插入 树不空，按二叉搜索树性质查找插入位置，插入新节点 1.按照二叉树的性质，先找到插入节点的位置 ​ root-&gt;5,5&lt;10,root = root-&gt;right,parent = root; ​ root-&gt;7,7&lt;10,root = root-&gt;right,parent = root; ​ root-&gt;8,8&lt;10,root = root-&gt;right,parent = root; ​ root-&gt;9,9&lt;10,root = root-&gt;right,parnet = root; 2.插入新节点 二叉树的删除 首先查找元素是否在二叉搜索树中，如果不存在，则返回, 否则要删除的结点可能分下面四种情况： 1234a. 要删除的结点无孩子结点b. 要删除的结点只有左孩子结点c. 要删除的结点只有右孩子结点d. 要删除的结点有左、右孩子结点 看起来有待删除节点有4中情况，实际情况a可以与情况b或者c合并起来，因此真正的删除过程如下： 情况b：删除该结点且使被删除节点的双亲结点指向被删除节点的左孩子结点 情况c：删除该结点且使被删除节点的双亲结点指向被删除结点的右孩子结点 情况d：在它的右子树中寻找中序下的第一个结点(关键码最小)，用它的值填补到被删除节点中， 再来处理该结点的删除操作 二叉树的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210#pragma once#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;template&lt;class T&gt;struct BSTNode&#123; T _data; BSTNode&lt;T&gt;* _pLeft; BSTNode&lt;T&gt;* _pRight; BSTNode(const T&amp; data) :_data(data) ,_pLeft(nullptr) ,_pRight(nullptr) &#123;&#125;&#125;;template&lt;class T&gt;class BSTree&#123; typedef BSTNode&lt;T&gt; Node; typedef Node* PNode;private: PNode _pRoot;public: public: BSTree() : _pRoot(nullptr) &#123;&#125; ~BSTree() &#123; _Destroy(_pRoot); &#125; bool Insert(const T&amp; data) &#123; if(nullptr == _pRoot)&#123; _pRoot = new Node(data); return true; &#125; //非空则先找到应插入的位置 PNode pParent = nullptr; PNode pCur = _pRoot; //记录一下pCur的双亲位置 while(pCur)&#123; pParent = pCur; if(data &lt; pCur-&gt;_data) pCur = pCur-&gt;_pLeft; else if(data &gt; pCur-&gt;_data) pCur = pCur-&gt;_pRight; else return true; &#125; //插入节点 pCur = new Node(data); if(data &lt; pParent-&gt;_data) pParent-&gt;_pLeft = pCur; else pParent-&gt;_pRight = pCur; return true; &#125; bool Erase(const T&amp; data) &#123; //找待删除节点的位置 PNode pCur = _pRoot; PNode pParent = nullptr; while(pCur) &#123; //pParent = pCur; 不能放在这里，这里时能找到待删除节点，但是不能记录下双亲的位置 if(data == pCur-&gt;_data) break; else if(data &lt; pCur-&gt;_data) &#123; pParent = pCur; pCur = pCur-&gt;_pLeft; &#125; else &#123; pParent = pCur; pCur = pCur-&gt;_pRight; &#125; &#125; if(nullptr == pCur) //没有找到 return false; //分情况删除节点： //1.叶子节点||只有右孩子，则左孩子为空—— pParnet-&gt;right = pCur-&gt;right;（为双亲的右孩子） 或者 pParent-&gt;left = pCur-&gt;right（为双亲的左孩子）;(待删除节点为非根节点) 为根节点则更新pRoot然后直接删除节点即可 //2.只有左孩子 //3.左右孩子均存在 if(nullptr == pCur-&gt;_pLeft) //情况1 &#123; if(_pRoot == pCur) _pRoot = pCur-&gt;_pRight; else &#123; if(pCur == pParent-&gt;_pLeft) pParent-&gt;_pLeft = pCur-&gt;_pRight; else pParent-&gt;_pRight = pCur-&gt;_pRight; &#125; &#125; else if(nullptr == pCur-&gt;_pRight) //情况2 &#123; if(pCur == _pRoot) _pRoot = pCur-&gt;_pLeft; else &#123; if(pCur == pParent-&gt;_pLeft) pParent-&gt;_pLeft = pCur-&gt;_pLeft; else pParent-&gt;_pRight = pCur-&gt;_pLeft; &#125; &#125; else &#123; //左右孩子均存在---不能直接删除，找一个替代节点 //可以在左子树中找：左子树中最右侧节点 //也可以在右子树中找：右子树中最左侧节点 PNode pFirstOfIn = pCur-&gt;_pRight; PNode pParent = pCur; while(pFirstOfIn-&gt;_pLeft) &#123; pParent = pFirstOfIn; pFirstOfIn = pFirstOfIn-&gt;_pLeft; &#125;//找到右子树的最左侧节点,替代节点，一定没有左孩子，可能有右孩子 pCur-&gt;_data = pFirstOfIn-&gt;_data; //删除替代节点 if(pFirstOfIn == pParent-&gt;_pLeft) pParent-&gt;_pLeft = pFirstOfIn-&gt;_pRight; else pParent-&gt;_pRight = pFirstOfIn-&gt;_pRight; pCur = pFirstOfIn; &#125; delete pCur; return true; &#125; void Inorder() &#123; _InOrder(_pRoot); &#125; PNode Find(const T&amp; data) &#123; PNode pCur = _pRoot; while (pCur) &#123; if(data &lt; pCur-&gt;_data) pCur = pCur-&gt;_pLeft; else if(data &gt; pCur-&gt;_data) pCur = pCur-&gt;_pRight; else return pCur; &#125; return nullptr; &#125;private: void _InOrder(PNode _pRoot) //中序遍历 &#123; if (_pRoot) &#123; _InOrder(_pRoot-&gt;_pLeft); cout &lt;&lt; _pRoot-&gt;_data &lt;&lt; &quot; &quot;; _InOrder(_pRoot-&gt;_pRight); &#125; &#125; void _Destroy(PNode&amp; pRoot) &#123; if (pRoot) //后序销毁 &#123; _Destroy(pRoot-&gt;_pLeft); _Destroy(pRoot-&gt;_pRight); delete pRoot; pRoot = nullptr; &#125; &#125;&#125;;void TestBSTree()&#123; int a[] = &#123;5,3,4,1,7,8,2,6,0,9&#125;; BSTree&lt;int&gt; t; for(auto e : a) t.Insert(e); t.Inorder(); BSTNode&lt;int&gt;* pNode = t.Find(0); if(pNode) cout &lt;&lt; &quot;Yes&quot;&lt;&lt;endl; else cout &lt;&lt; &quot;No&quot;&lt;&lt;endl; t.Erase(6); t.Inorder(); cout &lt;&lt;endl; t.Erase(8); t.Inorder(); cout &lt;&lt;endl; t.Erase(5); t.Inorder();&#125; 二叉树的性能分析插入和删除操作都必须先查找，查找效率代表了二叉搜索树中各个操作的性能。对于有n个结点的二叉搜索树，若每个元素查找的概率相等，则二叉搜索树平均查找长度是结点在二叉搜索树的深度的函数，即结点越深，则比较次数越多。但对于同一个关键码集合，如果各关键码插入的次序不同，可能得到不同结构的二叉搜索树： 也就是说： 最优情况下，二叉搜索树为完全二叉树，其平均比较次数为： 最差情况下，二叉搜索树退化为单支树，其平均比较次数为：]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高级IO]]></title>
    <url>%2F2019%2F04%2F15%2F%E9%AB%98%E7%BA%A7IO%2F</url>
    <content type="text"><![CDATA[在进入IO之前，我们需要先明白一个概念，IO实际上是分两步的——1.等待，2.数据拷贝 正式进入IO时，先来通过一个例子简单理解一下五种IO模型： 123456我们在食堂吃饭，需要点餐后等待做好才能吃到。现在有：1.A同学到达窗口时点了餐以后一动也不动什么都不做就在窗口等着叫号2.B同学点了餐就开始刷手机，过一会抬头看点的餐是不是好了3.C同学学点餐之后告诉旁边的同事让饭好了叫一下他就开始低头玩手机4.D同学发现有好几个窗口都可以排到这份餐，于是他在这些窗口都排了号，等待任意一个窗口即可5.E同学则是拜托了另一位同事去帮他点餐等餐，在拿到餐之后通知他来吃就行 看了上边的例子大家是不是更！懵！了！好啦好啦，我们进入正题： 阻塞IO在内核将数据准备好之前，系统调用会一直等待。（所有的套接字默认都是阻塞方式） 阻塞IO是最常见的IO模型。 非阻塞IO如果内核还未将数据准备好，系统调用仍然会直接返回，并且返回EWOULDBLOCK错误码 非阻塞IO往往需要程序员循环的方式反复尝试读写文件描述符，这个过程称之为轮询。这对CPU来说是极大的浪费，一般只有特定场景下才使用 信号驱动IO内核将数据准备好的时候，使用SIGIO信号通知应用程序进行IO操作 IO多路转接虽然从流程图上看起来和阻塞IO类似，但是实际上最核心在于IO多路转接能够同时等待多个文件描述符的就绪状态 异步IO由内核在数据拷贝完成时，通知应用程序（与信号驱动不同的是，信号驱动是等到了数据告诉应用程序可以拷贝数据了） 现在回去看例子是不是懂了一些！]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能指针]]></title>
    <url>%2F2019%2F03%2F25%2F%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[​ C++程序设计中，使用堆内存是很繁琐的操作——堆内存的申请和释放都需要程序员自己去管理。虽然说程序员自己管理内存可以提高程序的效率，但是整体来说程序员手动管理内存是比较麻烦的，而且容易出现内存泄漏，异常安全（如果在malloc和free之间如果存在抛异常，那么还是有内存泄漏）等问题。而在C++11中引入了智能指针的概念 来管理堆内存。 ​ 智能指针的实现采用了一种RAII（利用对象生命周期来控制程序资源）的技术对普通的指针进行封装，使得智能指针实际是一个对象，其行为表现的却像一个指针。也就是说，在对象构造时获取资源，接着控制对资源的访问使之在对象的生命周期内始终保持有效，最后在对象析构的时候释放资源。那么我们就不需要显式地去释放资源，且对象所需要的资源在生命周期内始终有效。 auto_ptr简单模拟实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950template&lt;class T&gt;class AutoPtr&#123;private: T* _ptr;public: AutoPtr(T* ptr) :_ptr(ptr) &#123;&#125; AutoPtr(AutoPtr&lt;T&gt;&amp; ap) :_ptr(ap._ptr) &#123; ap._ptr = nullptr; &#125; AutoPtr&lt;T&gt;&amp; operator=(AutoPtr&lt;T&gt;&amp; sp) &#123; if(this != sp) &#123; if(_ptr) delete _ptr; //转移资源到当前对象 _ptr = sp._ptr; sp._ptr = nullptr; &#125; &#125; ~AutoPtr() &#123; if(_ptr) delete _ptr; &#125; T&amp; operator*() &#123; return *_ptr; &#125; T&amp; operator-&gt;() &#123; return _ptr; &#125; T&amp; Get() &#123; return _ptr; &#125;&#125;; 由以上代码可以看到，auto_ptr的实现是利用了管理权转移的思想——一旦发生拷贝，就将ap/sp中资源转移到当前对象中，然后令ap/sp与其所管理资源断开联系，这样就解决了一块空间被多个对象使用而造成程序奔溃问题。 但是， 通过实现原理层来分析会发现，这里拷贝后把ap对象的指针赋空了，导致ap对象悬空，通过ap对象访问资源时就会出现问题，于是，引出了一种资源管理权转移的方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566template&lt;class T&gt;class Autoptr&#123;public: Autoptr(T* ptr=nullptr) :_ptr(ptr) ,_owner(false) &#123; if(_ptr) _owner = true; &#125; Autoptr(const Autoptr&lt;T&gt;&amp; ap) :_ptr(ap._ptr) ,_owner(ap._owner) &#123; ap._owner = false; &#125; Autoptr&lt;T&gt;&amp; operator=(const Autoptr&lt;T&gt;&amp; sp) &#123; if(this !=&amp;sp) &#123; Test(); _ptr = sp._ptr; _owner = sp._owner; sp._owner = false; &#125; return this; &#125; ~Autoptr() &#123; Test(); &#125; T&amp; operator*() &#123; return *_ptr; &#125; T&amp; operator-&gt;() &#123; return _ptr; &#125; T&amp; Get() &#123; return _ptr; &#125;private: void Test() &#123; if(_ptr &amp;&amp; _owner) &#123; delete _ptr; _owner = false; &#125; &#125;private: T* _ptr; mutable bool _owner;&#125;; unique_ptr因为在拷贝时经常会出现一些问题，所以引出了一种简单粗暴的方式——禁止拷贝，就问你怕不怕！！！ 也就是说，将类中的拷贝构造函数和运算符重载函数设为私有的，使得资源独占，只能被一个对象使用 123456789101112131415161718192021222324252627282930313233343536模拟实现：template&lt;calss T&gt;class Uniqueptr&#123;public: Uniqueptr(T* ptr = nullptr) :_ptr(ptr) &#123;&#125; ~Uniqueptr() &#123; if(_ptr) delete _ptr; &#125; T* operator*() &#123; return *_ptr; &#125; T* operator-&gt;() &#123; return _ptr; &#125;private: //C98格式 Uniqueptr(const Uniqueptr&lt;T&gt;&amp; ); Uniqueptr&lt;T&gt; operator=(const Uniqueptr&amp; ); //C11格式 Uniqueptr(const Uniqueptr&lt;T&gt;&amp; ) = delete; Uniqueptr&lt;T&gt; operator=(const Uniqueptr&amp; ) = delete;private: T* _ptr;&#125;; shared_str：在C++11中，引入了shared_str这一更靠谱且支持拷贝的智能指针。 shared_str的原理是： 通过引用计数的方式来实现多个shared_str对象之间共享资源。也就是说：shared_str在其内部，为每个资源都维护了一份计数，用来记录该资源被几个对象共享。 在对象被销毁时，就说明该对象不使用这一资源了，对象的引用计数减一。 当引用计数减为0时，说明自己是最后一个使用该资源的对象必须释放该资源。 如果不是0，说明该资源还被其他的对象使用着，就不能释放该资源，否则其他对象就会成为野指针 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127//采用引用计数的方式//为了线程安全，需要上锁，但是可能会造成死锁（锁内调用的其他代码如果抛异常则会造成死锁），守卫锁，进入时创建对象，函数退出时自动销毁// 模拟实现一份简答的SharedPtr,了解原理#include &lt;thread&gt;#include &lt;mutex&gt;template &lt;class T&gt;class SharedPtr&#123;public: SharedPtr(T* ptr = nullptr) : _ptr(ptr) , _pRefCount(new int(1)) , _pMutex(new mutex) &#123; // 如果是一个空指针对象，则引用计数给0 if (_ptr == nullptr) *_pRefCount = 0; &#125; ~SharedPtr() &#123; Release(); &#125; SharedPtr(const SharedPtr&lt;T&gt;&amp; sp) : _ptr(sp._ptr) , _pRefCount(sp._pRefCount) , _pMutex(sp._pMutex) &#123; // 如果是一个空指针对象，则不加引用计数，否则才加引用计数 if (_ptr) AddRefCount(); &#125; // sp1 = sp2 SharedPtr&lt;T&gt;&amp; operator=(const SharedPtr&lt;T&gt;&amp; sp) &#123; //if (this != &amp;sp) if (_ptr != sp._ptr) &#123; // 释放管理的旧资源 Release(); // 共享管理新对象的资源，并增加引用计数 _ptr = sp._ptr; _pRefCount = sp._pRefCount; _pMutex = sp._pMutex; if (_ptr) AddRefCount(); &#125; return *this; &#125; T&amp; operator*() &#123; return *_ptr; &#125; T* operator-&gt;() &#123; return _ptr; &#125; int UseCount() &#123; return *_pRefCount; &#125; T* Get() &#123; return _ptr; &#125; int AddRefCount() &#123; // 加锁或者使用加1的原子操作 _pMutex-&gt;lock(); ++(*_pRefCount); _pMutex-&gt;unlock(); return *_pRefCount; &#125; int SubRefCount() &#123; // 加锁或者使用减1的原子操作 _pMutex-&gt;lock(); --(*_pRefCount); _pMutex-&gt;unlock(); return *_pRefCount; &#125; private: void Release() &#123; // 引用计数减1，如果减到0，则释放资源 if (_ptr &amp;&amp; SubRefCount() == 0) &#123; delete _ptr; delete _pRefCount; &#125; &#125; private: int* _pRefCount; // 引用计数 T* _ptr; // 指向管理资源的指针 mutex* _pMutex; // 互斥锁&#125;;int main()&#123; SharedPtr&lt;int&gt; sp1(new int(10)); SharedPtr&lt;int&gt; sp2(sp1); *sp2 = 20; cout &lt;&lt; sp1.UseCount() &lt;&lt; endl; cout &lt;&lt; sp2.UseCount() &lt;&lt; endl; SharedPtr&lt;int&gt; sp3(new int(10)); sp2 = sp3; cout &lt;&lt; sp1.UseCount() &lt;&lt; endl; cout &lt;&lt; sp2.UseCount() &lt;&lt; endl; cout &lt;&lt; sp3.UseCount() &lt;&lt; endl; sp1 = sp3; cout &lt;&lt; sp1.UseCount() &lt;&lt; endl; cout &lt;&lt; sp2.UseCount() &lt;&lt; endl; cout &lt;&lt; sp3.UseCount() &lt;&lt; endl; return 0;&#125; std::shared_str的线程安全问题：通过以上的代码细心的同学就会发现了：在对引用计数进行加1，减1操作时我们对其进行了上锁操作。 那么为什么要对其进行上锁操作呢？细想一下其实也很简单： 1.智能指针对象中引用计数是多个智能指针对象共享的，两个线程中智能指针的引用计数同时++或–，这个操作不是原子的，引用计数原来是1，++了两次，可能还是2。这样引用计数就错乱了。会导致资源未释放或者程序崩溃的问题。所以只能指针中引用计数++、–是需要加锁的，也就是说引用计数的操作必须是线程安全的。 2.智能指针管理的对象存放在堆上，两个线程中同时去访问，会导致线程安全问题 std::shared_str的循环引用问题：12345678910111213141516171819struct ListNode&#123; int _data; shared_ptr&lt;ListNode&gt; _prev; shared_ptr&lt;ListNode&gt; _next; ~ListNode()&#123; cout &lt;&lt; &quot;~ListNode()&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; shared_ptr&lt;ListNode&gt; node1(new ListNode); shared_ptr&lt;ListNode&gt; node2(new ListNode); cout &lt;&lt; node1.use_count() &lt;&lt; endl; cout &lt;&lt; node2.use_count() &lt;&lt; endl; node1-&gt;_next = node2; node2-&gt;_prev = node1; cout &lt;&lt; node1.use_count() &lt;&lt; endl; cout &lt;&lt; node2.use_count() &lt;&lt; endl; return 0;&#125; 在上边代码上可以看出一个问题——循环引用，分析如下： node1和node2两个智能指针对象指向两个节点，引用计数变成1，我们不需要手动delete。 node1的_next指向node2，node2的_prev指向node1，引用计数变成2。 node1和node2析构，引用计数减到1，但是_next还指向下一个节点。但是_prev还指向上一个节点。 也就是说_next析构了，node2就释放了。 也就是说_prev析构了，node1就释放了。 但是_next属于node的成员，node1释放了，_next才会析构，而node1由_prev管理，_prev属于node2成员，所以这就叫循环引用，谁也不会释放。 12345678910111213141516171819202122// 解决方案：在引用计数的场景下，把节点中的_prev和_next改成weak_ptr就可以了// 原理就是，node1-&gt;_next = node2;和node2-&gt;_prev = node1;时weak_ptr的_next和_prev不会增加node1和node2的引用计数。struct ListNode&#123; int _data; weak_ptr&lt;ListNode&gt; _prev; weak_ptr&lt;ListNode&gt; _next; ~ListNode()&#123; cout &lt;&lt; &quot;~ListNode()&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; shared_ptr&lt;ListNode&gt; node1(new ListNode); shared_ptr&lt;ListNode&gt; node2(new ListNode); cout &lt;&lt; node1.use_count() &lt;&lt; endl; cout &lt;&lt; node2.use_count() &lt;&lt; endl; node1-&gt;_next = node2; node2-&gt;_prev = node1; cout &lt;&lt; node1.use_count() &lt;&lt; endl; cout &lt;&lt; node2.use_count() &lt;&lt; endl; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS，ICMP协议及NAT技术]]></title>
    <url>%2F2019%2F03%2F07%2FDNS%EF%BC%8CICMP%E5%8D%8F%E8%AE%AE%E5%8F%8ANAT%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[DNS(Domain Name System)DNS是一整套从域名映射到IP的系统 在TCP/IP中使用IP地址和端口号来确定网络上的一台主机的一个程序，但是IP地址不方便记忆。所以引出了一种叫主机名的东西，是一个字符串，并且使用hosts文件来描述主机名与IP地址之间的关系 。也就是说，用户简单的输入一个主机名“host-a”通过查文件就可以对应到其IP地址。 最初是通过互联网信息中心（SRI-NIC）来管理这个文件的，但是这样太麻烦，比如说：如果一个新计算机要接入这个网络，或者某个计算机的IP变更了，都需要到信息中心申请变更hosts文件，而且其他的计算机也需要定期的进行下载更新hosts文件才能正确上网。于是就产生了DNS系统。 DNS是一个组织的系统管理机构，维护系统内的每个主机的IP和主机名的对应关系 如果新计算机接入网络，将这个信息注册到数据库中 用户输入域名的时候，会自动查询DNS服务器，由DNS服务器去检索数据库，得到对应的IP地址 域名简介主域名是用来识别主机名称和主机所属的组织机构的一种分层结构的名称。 1www.baidu.com 域名使用.进行连接 com：一级域名，表示这是一个企业域名。同级的还有”net”（网络提供商）,”org”（非盈利组织）等 baidu：二级域名，公司名 www：只是一种习惯用法，之前人们在使用域名时，往往命名成类似于ftp.xxx.xxx/www.xxx.xxx这样的格式，来表示主机支持的协议 域名解析过程计算机Li要访问www.lf.org： 向DNS服务器查询IP地址 由于Feng的DNS服务器并不知道www.lf.org的IP地址是什么，它向根域名服务器请求进行查询 由于根域名服务器知道www.lf.org的IP地址，因此将地址返回 向www.lf.org的域名服务器查询www.lf.org的IP地址 将查到的IP地址返回给客户端 pepper开始与www.lf.org进行通信 简单的来说，过程如下： 输入域名后，先查找自己主机对应的域名服务器 域名服务器先查找自己的数据库中的数据。如果没有，就向上级域名服务器进行查找，依此类推 最多回溯到根域名服务器，肯定能找到这个域名的IP地址 域名服务器自身也会进行一些缓存，把曾经访问过的域名和对应的IP地址缓存起来，可以加速查找过程 ICMP协议ICMP是一个网络层协议 对于一个新搭建好的网络，往往需要先进行一个简单的测试来测试网络是否畅通，但是IP协议并不提供可靠传输。如果丢包了，IP协议并不能通知传输层是否丢包以及丢包的原因。 ICMP功能 确认IP包是否成功到达目标地址 通知在发送过程中IP包被丢弃的原因 ICMP也是基于IP协议工作，但是它并不能传输层的功能，因此人们仍然把它归结为网络层协议 ICMP只能搭配IPV4使用。如果是IPV6的话，需要用的是ICMPv6 ICMP报文格式 ICMP大概分为两类报文： 一类是通知出错原因 一类是用于诊断调查 NAT技术在之前，我们讨论了关于IPv4协议中IP地址数量不足的问题。NAT技术即是当前解决IP地址不够用的主要手段，是路由器的一个功能。 NAT能将私有IP对外通信时转为全局IP，也就是一种将私有IP和全局IP相互转化的技术方法，很多的学校，家庭，公司内部等多采用每个终端设置私有IP，而在路由器或必要的服务器上设置全局IP。全局IP需要唯一，而私有IP则不需要，在不同的局域网中出现相同的私有IP是完全有可能的。 NAT转换过程 NAT路由器将源地址从10.0.0.10替换成了全局IP：202.211.174.37 NAT路由器收到外部的数据时，又会把目标IP从202.211.174.37替换回10.0.0.10 在NAT路由器内部，有一张自动生成的，用于地址转换的表 当10.0.0.10第一次向162.221.120.9发送数据时就会生成表中的映射关系 NAPT此时我们意识到一个问题，如果局域网内同时有多个主机都访问同一个外部的服务器，那么对于服务器返回的数据中目的IP都是相同的，那么NAT路由器如何判定要将这个数据包发给哪个局域网的主机呢？这时候就需要有NAPT来解决问题了，它使用了IP+port来形成一个关联的关系，这个关联关系也是由NAT路由表来维护的 NAT技术的缺陷我们发现NAT技术的实现，是很依赖这个转换表的，所以就会产生诸多问题： 无法从NAT外部向内部服务器建立连接 转换表的生成和销毁都需要额外开销 通信过程中一旦NAT设备异常那么所有的连接也将会断开]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议之GET请求与POST请求的区别]]></title>
    <url>%2F2019%2F03%2F06%2FHTTP%E5%8D%8F%E8%AE%AE%E4%B9%8BGET%E8%AF%B7%E6%B1%82%E4%B8%8EPOST%E8%AF%B7%E6%B1%82%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[GET和POST是HTTP请求的两种基本方式，对于这两种请求方式的区别，只要是接触过Web开发的就能说出一二：GET把参数包含在URL中，POST通过正文传参！ 而我想深入了解以下的时候，就去了w3cschool，这是w3cschool给出的标准答案： 这，恕在下愚钝@-@。在相继查了些资料之后，大概总结如下： GET和POST报文上的区别GET和POST方法其实是没有实质区别的。因为GET和POST只是HTTP协议中的两种请求方式，而HTTP协议是基于TCP/IP的应用层协议，所以无论GET还是POST，用的都是同一个传输层协议，所以在传输上是没有区别的。 而在报文格式上，不带任何参数时最大的区别就是第一行的方法名不同： GET方法请求报文第一行如下：GET + URL + HTTP/1.1 \r\n POST方法请求报文第一行如下：POST+ URL + HTTP/1.1 \r\n 那么在带参数时报文的区别在哪里呢？ 在约定中，GET方法的参数应该放在URL中，POST方法参数应该放在正文中。 举个栗子： 123456789如果参数是name=xiazi，email=97GET方法的简约报文是这样的： GET http://job.com/companyLogin.do?name=xiazi&amp;email=97 HTTP/1.1 HOST：localhostPOST方法的简约报文是这样的： POST http://job.com/companyLogin.do HTTP/1.1 HOST：localhost name=xiazi&amp;email=97 GET方法的安全性问题由上边的例子我们可以知道： GET方法的参数是写在?后面，用&amp;分割的 GET方法中参数会在URL中显示，而POST方法则不会 那么，POST是不是比GET方法安全呢？ 如果是依据数据在地址栏上是否可见来说的话，POST是比GET安全的。然而，从传输的角度来说，他们都是不安全的，因为HTTP在网络上是明文传输的，只要在网络节点上进行抓包就能完整地获取数据报文，所以要想安全传输就只有加密，也就是使用HTTPS GET方法的长度限制问题在HTTP协议中，并没有对BODY（正文）和URL的长度进行长度限制，对URL限制的大多数是浏览器和服务器的原因。大多数浏览器通常都会限制url长度在2K个字节，而大多数服务器最多处理64K大小的url。超过的部分，恕不处理。 浏览器就不用说了，服务器是因为处理长URL要消耗比较多的资源，为了性能和安全（防止恶意构造长URL来攻击服务器）考虑，会给URL限制长度 POST方法会产生两个TCP数据报问题在有些文章中提到，POST方法会将Header和Body分开发送，先发送Header，服务端返回100状态码后再发送Body。 然而，HTTP协议中并没有规定POST发送时要发送两个数据报。因为能力问题借鉴了大佬的研究，得到了以下结论：大多数框架都是尽量在一个tcp包里面把HTTP请求发出去的，但是也确实存在先发HTTP头，然后发body的框架。但是具体发多少个TCP包，这个是代码的问题，是tcp协议栈的问题，跟HTTP没关系。详情请戳这里]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议]]></title>
    <url>%2F2019%2F03%2F06%2FHTTP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[HTTP简介HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从网络服务器传输超文本到本地浏览器的传送协议。 HTTP基于TCP/IP协议来传输数据（HTML 文件, 图片文件, 查询结果等）。它和TCP/IP协议簇内的众多协议相同用来客户端和服务器通信。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。 HTTP之URL在认识URL之前，浅显的提一句URI。HTTP使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。而URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息 URL,全称是UniformResourceLocator, 中文叫统一资源定位符,是互联网上用来标识某一处资源的地址 URI 表示请求服务器的路径，定义这么一个资源 URL 同时说明要如何访问这个资源 平时我们说的“网址”其实就是说的URL。 1http://user:pass@www.example.jp:80/dir/index.htm?uid=1#ch1 从上边的URL可以看到，一个完整的URL包含这几个部分： 1.协议方案名：该协议方案名为“http：”，这代表网页使用的是HTTP协议 2.登陆信息（如果网页需要认证则会出现） 3.域名部分：该URL的域名部分为”www.example.jp&quot;。一个URL中也可以使用IP地址作为域名使用 4.端口部分：跟在域名后面，与域名之间使用”:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分将会采用默认端口 5.带层次的文件路径：从域名后的第一个”/“开始到最后一个”/“结束，是虚拟目录部分。不是URL必须的部分，本例中的虚拟目录是”/dir/“ 6.文件名部分：从域名后的最后一个”/“开始到”?”为止；如果没有”?”，则是从域名后的最后一个”/“开始到”#”为止；如果没有”?”和”#”,那么从域名后的最后一个”/“开始到结束都是文件名部分。本例中的文件名是”index.htm”。文件名部分也不是一个URL必须的部分，如果省略该部分则使用默认的文件名 7.参数部分：从”?”开始到”#”之间的部分称之为参数部分，又称搜索部分，查询部分。本例中的参数部分为”uid=1”。参数可以允许有多个参数，参数之间用”&amp;”作为分隔符 8.锚部分：从”#”开始到最后都是锚部分。本例中的锚部分是”ch1”。锚部分也不是一个URL必须的部分 urlencode和urldecode在URL中，像/？：这样的字符会被当做特殊意义理解，因此这些字符不能随意出现。而如若某个参数需要带有这些特殊字符，就必须对这些特殊字符进行转义，即urlencode编码。 转义规则：将需要转码的字符转为16进制，然后从右往左取四位（不足四位直接处理），每2位做一位，前面加上%，编码成%XY格式 如上图所示，我们搜索的是”C++”，而”+”被转义成了”%2B” urldecode就是urlencode的逆过程，即解码。 HTTP协议格式请求消息Request客户端发送一个HTTP请求到服务器的请求消息包括以下格式： 请求行：用来说明请求类型，要访问的资源以及使用的HTTP版本信息 请求头部：请求的属性，冒号分割的键值对；每组属性用\n分隔，遇到空行则表示请求头部结束 空行 请求正文：请求正文允许为空字符串；如果请求正文存在则在请求头部中会有一个Content-Length属性来表示请求正文的长度 响应消息Response服务器在接收并处理客户端发过来的请求之后会返回一个HTTP的响应消息 HTTP响应也分为四个部分组成，分别是： 状态行：[][][版本号]+[状态码]+[状态码描述] 消息报头：请求的属性，冒号分割的键值对；每组属性用\n分隔，遇到空行则表示请求头部结束 空行 响应正文：如果服务器返回了一个html页面，那么html页面内容就是在响应正文中 HTTP的方法 方法 说明 支持的HTTP协议版本 GET 请求指定的页面信息，并返回实体 1.0，1.1 POST 向指定资源提交数据进行处理请求，可能会导致新的资源的建立或已有资源的修改 1.0，1.1 PUT 传输文件 1.0，1.1（1.1新增） HEAD 获得报文首部（类似于GET请求） 1.0，1.1 DELETE 删除文件 1.0，1.1（1.1新增） OPTIONS 询问支持的方法 1.1（1.1新增） TRACE 回显服务器收到的请求，追踪路径 1.1（1.1新增） CONNECT 预留给能够将连接改为管道方式的代理服务器 1.1（1.1新增） LINK 建立和资源之间的联系 1.0 UNLINE 断开连接关系 1.0 Get与POST请求的区别 HTTP的状态码 类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 常见状态码： 200（OK） 404（Not） 403（Forbidden） 302（Redirect，重定向） 504（Bad Gateway） HTTP常见Header Content-Type：数据类型（text/html等） Content-Length：正文的长度 Host：客户端告知服务器，所请求的资源是在哪个主机的哪个端口上 referer：当前页面是从哪个页面跳转过来的 location：搭配3XX状态码使用，告诉客户端接下来要去哪里访问 Cookie：用于在客户端存储少量信息，通常用于实现会话的功能 HTTP工作原理1.客户端连接到Web服务器 一个HTTP客户端（通常是浏览器），与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接 2.发送HTTP请求 通过TCP套接字，客户端向Web服务器发送一个请求报文 3.服务器接受请求并返回HTTP响应 Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。 4.释放连接TCP连接 5.客户端浏览器解析HTML内容 客户端首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端读取响应数据，根据HTML的语法对其进行格式化，并在浏览器窗口显示]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ARP协议]]></title>
    <url>%2F2019%2F03%2F05%2FARP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[ARP协议虽然我们把ARP协议单独列出来了，但是在介绍ARP协议之前我们需要强调一点——ARP不是一个单纯的数据链路层的协议，而是一个介于数据链路层和网络层之间的协议 ARP协议的作用ARP协议建立了主机IP地址和MAC地址的映射关系 在网络通信时，源主机的应用程序知道目的主机的IP地址和端口号，却不知道目的主机的硬件地址 数据包首先是被网卡接收到再去处理上层协议的，如果接收到的数据包的硬件地址与本机不符则直接丢弃 因此在通讯前必须获得目的主机的硬件地址 ARP协议工作流程 源主机发出ARP请求，询问“IP地址是127.20.1.4的主机的硬件地址是多少”，并将这个请求广播到本地网段（以太网帧首部的硬件地址填FF：FF：FF：FF：FF：FF表示广播） 目的主机接收到广播的ARP请求，发现其中的IP地址与本机相符合，则发送一个ARP应答数据包给源主机，将自己的硬件地址填写在应答包中 每台主机都维护一个ARP缓存表，可以用arp -a命令查看。缓存表中的表项有过期时间（一般为20分钟）。如果20分钟内没有再次使用某个表项，则该表项失效，下次还要发ARP请求来获得目的主机的硬件地址 ARP数据报格式 源MAC地址，目的MAC地址在以太网首部和ARP请求中各出现一次，对于链路层为以太网的情况是多余的，但如果链路层是其他类型的网络则有可能是必要的 硬件类型指链路层网络类型，1为以太网 协议类型指要转换的地址类型，0x0800为IP地址 op字段为1表示ARP请求，op字段为2表示ARP应答]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目之文本相似度比较]]></title>
    <url>%2F2019%2F03%2F03%2F%E9%A1%B9%E7%9B%AE%E4%B9%8B%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[​ 对于当代大学生而言，毕业时写的论文是一个对自己知识的 1.基于jieba库对文件进行分词 123456789101112131415161718192021222324252627282930313233343536373839404142Similarity::wordfreq Similarity::getWordFreq(const char* filename)&#123; ifstream fin(filename); if(!fin.is_open()) &#123; cout &lt;&lt; &quot;Open File&quot; &lt;&lt; filename &lt;&lt; &quot;Failed&quot;&lt;&lt;endl; return wordfreq(); &#125; string line; wordfreq freq; while(!fin.eof()) &#123; getline(fin,line); //GBK--&gt;UTF8 line = GBKToUTF8(line); //分词 vector&lt;string&gt; words; _jieba.Cut(line,words,true); //统计词频，统计时先对应停用词表去掉停用词 for(const auto&amp; e : words) &#123; if(_StopWordSet.count(e) &gt; 0) continue; else &#123; if(freq.count(e) &gt; 0) freq[e]++; else freq[e] = 1; &#125; &#125; return freq; &#125;&#125; 2.而在统计词频时，需要对分好的词去掉停用词，使用jieba中给出的停用词文件构造停用词表（人类语言包含很多功能词。与其他词相比，功能词没有什么实际含义。 停用词主要包括数字、标点符号及使用频率 特高的词(代词，语气助词、副词、介词、连接词 )等。 我 我们 怎么办 总之 此外 然而 不如 不妨 。 , ？ …….. 停用词不代表实际意义，所以不需要统计停用词的词频，停用词不参与构建词频向量 ） 1234567891011121314151617void Similarity::getStopWord(const char* stopwordsFile)&#123; ifstream fin(stopwordsFile); if(!fin.is_open()) &#123; cout&lt;&lt;&quot;Open File&quot; &lt;&lt; stopwordsFile &lt;&lt;&quot;Failed&quot; &lt;&lt;endl; return; &#125; string line; while(!fin.eof()) &#123; getline(fin,line); _StopWordSet.insert(line); &#125; fin.close();&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太网]]></title>
    <url>%2F2019%2F02%2F17%2F%E4%BB%A5%E5%A4%AA%E7%BD%91%2F</url>
    <content type="text"><![CDATA[点到点信道的数据链路层协议的数据单元为帧： 将网络层交下来的IP数据报添加首部尾部封装成帧； 将封装好的帧发送给接受方的数据链路层； 收到的帧无差错则从中提取到IP数据报交给网络层，否则丢弃 ​ 由上图可知，在 IP 数据包交付的过程中，在数据链路层会对数据包进行添加报头信息。此时就要引出一个新的概念——以太网。那么以太网是什么呢？ 以太网不是一种具体的网络，而是一种技术标准。它既包含了数据链路层的内容，也包含了一些物理层的内容。例如：规定了网络拓扑结构，访问控制方式，传输速率等 以太网是当前应用最广泛的局域网技术（和以太网并列的还有令牌环网，无线LAN等） 以太网帧格式​ 以太网帧就是将网络层交付的数据添加报头信息后，此时的数据以帧的形式传递。 ​ 以太网格式如下： 在这里，目的地址与源地址这里都指的是 MAC 地址。每一个主机对应唯一的一个 MAC 地址，是由网卡决定的，长度是 48 位，所以这里的目的地址与源地址都是 6 个字节，也就是 48 个比特位。 在以太网帧的最后，还有一个 CRC 校验码，来校验数据是否异常。 在中间，有一个两个字节的类型标识。这个类型字段有三种值，分别对应IP、ARP、RARP。 类型字段IP 如果类型码为 0800 那么在数据链路层解包完毕后，将该数据交付给网络层的 IP 协议来处理该报文。 ARP 如果类型码是 0806 ， 那么在向上层交付的时候就交付给 ARP 协议，这里要说的是 ARP 协议是处于数据链路层与网络层之间的一种协议，也叫作地址解析协议。它将 IP 地址转换为 MAC 地址。 RARP RARP 协议，就是 Reverse ARP，与 ARP 协议相同，是将 MAC 地址转换为 IP 地址的协议 注意：一般来说，数据第一次发送给目的主机时，在这之前应该发送 ARP 协议，根据目的主机的 IP 地址来确定目的主机的 MAC 地址，从而为后面的数据发送与接收提供便利 MAC地址与IP地址 MAC地址用来识别数据链路层中相连的节点 MAC地址长度为48位，即6个字节。一般用16进制数字加上冒号的形式来表示（例如：08：00：27：03：fb：19） MAC地址在网卡出场时就确定了，不能被修改。MAC地址通常时唯一的 在数据发送传输的过程中，目的 IP 地址与源 IP 地址是永远不会变的，这是这个数据的起始与终点，而 MAC 地址是一直在变化的，由于数据在传输的过程中会经历很多的主机等，所以在这个过程中 MAC 地址一直在变。类似于我们坐车，要坐车从 A 出发，目的地是 D。这个过程中我们会经过 B C，在到达 B 的时候，此时的 MAC 地址相当于我们上一站是 A ， 下一站是 C。而目的 IP 地址与 源 IP 地址 分别是 D 与 A，这样说的话就很好理解了（MAC 地址与 IP 地址，一个代表的目的与终点，一个代表着途中的经过。所以在到达目的局域网后，数据包并不知道要传输给哪台主机，因为 MAC 地址的变化，但是目的 IP 地址一直没有变化，所以此时就需要 ARP 协议来确定目的主机的 MAC 地址） MTU在谈 IP 协议的时候说到， IP数据报的长度受数据链路层的 MTU 影响。数据链路层要求在网络层传输过来的数据包必须在 MTU 范围内 。MTU相当于发快递时对包裹尺寸的限制。这个限制是不同的数据链路对应的物理层产生的限制。 以太网帧中的数据长度规定最小46个字节，最大1500字节。ARP数据包的长度不够46字节，那么要在后面补充填充位（PAD） 最大值1500称之为以太网的最大传输单元（MTU），不同的网络类型有不同的MTU 如果一个数据包从以太网路由到拨号链路上，数据包长度大于拨号链路的MTU了，则需要对数据包进行分片 MTU对IP协议的影响由于MTU的限制，对于较大的IP数据包要进行分包 在IP层在添加报头信息之前，要判断此时由传输层传输过来的数据段是否超过了1480个字节（以太网帧中的数据包括IP协议的报头信息，IP协议的报头信息为20字节），如果超过了那么则要对该数据段进行分片） 将较大的IP包分成多个小包，并给每个小包打上标签 每个小包IP协议头的16位标识是相同的 每个小包的IP协议头的3位标志字段中，第二位置0表示允许分片，第3位表示结束标记（当前是否是最后一个小包，如果是则置为1，否则置为0） 到达对端后再将这些小包按顺序重组，拼装到一起返回给传输层 一旦这些小包中任意一个小包丢失，接收端的重组就会失败，但是IP层不会负责重新传输数据 MTU对UDP协议的影响 因为IP数据报的首部为20字节,所以IP数据报的数据区长度最大为1480字节. 而这个1480字节就是用来放TCP传来的TCP报文段或UDP传来的UDP数据报的. 又因为UDP数据报的首部8字节,所以UDP数据报的数据区最大长度为1472字节. 这个1472字节就是我们可以使用的字节数。 一旦UDP携带的数据超过1472，那么就会在网络层分成多个IP数据报 这些多个数据报有任意一个丢失都会引起接收端网络层重组失败。这就意味着，如果UDP数据报在网络层被分片，整个数据被丢失的概率就大大增加了 MTU对TCP协议的影响我们先来回忆一下TCP协议： TCP的一个数据报也不能无限大，还是受制于MTU。TCP的单个数据报的最大消息长度，称为MSS（Max Segment Size） TCP在建立连接的过程中，通信双方会进行MSS协商 最理想的情况下，MSS的值正好是在IP不会被分片处理的最大长度（这个长度仍然受制于数据链路层的MTU） 双方在发送SYN的时候会在TCP头部写入自己能支持的MSS值 然后双方得知对方的MSS值之后，选择较小的作为最终MSS MSS的值就是在TCP首部的40字节变长选项中 MSS和MTU的关系​ 由上可知，MSS 的大小其实就是应用层给传输层的交付的数据的大小。不包括传输层的报头信息。所以在计算 MSS 的时候，用 MTU 减去网络层报头长度以及传输层报头长度即可。]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP协议]]></title>
    <url>%2F2019%2F01%2F28%2FIP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[基本概念 IP协议提供了一种从A主机跨网络将数据传给B主机的能力 主机：配有IP地址，但是不进行路由控制的设备 路由器：既配有IP地址，又可以进行路由控制 节点：主机和路由器的统称 IP协议头格式 4位版本号：指定IP协议的版本，对于IPV4来说就是4，IPV6为6 4位首部长度：IP头部的长度是多少个32bit，也就是Lenth*4的字节数。4bit表示最大的数字是15，因此IP头部最大长度是60字节 8位服务类型：3位优先权字段（已经弃用），4位TOS字段，和1位保留字段（必须置为0）.4位TOS分别表示：最小延时，最大吞吐量，最高可靠性，最小成本。这四者相互冲突，只能选择一个。对于ssh/telnet这样的应用程序，最小延时比较重要；对于ftp这样的程序，最大吞吐量比较重要 16位总长度：IP数据报整体占多少个字节 16位标识：唯一的标识主机发送的报文。如果IP报文在数据链路层被分片了，那么每一个片里面的这个id是相同的 3位标志字段：占3位，但目前只有两位有意义 标志字段中的最低位记为MF。MF=1即表示后面“还有分片”的数据报。MF=0表示这已经若干数据报片中的最后一个 标志字段中间的一位记为DF，置为1表示禁止分片，这时候如果报文长度超过MTU，IP模块就会丢弃报文，只有DF=0时才允许分片 13位分片偏移：是分片相对于原始IP报文开始处的偏移。其实就是在表示当前分片在原报文中处在哪个位置。实际偏移的字节数*8得到的。因此，除了最后一个报文之外，其他报文的长度必须是8的整倍数（否则报文就不连续了） 片偏移计算为什么以8字节为单位？ 因为在报头中，IP总长度是16位来表示的，也就是总共可能有2^16个字节数据，但是只有13位片偏移，相差2^3，也就是8位。 8位生存时间：数据报到达目的地的最大报文跳数。一般是64.每次经过一个路由，TTL-=1，一直减到0还没到达，那么就丢弃了。这个字段主要是用来防止出现路由循环 8位协议：表示上层协议的类型 16位头部校验和：使用CRC进行校验，来鉴别头部是否损坏 32位源地址和32位目标地址：表示发送端和接收端 选项字段（不定长，最多40字节） 网段划分​ 在根据TCP/IP协议进行通信时，要用IP地址来标识主机或路由器。在IPv4中，IP地址是一个32位的整数。所以最多可以表示的数字IP地址是：2^32（大约是43亿）。 ​ IP地址由网络号和主机号两部分来标识。处于不同网段内的主机必须有不同的网络标识。而处于同一网段内的主机的网络号表示相同，但主机号标识必须不同。所以，在某网段内新增一台主机后，该主机的网络号与该网段的网络号相同，但是主机号不能与该网段里的其他主机的主机号相同，即通过合理设置网络号和主机号，就可以保证在相互连接的网络中，每台主机的IP地址都是唯一的。 123那么问题来了，手动管理子网内的IP，是一个相当麻烦的事情。有一种技术叫做DHCP，能够自动的给子网内新增的主机节点分配IP地址，避免了手动管理IP的不便一般的路由器都带有DHCP功能，因此路由器也可以看做一个DHCP服务器 通过将IP地址划分为网络号和主机号来标识，可以有如下特点： （1）IP地址管理机构在分配IP地址时只分配网络号。剩下的主机号由得到该网络号的单位自行分配，这样就方便了管理就够的管理； （2）路由器在寻找目的主机的IP地址时，只需找到目的主机所在的局域网，再在该局域网内寻找目的主机。 （3）具有不同网络号的局域网必须有路由器进行连接，所以路由器总是有两个或两个以上网络号不同的IP地址 IP地址分类 A类 0.0.0.0到127.255.255.255 B类 128.0.0.0到191.255.255.255 C类 192.0.0.0到223.255.255.255 D类 224.0.0.0到239.255.255.255 E类 240.0.0.0到247.255.255.255 ​ A类地址的网络号占1个字节，只有7位可以使用。可以指派的A类网络号为126（2^7-2）个。A类IP地址中网络字段全0表示的是“本网络（A类网络）”的意思，不用于分配给具体的主机。IP地址中网络号全1表示的是本地环回地址，用于测试本主机的进程之间的通信，即网络号为127的IP地址。A类地址的主机号占3个字节，所以一个A类网络中可以连接的最大主机数为：2^24-2。主机号全0表示该主机连接的单个网络地址（某个A类网络），主机号全1表示该网络中的所有主机。 B类地址的网络号占2个字节，只有14位可以使用。可以指派的B类网络号为2^14-1（128.0.0.0）不用，最小的网络号为：128.1.0.0。每一个B类网路可以连接的最大主机数为：2^16-2=65534。（扣除主机号全0和全1的IP地址）。 ​ C类地址的网络号占3个字节，只有21位可以使用。可以指派的C类网络号为2^21（192.0.0.0不用），最小的网络号为：192.0.1.0。每一个C类主机可以连接的最大主机数为：2^8-2=254（扣除主机号为全0和全1的IP地址）。 子网划分为什么要划分子网？ 第一，节约IP地址。 ​ 这个很容易懂，比如一个C类的地址块，192.168.1.0/24，可以有254个主机，可是你的网络只有20台机器，也就是说你浪费了234个IP地址，实际上拿出来5位作主机地址就够用了，也就是说把你的子网掩码写成255.255.255.224就行了，那么余下的3位就是子网号，可以划分为8个子网，你用一个其余的就可以给别人的网络用 第二，路由表太大，影响网络性能 ​ 路由器需要能够从路由表中找出怎样到达其他网络的下一跳地址，而一个物理网络对应一个网络号，如果网络越多，则路由表越大，路由器的存储空间就需要越大，查找也更耗时，但使用构造子网，则能减少网络数，提升性能 第三，增加了广播域，减少了广播风暴 ​ 明确一点，一个子网一个广播域。 ​ 所谓广播传输，就是向本网段中的所有节点都发送同样的数据包，这就势必要占用相当多的网络资源（因为每个广播数据包硬件设备都要对它进行分析）。然而最令人讨厌的就是在这些广播传输中对终端真正有用的只是所有广播接收用户中的一个，因为广播的目的就是查询目标用户的MAC地址，这样也就是在所有广播传输中，绝大多数都是没有取到任何作用的，纯粹是资源的浪费。而且网络规模越大，广播数据包发送所占用的资源就越多（因为广播中要传输的次数越多），很可能就形成广播风暴，正常的网络通信可能被中断，致使网络瘫痪 ​ 而又因为广播数据包只能在同一网段中传输，网络规模小了，网络中用户数少了，当然所占用的资源也就少了 子网掩码​ 随着Internet的飞速发展，这种划分方案的局限性就显现出来：IP地址空间的利用率降低——一个B类网络中最多可以表示的IP地址为65534个，而某些种类网络由于链路的特点能够连接的结点个数有限，所以就会造成大量的IP地址浪费；由于C类网络能连接的结点个数有限。所以，单位会申请B类网络，但一般又用不了这么多的IP地址，所以会造成IP地址的浪费。同理，A类网络的IP地址也会造成大量的浪费。 ​ 针对这种情况提出了新的划分方案，称为CIDR： 引入一个额外的子网掩码来区分网络号和主机号 子网掩码也是一个32位的正整数，通常用一串“0”来结尾 将IP地址和子网掩码进行“按位与”操作，得到的结果就是网络号 网络号和主机号的划分与这个IP地址是A类，B类还是C类无关 划分子网的例子： 可见，IP地址与子网掩码做与运算可以得到网络号，主机号从全0到全1就是子网的地址范围 1IP地址和子网掩码还有一种更简洁的表示方式，例如140.252.20.68/24.表示IP地址为140.252.20.68，子网掩码的高24位是1，也就是255.255.255.0 特殊的IP地址 将IP地址中的主机地址设置为全0，就成为了网络号，代表这个局域网 将IP地址中的主机地址全部设为1，就成为了广播地址，用于给同一个链路中相互连接的所有主机发送数据包 127.*的IP地址用于本机环回测试，通常是127.0.0.1· IP地址的数量限制​ 我们知道，IP地址（IPv4）是一个4字节32位的正整数，那么一共只有2的32次方个IP地址，大概是43亿左右，而TCP/IP协议规定，每个主机都需要一个IP地址。 ​ 这意味着，只有43亿台主机能接入网络么？实际上，由于一些特殊的IP地址的存在，数量远远不足43亿；另外，IP地址并非是按照主机台数来配置的，而是每一个网卡就需要配置一个或多个IP地址。 ​ CIDR在一定程度上缓解了IP地址不够用的问题（提高了利用率，减少了浪费），但是IP地址的绝对上限并没有增加，仍然是不够用的，这时候有三种方式来解决： 动态分配IP地址：只给接入网络的设备分配IP地址。因此同一个MAC地址的设备，每次接入互联网中得到的IP地址是不同的 IPv6：IPv6并不是IPv4的简单升级版。这是互不相干的两个协议，彼此互不兼容；IPv6用16字节128位来表示一个IP地址（但是IPv6还没有普及） NAT技术 私有IP地址和公网IP地址​ 如果一个组织内部组建局域网，IP地址只用于局域网内的通信，而不直接连到Internet上，理论上使用任意的IP地址都可以，但是RFC 1918规定了用于组建局域网的私有IP地址 10.*，前8位是网络号，共16，777，216个地址 172.16.到172.31.，前12位是网络号，共1，048，576个地址 192.168.*，前16位是网络号，共65，536个地址包含在这个范围中的，都成为私有IP，其余的则称为全局IP（或公网IP） 注意： 1.一个路由器可以配置两个IP地址，一个是WAN口IP，一个是LAN口IP（子网IP）2.路由器LAN口连接的主机，都从属于当前这个路由器的子网中3.不同的路由器，子网IP其实都是一样的（通常都是192.168.1.1），子网内的主机IP地址不能重复，但是子网之间的IP就可以重复了 4.每一个家用路由器，其实又作为运营商路由器的子网中的一个节点。这样的运营商路由器可能会有很多级，最外层的运营商路由器，WAN口IP就是一个公网IP了 5.子网内的主机需要和外网进行通信时，路由器将IP首部中的IP地址进行替换（替换成WAN口IP），这样逐级替换，最终数据包中的IP地址成为一个公网IP。这种技术称为NAT（Network Address Translation，网络地址转换） 6.如果希望我们自己实现的服务器程序能够在公网上被访问到，就需要把程序部署在一台具有外网IP的服务器上 路由​ 路由的过程，就是”一跳一跳“问路的过程，”一跳“就是数据链路层中的一个区间，具体在以太网中指从源MAC地址到目的MAC地址之间的帧传输区间。 IP数据包的传输过程也和问路一样： 当IP数据包，到达路由器时，路由器会先查看目的IP 路由器决定这个数据包是能直接发送给目标主机，还是需要发送给下一个路由器 依次反复，一直到达目标IP地址 那么怎么判断当前这个数据包该发送到哪里呢？这个就依靠每个节点内部维护的一个路由表。 路由表可以使用route命令查看 如果目的IP命中了路由表，就直接转发即可 路由表中的最后一行，主要由下一跳地址和发送接口两部分组成，当目的地址与路由表中其他行都不匹配时，就按缺省路由条目规定的接口发送到下一跳地址]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP协议]]></title>
    <url>%2F2019%2F01%2F07%2FTCP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[对于常见的网络协议来说，TCP是最为人知晓的，即便是一些业外人士只要对电脑网络有一定的了解也能说上几句，那么广为人知的TCP协议到底是什么呢，下边作为一个初学者的视角来浅谈一下 TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议 。常用于一次传输要交换大量报文的情形，如文件传输，远程登陆等。为了实现这种端到端的可靠传输，TCP必须规定传输层的连接建立与拆除的方式，数据传输格式，确认的方式，目标应用进程的识别以及差错控制和流量控制机制等。 TCP的协议数据单元被称为分段，TCP通过分段的交互来建立连接，传输数据，发出确认，进行差错控制，流量控制及关闭连接。 TCP分段格式 TCP协议段格式 源/目的端口号：表示数据从哪个进程来，到哪个进程去； 32位序号：该分段在发送方的数据流中的位置，用来保证到达数据顺序的序号 32位确认序号：下一个期望接收的分段序号，相当于是对方发送的并已经被本方正确接收的分段的确认 4位首部长度：TCP头长，以32位字长为单位。表示该TCP头部有多少个4字节，所以TCP头部最大长度为15*4=60，实际相当于给出数据在数据段中的开始位置 保留：占6比特，目前置为“0” 六位标志位： URG：紧急指针是否有效，即解决报文插队的问题 ACK：确认号是否有效 PSH：提示接收端应用程序立刻从TCP缓冲区将数据读走（接收方的上层尽快取走） RST：对方要求重新建立连接（复位报文段） SYN：请求建立连接，与ACK合用以建立TCP连接 FIN：通知对方，本端要关闭了。称携带FIN标识的为结束报文段 16位窗口大小：可以理解成自己所能提供的缓冲区大小（填上自己的，给对方看，让对方根据这个数值来设置要发给自己的被滑动窗口传输的数据量）。由于窗口由16位bit所定义，所以接收端TCP 能最大提供65535个字节的缓冲 16位校验和：CRC校验。接收端不通过则认为数据有问题。此处的校验和不光包括TCP首部，也包括TCP数据部分 16位紧急指针：标识哪部分数据是紧急数据 40字节头部选项：暂时忽略 连接管理机制TCP连接包括建立和拆除两个过程。TCP使用3次握手协议来建立连接。连接可以由任何一方发起，也可以由双方同时发起。一旦一台主机上的TCP软件已经主动发起连接请求，运行在另一台主机上的TCP软件就被动地等待握手。 建立连接（三次握手）设主机B运行一个服务器进程，它先发出一个被动打开命令，告诉它的TCP要准备接收客户进程的连续请求，然后服务进程就处于听的状态。不断检测是否有客户进程发起连续请求，如有，作出响应。 设客户进程运行在主机A中，他先向自己的TCP发出主动打开的命令，表明要向某个IP地址的某个端口建立运输连接，过程如下： ​ 1）主机A的TCP向主机B的TCP发出连接请求报文段，其首部中的同步比特SYN应置1，同时选择一个序号x，表明在后面传送数据时的第一个数据字节的序号是x。 ​ 2）主机B的TCP收到连接请求报文段后，如同意，则发挥确认。在确认报文段中应将SYN置为1，确认号应为x+1，同时也为自己选择一个序号y ​ 3）主机A的TCP收到此报文段后，还要向B给出确认，其确认号为y+1 ​ 4）主机A的TCP通知上层应用进程，连接已经建立，当主机B的TCP收到主机A的确认后，也通知上层应用进程，连接建立。 释放连接（四次挥手） 在数据传输完毕之后，通信双方都可以发出释放连接的请求。释放连接的过程为如上图所示： ​ 1）数据传输结束后，主机A的应用进程先向其TCP发出释放连接请求，不在发送数据。TCP通知对方要释放从A到B的连接，将发往主机B的TCP报文段首部的终止比特FIN置为1，序号u等于已传送数据的最后一个字节的序号加1。 ​ 2）主机B的TCP收到释放连接通知后发出确认，其序号为u+1，同时通知应用进程，这样A到B的连接就释放了，连接处于半关闭状态。主机B不在接受主机A发来的数据；但主机B还向A发送数据，主机A若正确接收数据仍需要发送确认。 ​ 3）在主机B向主机A的数据发送结束后，其应用进程就通知TCP释放连接。主机B发出的连接释放报文段必须将终止比特置为1，并使其序号w等于前面已经传送过的数据的最后一个字节的序号加 1，还必须重复上次已发送过的ACK=u+1。 ​ 4）主机A对主机B的连接释放报文段发出确认，将ACK置为1。这样才把从B到A的反方向连接释放掉，主机A的TCP再向其应用进程报告，整个连接已经全部释放。 123456789101112131415161718可以根据上图看到客户端以及服务端状态变化：客户端状态变化：CLOSED-&gt;SYN_SENT:客户端调用connect,发送同步报文段SYN_SENT-&gt;ESTABLISHED:connect调用成功，则进入ESTABLISHED状态，开始读写数据ESTABLISHED-&gt;FIN_WAIT_1：客户端主动调用close时，向服务器发送结束报文段，同时进入FIN_WAIT_1FIN_WAIT_1-&gt;FIN_WAIT_2:客户端收到服务器对结束报文段的确认就进入FIN_WAIT_2，开始等待服务器的结束报文段FIN_WAIT_2-&gt;TIME_WAIT:客户端收到服务器发来的结束报文段，进入TIME_WAIT,并发出LAST_ACKTIME_WAIT-&gt;CLOSED:客户端要等待一个2MSL（Max Segment Life，报文最大生存时间）的时间才进入CLOSE状态服务端状态变化：CLOSED-&gt;LISTEN:服务端调用listen后进入LISTEN状态，等待客户端连接LISTEN-&gt;SYN_RCVD:一旦监听到客户端连接请求（同步报文段），就将该连接放入内核等待队列中，并向客户端发送 SYN确认报文SYN_RCVD-&gt;ESTABLISHED:服务端一旦收到客户端的确认报文，就进入ESTABLISHED状态，可以进行读写数据了ESTABLISHED-&gt;CLOSE_WAIT:当客户端主动关闭连接（调用close），服务器会收到结束报文段，服务器返回确认报文 段并进入CLOSE_WAITCLOSE_WAIT-&gt;LAST_ACK:进入CLOSE_WAIT后说明服务器准备关闭连接（处理完之前的数据）；当服务端真正调用close 关闭连接时，会向客户端发送FIN，此时服务器进入LAST_ACK状态，等待最后一个ACK到来（这个 ACK是客户端确认收到了FIN）LAST_ACK-&gt;CLOSED:服务器收到了对FIN的ACK，彻底关闭连接 服务拒绝式攻击​ 在连接管理机制这里，我们可以发现如果想要黑掉一台服务器是很容易的。因为TCP是面向连接的，也就是说当服务器端与客户端要进行数据通信时首先要建立连接，而在建立连接时服务器端与客户端的关系本身是一对多的，当一个服务器被多个客户端访问时就有可能在服务器端建立很多的连接，此时我们首先需要明确一点——服务器端管理连接是要耗费成本的——空间成本和时间成本。那么也就是说服务器端操作系统通过先描述再组织的方式要把连接管理起来，即在系统层面上创建一个结构体对象，而创建一个结构体对象是需要成本的（包括内存资源），连接越多所需要的资源越多，换而言之，要想黑掉一个服务器只需要使服务器挂上大量不做任何操作的非法连接，这样就会导致正常客户想要和服务器无法正常通信——操作系统因为资源问题不可能使连接创建好。 为什么是三次握手？​ 在了解了服务拒绝式攻击后，我们现在可以思考一个问题，建立连接为什么是三次握手而不是两次，抑或四次？ 12为什么不是两次握手？ 两次握手会产生一个问题——最后一个响应报文(ACK）丢失，从而导致服务器端对客户端的请求进行回应（第二次握手）后，就会认为连接已经建立好。而如果客户端没有收到服务器端对其做出的回应呢？此时，客户端认为连接尚未建立，而服务器端会对已经建立的连接保存必要的资源，如果出现大量的这种情况，服务器端会崩溃。 1234为什么是三次握手？ 我们看了上边的分析又会有一个疑问：既然没法确认第二次的握手，客户端是否可以收到，那么怎么确定第三次握手服务器端就可以收到呢？ 这根本没法确定，因为完全可靠的通信协议是根本不存在的，我们任何的通信协议都是在接受这样的现实情况之上进行的。此时我们假设三次握手的最后一个ACK丢失，这时客户端认为连接已经建立好而服务器端认为没有，连接挂在了客户端上，服务器端就不用耗费资源去管理连接，有效的规避了服务器受到攻击的可能。 所以使用三次握手可以较为可靠的建立连接！ 理解TIME_WAIT释放连接时，提到一个名词–&gt;TIME_WAIT,那么什么是TIME_WAIT？ 首先我们可以通过如下测试：启动server，再启动一个client，然后使用Ctrl+C使server终止，这时立马运行server结果是： 这是因为，虽然server的应用程序终止了，但是TCP协议层的连接还没有完全断开，因此不能监听到同样的server端口。 12TCP协议规定，主动关闭的一方要处于TIME_WAIT状态，等待两个MSL的时间才能回到CLOSED状态。我们使用Ctrl+C终止了server，所以server是主动关闭连接的一方，在TIME_WAIT期间仍然不能再次监听同样的server端口。 TIME_WAIT为什么是2MSL呢123MSL是TCP报文的最大生存时间，因此TIME_WAIT持续在2MSL时间的话:1.保证在两个传输方向上的尚未被接收或迟到的报文段都已经消失（否则服务器立即重启就会收到来自上一个进程迟到的数据，而这个数据可能是错误的）2.在理论上保证最后一个报文可靠到达（假设最后一个ACK丢失了，那么服务器会重发一个FIN。这时候虽然客户端进程不在了，但是TCP连接还在，仍然可以重发LAST_ACK） ​ 此时会出现一个新的问题：如果服务器需要处理大量的客户端连接，但是这些连接的生存周期很短，这个时候如果由服务器来主动关闭连接清除不活跃连接就会导致服务器上产生大量TIME_WAIT连接，从而导致服务器的端口不够用无法处理新的连接。 1234567如何解决这个问题呢？ 在server代码的socket()和bind()调用之间插入如下代码： int opt = 1; setsockopt(listenfd,SOL_SOCKET,SO_REUSEADDR,&amp;opt,sizeof(opt)); 引入了setsockopt()函数。使用setsockopt()设置socket描述符的选项SO_REUSEADDR为1，表示允许创建端口号相同但IP地址不同的多个socket描述符 确认应答（ACK）机制​ TCP将每一个字节的数据都进行了编号，即为序列号。而每一个ACK都带有对应的确认序列号，意思是告诉发送者，我已经收到了哪些数据，下一次你从哪里开始发。 ​ 由图分析：当主机1给主机2发送了1~1000这么多数据时，主机2如果收到了就会给主机1应答（ACK报文段，每一个ACK都带有对应的确认序列号），表示你给我发的1~1000的数据我已经全部收到了（收到哪些数据），下次你再给我发就给我从1001数据开始发（下次从哪里开始发）。那么主机1收到应答之后就知道对方已经收到了1~1000的全部数据，所以再一次发送数据的时候他就会从1001开始发，后面都是依此类推的情况。 ​ 当然了，当我们的主机1给主机2发送了数据之后，经过一端时间主机1并没有收到主机2的应答的情况也是有的，所以这个时候为了确保数据的准确到达，TCP就有了超时重传机制。 超时重传机制​ ​ 如图所示，主机A发送数据给主机B之后，可能因为网络拥堵等原因，数据无法到达主机B;那么主机A在一个特定的时间间隔内没有收到B发来的确认应答就会进行重发。 ​ 但是，主机A未收到主机B发来的确认应答，也可能是因为ACK丢失了： ​ 因此主机B会收到很多重复数据，那么TCP协议需要能识别出哪些包是重复的包，并且把重复的丢弃掉，这时候我们可以利用前面提到的序列号就可以很容易做到去重的效果。 ​ 那么，超时的时间如何确定呢？ ​ 最理想的情况下，找到一个最小的时间，保证“确认应答一定能在这个时间内返回”，但是这个时间的长短随着网络环境的不同是有差异的。如果超时时间设的太长会影响整体的重传效率，如果超时时间设的太短有可能会频繁发送重复的包。 ​ TCP为了保证无论在任何环境下都能比较高性能的通信，因此会动态的计算这个最大超时时间。 1Linux下，超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。如果重发一次仍然得不到应答，那么等待2*500ms后再进行重传；如果还得不到应答，等待4*500ms进行重传···依次类推，以指数形式递增。在累计到一定的重传次数后，TCP会认为网络或者对端主机出现异常，强制关闭连接。 滑动窗口​ 刚才我们讨论了确认应答机制，对每一个发送的数据段，都要给一个ACK确认应答，收到ACK后再发送下一个数据段。这样做有一个比较大的缺点：性能较差。尤其是数据往返时间较长时候。 ​ 这样一发一收的方式性能较低，那么我们一次发送多条数据，就可以大大的提高性能（其实是将多个段的等待时间重叠在一起了）。 窗口大小指的是无需等待确认应答而可以继续发送数据的最大值。上图窗口大小就是4000个字节（四个段） 发送前四个段的时候，不需要等待任何ACK，直接可以发送 收到第一个ACK后，滑动窗口向后移动，继续发送第五个段的数据，依次类推 操作系统为了维护这个滑动窗口，需要开辟发送缓冲区来记录当前还有哪些数据没有应答，只有确认应答过的数据才能从缓冲区删掉 窗口越大，则网络的吞吐率就越高 123注意：1.凡是已经发送过的数据，在未收到确认之前都必须暂时保留，以便在超时重传时使用。2.发送窗口前沿通常是不断向前移动的，但也有可能不动。这对于两种情况：一是没有收到新的确认，对方通知的窗口大小也不变；二是收到了新的确认但对方通知的窗口缩小了，使得发送窗口前沿正好不动。 ​ 那么，如果出现了丢包，如何进行重传？这里分两种情况讨论。 情况一：数据包已经抵达，ACK被丢失了 这种情况下，部分ACK丢失了并不要紧，因为可以通过后续的ACK进行确认。 当某一段报文段丢失之后，发送端会一直收到1001这样的ACK，就像是在提醒发送端“我想要的是1001”一样 如果发送端主机连续三次收到了同样一个“1001”这样的应答，就会将对应的数据1001~2000重新发送 这个时候接收端收到了1001之后，再次返回的ACK就是7001了（因为2000~7001接收端其实之前已经就收到了，被放到了接收端操作系统内核的接收缓冲区中） 这种机制也被叫做“高速重发控制”（“快重传”） 根据以上所讨论的，我们还要强调三点： ​ 第一，虽然A的发送窗口是根据B的接收窗口设置的，但在同一时刻，A的发送窗口并不总是和B的接收窗口一样大。这是因为通过网络传送窗口值需要经历一定的时间滞后（这个时间是不确定的）。另外，发送方A还要根据当时的拥塞情况适当的减小自己的发送窗口数值。 ​ 第二，对于不按序到达的数据应如何处理，TCP标准并无明确的规定。如果接收方把不按序到达的数据一律丢弃，那么接收窗口的管理就会比较简单，但这样做对网络资源的利用不利（因为发送方会重复发送较多的数据）。因此TCP通常对不按序到达的数据是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付给上层的应用进程。 ​ 第三，TCP要求接受方必须有累计确认的功能，这样可以减少传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据发送时把确认信息顺便捎带上。但请注意两点：第一，接收方不应过分推迟发送确认，否则会导致发送方不必要的重传，这反而浪费了网络资源。TCP标准规定，确认推迟的时间不应超过0.5秒。若收到一连串具有最大长度的报文段，则必须每隔一个报文段就要发送一个确认。第二，捎带确认实际并不经常发生，因为大多数应用程序不同时在两个方向上发送数据。 流量控制 ​ 接收端处理数据的速度是有限的。如果发送端发的太快，导致接收端的缓冲区被打满，这个时候如果发送端继续发送，就会造成丢包，继而引起丢包重传等一系列连锁反应。因此，TCP支持根据接收端的处理能力，来决定发送端的发送速度，这个机制就叫做流量控制。 ​ 下面通过图示例子说明入户利用滑动窗口机制进行流量控制。 ​ 设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口rwnd = 400”（这里rwnd表示receiver window）。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。TCP连接建立时的窗口协商在图中没有显式出来。再设每一个报文段为100字节长，而数据报文段序号的初始值设为1.请注意，途中箭头上边大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值。 ​ 我们应注意到，接收方的主机B进行了三次流量控制。第一次把窗口减小到rwnd = 300，第二次又减到rwnd=100，最后减到rwnd=0，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发送一个新的窗口值为止。我们还注意到，B向A发送的三个报文段都设置了ACK=1，只有在ACK=1时确认号字段才有意义。 ​ 现在我们考虑一种情况：B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储空间。于是B向A发送了rwnd=400的报文段。然而这个报文段在传送过程中丢失了。A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据。如果没有其他措施，这种互相等待的死锁局面将一直持续下去。 ​ 为了解决这个问题，TCP为每一个连接设有一个持续计时器。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。如果窗口仍是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破。 ​ 接收端如何把窗口大小告诉发送端呢？ ​ 回忆我们的TCP首部中，有一个16位的窗口字段，就是存放了窗口大小信息；那么问题来了，16位数字最大表示65535，那么TCP窗口最大就是65535字节么？实际上，TCP首部40字节选项中还包含了一个窗口扩大因子M，实际窗口大小时窗口字段的值左移M位。（扩大2的M次） 拥塞控制 ​ 虽然TCP有了滑动窗口这个大杀器，能够高效可靠的发送大量的数据。但是如果在刚开始阶段就发送大量的数据，仍然可能引发问题。因为网络上有很多的计算机，可能当前的网络状态就已经比较拥堵。在不清楚当前网络状态下，贸然发送大量的数据，是很有可能雪上加霜的。 ​ 发送方维持一个叫做拥塞窗口cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口（如果再考虑到接收方的接受能力，那么发送窗口还可能小于拥塞窗口）。发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 ​ TCP引入慢启动机制，先发少量的数据探探路，摸清当前的网络拥堵状态，再决定按照多大的速度传输数据。 ​ 慢开始的思路是这样的：当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。经验证明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。 用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。 发送开始的时候，，定义拥塞窗口大小为1； 每次收到一个ACK应答，拥塞窗口加1 每次发送数据包的时候，将拥塞窗口和接收端主机反馈的窗口大小做比较，取较小的值作为实际发送的窗口 像上面这样的拥塞窗口增长速度，是指数级别的。“慢启动”只是指初始时慢，但是增长速度非常快。 为了不增长的那么快，因此不能使拥塞窗口单纯的加倍 此处引入一个叫做慢启动的阈值 当拥塞窗口超过这个阈值的时候，不再按照指数方式增长，而是按照线性方式增长 当TCP开始启动时 ，，慢启动阈值等于窗口最大值 在每次超时重发的时候，慢启动阈值会变成原来的一半，同时拥塞窗口置为一 ​ 那么发送方又是如何知道网络发生了拥塞呢？我们知道，当网络发生拥塞时，路由器会丢弃分组。少量的丢包，我们仅仅是出发超时重传；大量的丢包，我们就认为网络拥塞。 延迟应答如果接收数据的主机立刻返回ACK应答，这时候返回的窗口可能比较小 1假设接收端缓冲区为1M，一次收到了500K的数据；如果立即应答，返回的窗口就是500K,但实际上可能处理端处理的速度很快，10ms之内就把500K数据从缓冲区消费掉了，在这种情况下，接收端处理还远没有达到自己的极限，即使窗口再放大一些也能处理过来，如果接收端稍微等一会再应答，比如等待200ms再应答，那么这个时候返回的窗口就是1M ​ 一定要记得，窗口越大，网络吞吐量就越大，传输效率就越高。我们的目标是在保证网络不拥塞的情况下尽量提高传输效率 ​ 那么所有的 包都可以延迟应答吗？当然不是的 数量限制：每隔N个包就应答一次 时间限制：超过最大延迟时间就应答一次 具体的数量和超时时间，依操作系统不同也有差异：一般N取2，超时时间取200ms 捎带应答在延迟应答的基础上，我们发现，很多情况下，客户端服务器在应用层也是“一发一收”的，意味着客户端给服务器说了”How are you”，服务器也会给客户端回一个“Fine”，那么这个时候ACK就可以搭顺风车，和服务器回应的“Fine”一起回给客户端 面向字节流创建一个TCP的socket，同时在内核中创建一个“发送缓冲区”和“接收缓冲区” 调用send/write时，数据会先写入发送缓冲区中 如果发送的字节数太长，会被拆分成多个TCP的数据包发出 如果发送的字节数太短，就会先在缓冲区里等待，等到缓冲区长度差不多了，或者其他合适的时机发送出去 接收数据的时候，数据也是从网卡驱动程序到达内核的接收缓冲区 然后应用程序可以调用read从接收缓冲区拿数据 另一方面，TCP的一个连接，既有发送缓冲区，也有接收缓冲区。那么对于这一个连接，既可以读数据，也可以写数据。（全双工） 由于缓冲区的存在，TCP程序的读和写不需要一一匹配，例如： 写100个字节数据时，可以调用一次write写100个字节，也可以调用100次write每次写一个字节 读100个字节数据时，也完全不需要考虑写的时候是怎么写的，既可以一次read100个字节，也可以重复read100次，一次read一个字节 粘包问题​ 首先明确一点，粘包问题中的“包”，是指应用层的数据包。在TCP的协议头中，没有如同UDP一样的“报文长度”这样的字段，但是有一个序号这样的字段。站在传输层的角度，TCP是一个一个报文过来的，按照序号排好序放在缓冲区中。站在应用层的角度，看到的只是一串连续的字节数据，那么应用程序看到了这么一串字节数据就不知道从哪个部分开始到哪个部分，是一个完整的应用层数据包。 ​ 那么如何避免粘包问题呢？明确两个包之间的边界！！！ 对于定长的包，保证每次都按固定大小读取即可 对于变长的包，可以在包头位置，约定一个包总长度的字段，从而就知道了包的结束位置 对于变长的包，还可以在包和包之间使用明确的分隔符（应用层协议，是程序员自己定的）]]></content>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统之进程]]></title>
    <url>%2F2019%2F01%2F03%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[这一章我们主要介绍进程的状态，了解进程的状态有助于我们分析进程在系统中的各种作用等。进程的调度算法，进程的调度算法可以让我们看到内核是如何设计出一套注重效率并且兼顾公平的算法，内核如何为不同的进程分配资源等，帮助我们加深对于进程相关知识的了解。 进程的状态首先我们要知道进程虽然是占有CPU资源的可是就像人不能一直工作一样，进程也不能一直占用CPU资源，同时我们还要考虑并发问题等，具体原因有： 1.进程可能需要等待某种外部条件的满足，在满足条件之气那无法继续执行，在这种情况下占用CPU是对资源的浪费 2.linux是多用户多任务的操作系统，可能同时存在多个可以运行的进程，进程个数可能远远多于CPU个数，一个进程始终占有CPU对于其他进程来说不公平 3.linux支持软实时，实时进程的优先级高于普通进程，实时进程之间也有优先级的差别，软实时进程进入可运行状态的时候，可能会发生抢占，抢占当前运行的进程。 接下来我们具体说一下进程的状态，进程的状态一共有七种： 12345678910111213141516171819202122232425262728293031323334353637383940414243可运行状态 首先是可运行状态，这个状态不一定占用CPU资源，这个状态细分可以分成两个状态，正在运行与准备状态，处于准备状态意味随时可以运行，只不过由于CPU资源有限暂时没有运行 处于可运行状态的进程是进程调度的对象，如果进程并不处于可运行状态，进程调度就不会选择它投入运行，在Linux中每一个CPU都有它的运行队列，事实上还不止一个，根据调度类别不同可运行状态的进程位于不同的队列，如果是实时进程落入实时调度类的队列中，普通进程落入公平调度类的队列中，这样进程调度器就可以根据一定的算法从运行队列上挑选合适的进程来使用CPU资源 处于可运行状态的进程可能正在执行用户态的代码（比如计算排序等），也有可能在执行内核态的代码（类似IO等）Linux的time命令统计了三种时间，分别是实际时间，用户CPU实际以及系统CPU时间，其中最让我们产生误会的是很多人误以为 实际时间就等于用户CPU时间加系统CPU时间。 其实比如我们要是多核处理的话后者总和就会大于前者，要是我们一直陷入阻塞的话就会产生前者大于后者总和，我们根据这种时间分配分为计算密集型进程与IO密集型进程，前者是充分利用了多处理器并行的优势，后者多核并行优势并不明显。 可中断睡眠状态与不可中断睡眠状态 进程不是总处于可运行状态的，有的进程需要与慢设备打交道，比如进程和磁盘进行交互，相关的系统调用消耗的时间是非常长的，进程需要等待这些操作完成才能执行下来的指令。 在这种情况下占用CPU资源就很浪费了，所以这个时候内核将进程的状态改变为其他状态，将其从CPU的运行队列中移除，同时调度器选择其他的进程来使用CPU资源。 LINUX有两种睡眠状态，可中断睡眠与不可中断睡眠状态，可中断睡眠是指在睡眠中可以被唤醒，其中两种方式可以唤醒可中断睡眠，当收到没有被屏蔽的信号的时候会唤醒，当等待的事情发生了也会被唤醒，可是对于不可中断睡眠来说，只有一种情况就是等待的事情发生了才会醒来，不然就会一直陷入等待，KILL信号也不能将他唤醒。 很多人认为在vfork创建子进程的时候，子进程调用exec函数或退出之前，父进程始终处TASK_UNINTERRUPTIBLE状态，其实这个说法是错误的，因为很明显，父进程可以轻易的被信号杀死，这证明并不是处于不可中断睡眠状。 TASK_KILLABLE状态 事实上在内核2.6.25版本引入了一种新的状态即TASK_KILLABLE状态，这个状态是可中断睡眠与不可中断睡眠的综合版本，除了杀死这个进程的信号要进行唤醒处理之外，其他的信号一概不管。 等待队列 进程无论是哪一种睡眠状态，有一个数据结构是绕不开的，那就是等待队列，单反进程要进行休眠，必然是等待某个资源或者某个事件，内核必须想办法将进程和它等待的资源关联起来，当等待的资源可用或等待的事件已经发生的时候，可以及时的唤醒相关进程，内核采用的办法是等待队列 内核用双向链表来表示等待队列，每一个等待队列都可以用等待队列头来标识，内核中提供了wait_queue和add_queue_exclusive两个函数来吧等待队列元素添加到等待队列头部的双向链表 可是这里有一个新的问题： 如果存在多个进程在等待同一个满足条件或同一个事件发生，那么当条件满足的时候，应该吧所有进程一并唤醒还是只唤醒一个或几个进程呢。 应该是具体问题具体分析，有的时候我们需要唤醒所有进程，有的时候我们只足够一个进程来获取资源，可是我们要是全部唤醒的话就会发生除了获取到资源的进程外其他资源被唤醒后再次进入睡眠这个也被叫做惊群效应。 暂停状态与跟踪状态 暂停状态是一种较为特殊的状态，暂停后不能安装新的信号处理函数，直到收到CIGCONT后才会继续执行程序。 跟踪状态是指进程会停下来等待跟踪他的进程的操作，比如我们gdb调试的时候加断点就会进入暂停 僵尸状态与死亡状态 严格来说这不是进程的状态，进程与程序的区别就在于进程是正在被执行，而这两种都已经死亡，僵尸状态我们以前提过就是子进程退出后内核发送SIGCLD信号给父进程，父进程要是默认忽略没有等待子进程那么子进程的部分信息没办法进行回收子进程就会进入僵尸状态，死亡状态时间非常短，进程退出的时候就会进入死亡状态，我们一般观察不到。 进程调度设计原则进程调度是任何一个现代擦欧总系统都要解决的问题，也是我们这篇博客的重点，首先我们要从知道只有TASK_RUNNING状态的进程才可以进入调度队列被调度。 Linux是多任务的操作系统，多任务操作系统可以分为两类：抢占式和非抢占式，在非抢占式的操作系统中只有一个进程自己主动退出让出CPU的使用权其他进程才可以使用CPU，所以非抢占式也被叫做合作型多任务。 可是对于操作系统设计进程调度来说，合作型多任务没有优先级的概念，很多需要立即执行的进程反而长时间陷入等待，所以大多数操作系统是抢占式的，Linux也不例外，抢占式多任务由操作系统来决定进程调度，对于操作系统来说，面对不同类型的进程设计一个全面考虑的调度算法是很不容易的。 他要做到以下的几点： 12345678910111213141516171819公平:每一个进程都可以获得调度的机会，不能出现长时间不被调度的情况 良好的调度延迟：尽量确保进程在一定的时间范围内，总可以获得调度的机会 差异化：允许重要的进程获得更多的执行时间 支持软实时机制：软实时进程比普通的进程有更高的优先级 负载均衡：多个CPU要分配均衡，不能出现一些很闲一些很忙的情况 高吞吐量：单位时间内处理的进程个数尽可能多 简单高效：调度算法要高效，不能在调度上花费太多时间 目前Linux采用的是每个CPU都有自己的运行队列，每个CPU去自己的运行队列中选择进程，这样就可以降低竞争，这种方案还有一个好处就是缓存重利用。 某个进程位于它所属CPU的运行队列中，经过多次调度之后，内核区域选择相同的CPU去执行该进程，这种情况上次运行的变量很可能仍然处于CPU的缓存之中，提升了效率。 可是这样有一个问题，可能会负载不均衡，出现有的CPU的运行队列中有很多进程而有的CPU运行队列中没有进程的情况，为了解决这个问题，Linux提出了load_balance，它的作用就是在一定时机下，通过将任务从一个CPU的运行队列迁移到另一个CPU的运行队列中，实现负载均衡。 那么进程调度具体是干了些什么呢，其实说白了就是挑选下一个执行的进程，如果下一个被调度的进程和当前进程不是一个进程，就执行上下文切换。 Linux是抢占式内核，从内核2.6开始不仅支持用户态抢占，也支持内核态抢占，可抢占内核的优势在于何以保证系统的响应时间，当高优先级任务一旦就绪，总能及时得到CPU的控制权，但是很明显，内核抢占不能随意发生，某些情况下不能发生内核抢占，为了可以确定什么时候可以发生抢占，内核为每一个进程引入了一个preempt_count计数器，数值为0表示可以发生抢占，数值为1代表不能发生抢占。 preempt_count设置了很重要的一个标志位，即PREEMAT_ACTIVE，该标志为用来标记是否正在发生内核抢占，设置了之后就代表preempt_count不再为0，同时不允许再次抢占，PREEMAT_ACTIVE有一个很重要的作用就是设置了这个标志位的进程那么即使不处于RUNNING状态内核也不能将他从运行队列中剔除。 因为有一种情况是当前占用CPU的进程刚刚将自己设置为睡眠状态并且打算等待信号，可是这个时候发生了抢占，这个时候他就已经不是运行状态了，按道理说要将它从运行队列中剔除，可是如果我们真的剔除了那么他将永远睡眠再也不会醒来。正确的做法是将他再次放入运行队列，他就还有机会操作CPU资源就还有机会被唤醒。 调度类在选择下一个占用CPU的进程之前，内核会先根据调度类来更些一些数据，用来保证下一个调度的优先级最高。linux下一共有下面几种调度类： 12345671.stop_sched_class 停止类 2.rt_sched_classs 实时类 3.fair_sched_classs 完全公平调度类 4.idle_sched_classs 空闲类 这四种调度类是根据优先级顺序排布的，停止类具有最高的优先级，与之对应的空闲类有最低的优先级，挑选下一个进程的时候就先从停止类里面选择，没有的话从实时类选，以此类推。 ​ 优先级最高的停止类进程，主要用户多个CPU之间的负载均衡和CPU的热拔插，他所作的事情就是停止正在运行的CPU，以进行任务的迁移或拔插CPU，优先级最低的空闲类负责将CPU置于停机状态，直到中断将其唤醒，这两种类都是为了实现CPU调度性能的功能类，真正和应用层有关系的是实时类和完全公平调度类。 普通进程的优先级除非Linux用在一些特殊领域，不然Linux上的进程都是完全公平调度类，Linux是多任务系统，系统不能让一个进程始终占据CPU资源，那么如何给每一个进程分配多大的时间片就是一个很值得思考的问题。 ​ Linux实现完全公平调度类使用了一种动态时间片的算法，他给每一个进程分配使用CPU的时间比例，进程调度设计上，有一个很重要的指标是调度延迟，也就是保证每一个可运行的进程都至少运行一次的时间间隔。 ​ 比如我们调度延迟是20毫秒，正在运行的进程一共两个，那么每一个进程运行的时间片就是10毫秒，调度延迟可以让每一个进程都有机会占用CPU进程，可是产生了新的问题，要是我们的调度延迟是10毫秒但是正在运行的进程100个的话，那么根据调度延迟来说每一个进程只能分0.1毫秒的时间片，这显然什么都干不了。 ​ 为了应对这种情况，完全公平调度提供了另一种调度方法，调度最小颗粒，这个就是说任意进程所运行的时间片都有一个基准的最小值，不能小于这个最小值，对于这两种调度方法，进程规定了一个最大活动进程数目，最大活动数目等于调度延迟除以调度颗粒。 ​ 也就是说当当前进程个数小于最大活动数的时候，分得的时间片大于最小颗粒，就用延迟调度，当进程个数太多导致大于最大活动数的时候，分得的时间片小于调度最小颗粒，就按照调度最小颗粒的值来指定时间片。 ​ 到目前为止，我们所有的讨论都基于运行对立额上所有的进程都有相同的优先级，可是事实并非如此，有些任务的优先级高，理应获得更多的运行时间，考虑到这种情况，完全公平调度又引入了优先级的概念。 ​ 完全公平调度是通过引入调度权重来实现优先级的进程之间按照权重的比例，分配CPU时间，分配给进程的运行时间=调度周期*进程权重/运行队列所有进程权重之和。 ​ Linux下每一个进程都有一个nice值，该值的取值范围是[-20，19]nice值越高代表优先级越低，默认的优先级是0. weight=1024/（1.25^nice_value）。 普通进程的组调度1假如一个运行队列上一共有四个进程，这四个进程优先级相同，那么根据调度延迟以及调度最小颗粒，每一个进程分25%的时间片，可是如果其中三个进程是A组的，最后一个进程是B组的那么就会造成A组分得了大量的时间片而B组分的很少的情况，针对这种情况，内核先实现组间平衡，再实现组内平衡，也就是说B组的进程最后可以分得50%的时间片而A组的三个进程各自分得16.7%的时间片。 实时进程的调度​ 对于普通进程来说，完全公平调度已经可以实现足够好的性能以及响应体验了，但是对于实时性要求更高的进程来说还是不够，严格来说实时系统可以分为两类，硬实时进程和软实时进程，硬实时进程对于响应时间的要求非常严格，必须保证在一定的时间内完成超出相应事件就会失败并且有很严重的后果，比如军用武器系统，航空航天系统里面就很多硬实时进程。 ​ 软实时是硬实时的弱化版本，虽然也要求响应时间，可是超出了规定时间并不会有很严重的后果，比如视频处理，撑死影响用户体验，发生视频丢帧什么的（虽然我觉得视频丢帧也超级重要）。 实时调度策略与优先级Linux针对实时调度类也提供了两种调度策略，先进先出与时间片轮转策略，无论你使用哪一种策略都会高于前面的公平调度进程。 在linux中一共提供了140个优先级等级，0到99都是属于实时调度类的，100到139是属于完全公平调度类的，完全公平调度类的初始值就是120，所以我们知道不管如何调整nice值也不会使它跨类。 内核为这99个等级维护了99个队列，当要选下一个进程的时候就挨个去这些队列里边找，同时内核还用一个位图来表示哪个队列有运行的程序。 先进先出的调度策略没有时间片的概念，只要没有更高优先级的进程就绪，那么就会一直执行当前最高优先级的进程，除非自动放弃CPU资源或者进程终止。 时间片轮转的调度策略就是在当前相同优先级的优先级队列中所有进程平分时间片。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基础（一）]]></title>
    <url>%2F2018%2F11%2F30%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[数据传输（ (不)同主机上的进程间同信）协议：(通信双方的一个数据格式协议)网络中主机之间进行通信也必须使用相同的协议（相同的一个光电信号格式） 计算机如何传播数据—-光电波信号在网络中因为主机设备的生产厂商很多，每个厂商如果都使用自己的协议进行通信，那么将导致网络上主机间无法正常通信，于是设计了一个标准的协议 网络间的数据传输就必须使用同一个标准协议 ——-网络通信协议 在网络通信中，因为应对场景各有不同，因此协议也相对特别复杂，为了使用起来更加方便，因此就有了协议的封装/分层。 协议的封装/分层：按照各个协议的不同功能以及不同的应对场景对不同的协议进行了分层，在特定的环境下如果协议的分层清晰明了，那么使用/替换起来就更加方便 OSI网络互联七层参考模型：优点：1.将服务，接口和协议明确区分开来 应用层 表示层 会话层 传输层 网络层 数据链路层 物理层 TCP/IP五层模型：TCP/IP五层模型：TCP/IP指的是一个协议簇，因为TCP协议和IP协议是最典型的两个协议，因此这个协议簇就拿这两个协议名字进行命名了 应用层 :负责应用程序间的数据沟通 http/https ftp 传输层（内部完成）：负责端与端之间的数据传输（进程与进程间）TCP/UDP 网络层:负责地址管理和路由选择 IP (路由器) 数据链路层:负责相邻设备节点间的数据传输 以太网协议 交换机 物理层：负责光电信号的传输 以太网协议 集线器 数据的传输流程：1.不同的协议层对数据包有不同的称谓，在传输层叫做段，在网络层叫做数据报，在链路层叫做帧 2.应用层数据通过协议栈发到网络上时，每层协议都要加上一个数据首部，称为封装 3.首部信息中包含了一些类似于首部有多长，载荷有多长，上层协议是什么等信息 4.数据封装成帧后发到传输介质上，到达目的主机后每层协议再剥掉相应的首部，根据首部中的“上层协议字段”将数据交给对应的上层协议处理 套接字编程——–原始的网络socket编程IP地址：唯一定位网络上的主机（无符号四个字节的整数——uint32_t） 端口：标识一台主机上的进程（无符号两个字节的数据 uint16_t ,0~65535） 进程的标识为什么不用PID？ 因为PID会随着进程的创建改变的 sip+sport+dip+dport+proto 五元组 网络字节序：大小端 大端字节序：低地址存高位 0x01 02 03 04 uchar buf[4] 01 02 03 04 小端字节序：低地址存低位 uchar buf[4] 04 03 02 01 所以不同字节序主机之间进行数据传输，将造成数据的逆序，也就是得不到人家真正发送的数据。因此，约定了在网络间进行通信时必须使用大端字节序—-网络字节序，也就意味着如果我们的主机时小端字节序，那么通信时就需要对数据逆序，但是并不是所有数据都需要逆序，主要针对在内存中存储时，占据字节大于1个字节的数据（short,int,float,double,long等,针对这些类型的是数据，因为在内存中的存储跟展示顺序刚好相反，而发送时按字节发送对方按字节接收，那么如果对方时大端，因为低地址存高位，因为存储顺序和使用顺序完全相同，导致数据跟实际想发送的数据顺序刚好相反，因此需要进行字节逆序转换） 主机字节序：当前主机的字节序—–大小端不一定，取决于CPU的架构 x86（小端） MIP5（大端） RISC-V 网络套接字编程：（主要说的时传输层的TCP/UDP） 因为传输层有两个传输协议，所以必须选择其一进行数据传输，那么如何选择？ 答：TCP：面向连接，可靠传输，字节流服务 优点：可靠传输，并且传输灵活 缺点：传输速度低，数据粘包 UDP：无连接，不可靠，面向数据报 优点：传输数据快，无粘包 缺点：不可靠 针对数据安全性要求高的场景（文件传输）：使用TCP保证数据的可靠 安全性要求不是很高但是实时性要求高的场景（视频传输）：使用UDP保证传输速度 socket套接字编程： 网络编程涉及到对网卡的操作，因此操作系统就提供了一套接口—socket接口 网络编程中分了两个端：客户端程序和服务端程序（在网络编程中，客户端是主动的一方，并且客户端必须知道服务端的地址信息ip+port，而服务端需要在这个指定的地址等着） UDP编程步骤： 服务端： 创建套接字（建立网卡与进程之间的关系） 为套接字绑定地址信息（声明去网卡接收数据时找所需要的正确数据） 接收/发送数据 关闭套接字 客户端：创建套接字 ​ 绑定（由操作系统自己完成，不主动绑定） ​ 发送/接收数据 ​ 关闭套接字 服务端必须绑定地址，因为服务端是被动的一端，必须告诉别人需要将数据发送到哪个地址哪个端口，因此自己就必须接收这个地址这个端口的数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980811.int socket(int domain, int type, int protocol);domain：地址域 AF_INET IPV4type：套接字类型SOCK_STREAM 流式套接字 TCPSOCK_DGRAM 数据报套接字 UDPpro： 协议类型IPPROTO——TCP 6 TCP协议IPPROTO——UDP 17 UDP协议 返回值：非负整数（套接字描述符） 失败：-12.int bind(int sockfd, const struct sockaddr *addr,socklen_t addrlen);sockfd：套接字描述符addr：地址信息addrlen：地址信息长度返回值：成功：0 失败：-1uint16_t htons(uint16_t hostshort);将一个短整型（16位）数据从主机字节序转换成网络字节序in_addr_t inet_addr(const char *cp);将点分十进制的字符串IP地址转换为网络字节序的地址INADDR_ANY：只能用于服务端（0.0.0.0）3.ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);sockfd：套接字描述符buf：要发送的数据len：发送的数据长度flags：发送标志 一般给0，默认阻塞MSG_PEEK 接收数据后数据不会立即从缓冲区删除场景：探测型获取数据src_addr：发送端的地址信息addrlen：地址信息长度返回值：实际读取到的字节长度assign：从一个字符串中拷贝指定长度的数据到string中ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen);sockfd：套接字描述符buf：要发送的数据len：发送的数据长度flags：发送标志 一般给0，默认阻塞dest_addr：数据要发送到的对端地址信息addrlen：地址信息长度返回值：实际发送的数据长度 失败：-14.close(sockfd) 关闭套接字释放资源]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深浅拷贝]]></title>
    <url>%2F2018%2F11%2F26%2F%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[对象之间可以进行复制操作，包括采用拷贝构造函数的方式用一个对象去构造另一个对象（用一个对象的值初始化一个新的构造的对象），如同指针的复制一样，对象复制也分为浅复制和深复制 对象浅拷贝： 两个对象之间进行复制时，若复制完成后，他们还共同使用着某些资源（内存空间），其中一个对象的销毁会影响另一个对象（动态顺序表） 如果没有显式提供拷贝构造函数与赋值运算符重载，编译器会生成一个默认的拷贝构造函数和运算符重载（默认为位的拷贝，将一个对象中的内容原封不动的拷贝到到另一个对象中。如果类中涉及到资源管理，则会使得多个对象在底层共用同一块资源，在销毁对象时，就会导致一份资源释放多次引起程序崩溃） 如果一个类中涉及到资源，该类必须显式提供拷贝构造含糊，赋值运算符重载函数，析构函数 //类似系统生成的默认拷贝构造函数的方式 ​ //值的拷贝方式—–内存的拷贝 ​ //后果：多个对象共用同一份资源，在销毁时同一份资源被释放多次而引起程序的崩溃 12345String(const String&amp; s) :str(s.str) //当前对象的指针和s里的字符串共用同一段空间 &#123;&#125; ​ 对象深拷贝： 当两个对象之间进行复制时，若复制完成后，它们不会共享任何资源（内存空间），其中一个对象的销毁不会影响另一个对象 ​ 123456789String(const String&amp; s) :str(new char[strlen(s.str) + 1]) //先分配一段空间 &#123; strcpy(str,s.str); &#125; 此时查看监视，发现s1与s2地址空间并不一样，不会产生内存泄露问题，也可以正常析构销毁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404#include&lt;assert.h&gt;#include&lt;iostream&gt;using namespace std;#if 0 浅拷贝问题的String类class String&#123;public: String(const char* str = &quot;&quot;) //创建空的字符串 &#123; //assert(str); //断言检测是否为空 if(nullptr == str) str = &quot;&quot;; //如果为空那么就当作空字符串 _str = new char[strlen(str) + 1]; strcpy(_str,str); /* if(nullptr == str) &#123; //_str = new char //分配一个字节的空间,但在下边析构时需要与delete匹配起来使用，为了方便，将其设为以下形式 _str = new[1] char; *_str = &quot;\0&quot; &#125; else &#123; _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; */ &#125; //类似系统生成的默认拷贝构造函数的方式 //值的拷贝方式-----内存的拷贝 //后果：多个对象共用同一份资源，在销毁时同一份资源被释放多次而引起程序的崩溃 String(const String&amp; s) :_str(s._str) //当前对象的指针和s里的字符串共用同一段空间 &#123;&#125; //类似系统生成的默认的赋值运算符重载的方式 //问题：1.内存泄露 // 2.与拷贝构造函数类似 String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; _str = s._str; return *this; &#125; &#125; ~String() &#123; if(_str) //判断是否有空间 &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str;&#125;;void TestString()&#123; String s1(&quot;hello&quot;); String s2(s1); //用s1拷贝构造s2，因为没有自己给出拷贝构造函数，系统会默认使用类生成的拷贝构造函数进行值的拷贝（浅拷贝）,销毁期间会对一段资源销毁两次产生程序而崩溃 String s2 = s1; //此时会看到s2本身有一个地址空间，但是在赋值时完全将s1中的东西拷贝，使得s2本来的空间找不到了，产生内存泄漏&#125;#endif#if 0使用深拷贝进行处理 传统方式class String&#123;public: String(const char* str = &quot;&quot;) //创建空的字符串 &#123; //assert(str); //断言检测是否为空 if(nullptr == str) str = &quot;&quot;; //如果为空那么就当作空字符串 _str = new char[strlen(str) + 1]; strcpy(_str,str); /* if(nullptr == str) &#123; //_str = new char //分配一个字节的空间,但在下边析构时需要与delete匹配起来使用，为了方便，将其设为以下形式 _str = new[1] char; *_str = &quot;\0&quot; &#125; else &#123; _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; */ &#125; String(const String&amp; s) :_str(new char[strlen(s._str) + 1]) //先分配一段空间 &#123; strcpy(_str,s._str); &#125; String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; /* 释放旧空间，开辟新空间，再进行字符串拷贝 delete[] _str; //因为先释放了原来空间，如果开辟新空间失败了，那么会造成影响 _str = new char[strlen(s._str) + 1]; strcpy(_str,s._str); */ char* pStr = new char[strlen(s._str) + 1]; strcpy(_str,s._str); delete[] _str; //释放掉旧空间 _str = pStr; &#125; return *this; &#125; ~String() &#123; if(_str) //判断是否有空间 &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str;&#125;;void Test()&#123; String s1(&quot;hello&quot;); String s2(s1);&#125;int main()&#123; Test(); return 0;&#125;#endif#if 0现代版写法，代码较简洁class String&#123;public: String(const char* str = &quot;&quot;) //创建空的字符串 &#123; if(nullptr == str) str = &quot;&quot;; //如果为空那么就当作空字符串 _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; String(const String&amp; s)//注意！本编译器下此时_str没有进行初始化，放的是一个随机值，所以在释放strTemp时出错，所以需要给一个初始值 :_str(nullptr) &#123; String strTemp(s._str); swap(_str,strTemp._str); &#125; /* String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; String strTemp(s); swap(_str,strTemp._str); &#125; return *this; //当前对象用的是临时对象的空间，出了作用域销毁临时对象，实际是将当前对象的地址空间释放了 &#125; */ String&amp; operator=(String s) &#123; swap(_str,s._str); return *this; &#125; ~String() &#123; if(_str) //判断是否有空间 &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str;&#125;;void Test()&#123; String s1(&quot;hello&quot;); String s2(s1); String s3; s3 = s2; //此时实际是临时对象给s3赋值的&#125;int main()&#123; Test(); return 0;&#125;#endif#if 0class String&#123;public: String(const char* str = &quot;&quot;) &#123; if(nullptr == str) str = &quot;&quot;; _str = new char[strlen(str) + 1]; strcpy(_str,str); _count = 1; &#125; String(String&amp; s) :_str(s._str) ,_count(++s._count) &#123;&#125; ~String() &#123; if(0 == --_count &amp;&amp; _str) &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str; int _count; //每个对象中均有一份，一个对象修改了其他对象不知道&#125;;#endif/*static也不可以，是类中所有对象共享的class String&#123;public: String(const char* str = &quot;&quot;) &#123; if(nullptr == str) str = &quot;&quot;; _str = new char[strlen(str) + 1]; strcpy(_str,str); _count = 1; &#125; String(String&amp; s) :_str(s._str) &#123; ++_count; &#125; ~String() &#123; if(0 == --_count &amp;&amp; _str) &#123; delete[] _str; _str = nullptr; &#125; &#125;private: char* _str; static int _count; //所有对象共享的，但资源有可能会有多分，每调用一次构造就将_count置为1了，不能针对多份资源，如 String s3;&#125;;int String::_count = 0;void Test()&#123; String s1(&quot;hello&quot;); String s2(s1); String s3; //此时会出现问题，到这里时_count重新被置为1，导致只能将s3释放而无法释放s1和s2&#125;int main()&#123; Test(); return 0;&#125;*/#if 0//写时拷贝（COW copy on write）:浅拷贝+引用计数+在向对象写内容时，是否需要给当前对象独立空间class String&#123;public: String(const char* str = &quot;&quot;) :_pCount(new int(1)) &#123; if(nullptr == str) str = &quot;&quot;; _str = new char[strlen(str) + 1]; strcpy(_str,str); &#125; String(String&amp; s) :_str(s._str) ,_pCount(s._pCount) &#123; ++*(_pCount); &#125; String&amp; operator=(const String&amp; s) &#123; if(this != &amp;s) &#123; if(0 == --(*_pCount) &amp;&amp; _str) //检测拷贝以后自己的资源需不需要释放 &#123; delete[] _str; _str = nullptr; delete _pCount; _pCount = nullptr; &#125; //与被拷贝的资源共享资源 _str = s._str; _pCount = s._pCount; //新资源计数+1 ++(*_pCount); &#125; return *this; &#125; char&amp; operator[](size_t index) //返回引用是因为有可能返回后作为左值 &#123; if(*_pCount &gt; 1) &#123; String str(_str); this-&gt;Swap(str); &#125; return _str[index]; &#125; const char&amp; operator[](size_t index)const &#123; return _str[index]; &#125; ~String() &#123; if(0 == --(*_pCount) &amp;&amp; _str) &#123; delete[] _str; _str = nullptr; delete _pCount; _pCount = nullptr; &#125; &#125; void Swap(String&amp; s) &#123; swap(_str,s._str); swap(_pCount,s._pCount); &#125;private: char* _str; int* _pCount; &#125;;void Test()&#123; String s1(&quot;hello&quot;); String s2(s1); String s3; //s3 = s1; s1 = s3; s1[0] = &apos;H&apos;; //此时一改变会全改变，s1,s2,s3共用一份资源&#125;int main()&#123; return 0;&#125;#endif]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板]]></title>
    <url>%2F2018%2F11%2F19%2F%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[如何实现一个通用的函数呢？（如针对不同的参数类型均可） 在平时的编程中，如何实现一个通用的函数呢？ 首先想到的就是使用函数重载，但是这样一来会有几个不好的地方： 重载的函数仅仅只是类型不同，代码的复用率比较低，只要有新类型出现时就需要增加对应的函数 代码可维护率比较低，一个函数出错就有可能所有的重载都出错 那么有没有一种方式，使得编译器可以根据不同的类型来利用该模子来生成代码呢？ 答案是有的——泛型编程，也就是一种编写与类型无关，与使用场景无关的通用代码，使得代码可以复用的手段，而模板则是泛型编程的基础 模板：模板是C++支持参数化多态的工具，使用模板可以使用户为类或者函数声明一种一般模式，使得类中的某些数据成员或者成员函数的参数、返回值取得任意类型。 模板是一种对类型进行参数化的工具； 通常有两种形式：函数模板和类模板； 函数模板针对仅参数类型不同的函数； 类模板针对仅数据成员和成员函数类型不同的类。 使用模板的目的就是能够让程序员编写与类型无关的代码。比如编写了一个交换两个整型int 类型的swap函数，这个函数就只能实现int 型，对double，字符这些类型无法实现，要实现这些类型的交换就要重新编写另一个swap函数。使用模板的目的就是要让这程序的实现与类型无关，比如一个swap模板函数，即可以实现int 型，又可以实现double型的交换。模板可以应用于函数和类。下面分别介绍。 注意：模板的声明或定义只能在全局，命名空间或类范围内进行。即不能在局部范围，函数内进行，比如不能在main函数中声明或定义一个模板。 函数模板是一个函数家族，与类型无关，使用时才被参数化，根据实参类型产生函数的适用版本 函数模板格式template //模板参数列表 可以使用template ，不可以使用struct T1 _Add(T1 left,T2 right) //函数模板 { ​ return left + right; } 实例化：隐式实例化：编译器根据实参推演模板参数的实际类型 显示实例化：函数名和后加&lt;&gt;指定参数实际类型 匹配原则：1.优先调用自己写的模板函数 2.模板函数不允许自动类型转换，普通函数可以自动类型转换 1234567891011121314151617181920212223242526272829303132333435363738394041#pragma once#include&lt;assert.h&gt;#include&lt;iostream&gt;using namespace std;//不是一个真正的函数template&lt;class T&gt; //模板参数列表 可以使用template&lt;typename T&gt; ，不可以使用struct T _Add(T left,T right) //函数模板&#123; return left + right;&#125;template&lt;class T&gt;void PrintfArray(T array,int size) //数组会自己转换类型&#123; cout&lt;&lt;typeid(array).name() &lt;&lt;endl; int i = 0; for(i=0;i&lt;size;i++) &#123; cout&lt;&lt; array[i] &lt;&lt; " "; cout&lt;&lt;endl; &#125;&#125;int main()&#123; int array[] = &#123;1,2,3,4,&#125;; char str[] = "hello"; PrintfArray(array,sizeof(array)/sizeof(int)); PrintfArray(str,strlen(str)); //隐式实例化---不会进行隐式的类型转化，需要用户自己来强转/ cout&lt;&lt; _Add(1,2) &lt;&lt;endl; //根据实参类型来进行类型推演生成处理具体类型的函数 cout&lt;&lt; _Add(1,(int)2.0) &lt;&lt;endl; //但是面对参数为不同类型时无法判断如何输出，需要对参数进行处理，如强转类型 //显式实例化 _Add&lt;int&gt;(1,2.2); _Add&lt;&gt;(1,2); //隐式实例化 return 0;&#125; 用模板写list类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151template&lt;class T&gt;class Seqlist&#123;public: Seqlist(int capacity = 10) :_Data(new T[capacity]) ,_capacity(capacity) ,_size(0) &#123;&#125; //拷贝构造：Seqlist(const Seqlist&lt;T&gt;&amp; s); //赋值运算符重载：Seqlist&lt;T&gt;&amp; operator = (const Seqlist&lt;T&gt;&amp; s) void PushBack(const T&amp; data) &#123; _CheckCapacity(); _Data[_size++] = data; &#125; void PopBack() &#123; if(_size != 0) --_size; &#125; //访问任意位置 T&amp; operator[](size_t index) //可能会修改s[i]中的元素 &#123; assert(index &lt; _size); return _Data[index]; &#125; //因为const类型的对象不能调用普通函数，这里是const对象访问 const T&amp; operator[](size_t index) const &#123; assert(index &lt; _size); return _Data[index]; &#125; //访问第一个元素 T&amp; Front() &#123; return _Data[0]; &#125; const T&amp; Front()const &#123; return _Data[0]; &#125; //访问最后一个元素 T&amp; Back() &#123; return _Data[_size-1]; &#125; const T&amp; Back()const &#123; return _Data[_size-1]; &#125; size_t Size() const &#123; return _size; &#125; size_t Capacity() const &#123; return _capacity; &#125; void Clear() &#123; _size = 0; &#125; ~Seqlist();private: void _CheckCapacity() &#123; if(_size == _capacity) &#123; size_t newCapacity = (_capacity&lt;&lt;1); //申请空间 T* Temp = new T[newCapacity]; //拷贝元素 memcpy(Temp,_Data,_size*sizeof(T)); //释放旧空间 delete[] _Data; //替换新空间 _Data = Temp; _capacity = newCapacity; &#125; &#125;private: T* _Data; size_t _capacity; size_t _size;&#125;;template&lt;class T&gt;Seqlist&lt;T&gt;::~Seqlist()&#123; if(_Data) &#123; delete[] _Data; _Data = nullptr; _capacity = 0; _size = 0; &#125;&#125;void TestSeqlist()&#123; Seqlist&lt;int&gt; s1; Seqlist&lt;double&gt; s2; Seqlist&lt;char&gt; s3; s1.PushBack(1); s1.PushBack(2); s1.PushBack(3); s1.PushBack(4); s1[0] = 6; cout&lt;&lt; s1.Size()&lt;&lt;endl; cout&lt;&lt; s1.Front()&lt;&lt;endl; cout&lt;&lt; s1.Back()&lt;&lt;endl; s1.Clear(); cout&lt;&lt;s1.Size()&lt;&lt;endl;&#125;#include&lt;string&gt;void Test()&#123; Seqlist&lt;string&gt; s; s.PushBack("0000"); s.PushBack("1111"); s.PushBack("2222"); s.PushBack("3333"); s.PushBack("4444"); s.PushBack("5555"); s.PushBack("6666"); s.PushBack("7777"); s.PushBack("8888"); s.PushBack("9999");&#125;int main()&#123; //TestSeqlist(); Test(); return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态内存管理]]></title>
    <url>%2F2018%2F11%2F15%2F%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[父子进程之SIGCHLD]]></title>
    <url>%2F2018%2F11%2F11%2F%E7%88%B6%E5%AD%90%E8%BF%9B%E7%A8%8B%E4%B9%8BSIGCHLD%2F</url>
    <content type="text"><![CDATA[​ 在用wait和waitpid函数处理僵尸进程时，父进程可以阻塞等待子进程结束，也可以非阻塞的查询是否有子进程结束等待处理。但是，第一种方式父进程阻塞了就不能处理自己的工作了，而第二种父进程在处理自己的工作时还需要时不时的轮询一下，使得程序变得复杂。而在子进程终止时，会给父进程发送SIGCHLD信号，该信号的默认处理是忽略，父进程可以自定义该函数，使得父进程可以专心处理自己的工作不必关心子进程，而在子进程终止时会通知父进程，父进程在信号处理函数中调用wait清理子进程即可。 12345678910111213141516171819202122232425262728293031#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;signal.h&gt;#include&lt;stdlib.h&gt;void sigcb()&#123; //使用非阻塞的循环来处理SIGCHLD信号 //因为SIGCHLD信号是不可靠信号，有可能会丢失 //一旦接受到信号就处理到不能处理为止 //!=0代表一直有子程序在退出，所以一直循环，&gt;0返回子进程PID (!=0可能&lt;0，没有子进程） while(waitpid(-1,NULL,WNOHANG) != 0);//多个子进程可能会同时退出，如果同时退出了那么有些信号就会丢失，使得少处理一个信号 printf(&quot;Have a child exit!\n&quot;);&#125;int main()&#123; signal(SIGCHLD,sigcb); int pid = fork(); if(pid == 0) &#123; exit(0); &#125; //waitpid(-1,NULL,0); //避免产生僵尸子进程，但是使得父进程中后续的操作不能正常继续 while(1) &#123; printf(&quot;--------\n&quot;); sleep(1;) &#125; return 0;&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[可重入函数]]></title>
    <url>%2F2018%2F11%2F10%2F%E5%8F%AF%E9%87%8D%E5%85%A5%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[不可重入函数：如果函数在不同的地方/时序进行调用，会对函数的功能逻辑造成影响 可重入函数：不管怎么调用都不会对函数内部功能/程序逻辑造成影响（局部变量） 下面具体演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** 这是一个演示signal接口修改信号处理方式的demo* 信号的处理方式有三种：* 忽略* 默认* 自定义*/ #include&lt;stdio.h&gt; #include&lt;unistd.h&gt; #include&lt;signal.h&gt; void sigcb(int signo) &#123; static int a= 1;//静态变量，再次进入可能会产生不是预期的结果 static int b = 1; int c = 0; a++; sleep(10); b++; c= a + b; printf(&quot;receive signo:%d---%d\n&quot;,signo,c);/* if(signo == SIGINT ) //因为可能有很多信号来调用这个函数，所以需要做出判断 &#123; &#125; else &#123; &#125; */ return; &#125; int main() &#123; // sighandler_t signal(int signum, sighandler_t handler); //signum:信号的编号 //handler：处理方式 // SIG_IGN 忽略 // SIG_DFL 默认 int i = 0; //signal(SIGINT,SIG_IGN); //提前备注，当这个信号到来时忽略它 signal(SIGINT,sigcb); //自定义方式处理 while(1) &#123; /*printf(&quot;--------------\n&quot;); kill(getpid(),SIGINT); if(++i == 3) &#123; signal(SIGINT,SIG_DFL); &#125;*/ sigcb(SIGQUIT); &#125; return 0; &#125; 运行程序时输入Ctrl+C，发现出现下边的情况： 这是为什么呢？图解如下： 不可重入函数的要点（什么函数是不可重入函数）： 1.函数内部包含有对全局性变量的修改操作 2.函数传参的参数跟其他地方共同使用同一个变量 因为这些对全局变量的操作不是原子性的，因此这些修改操作有可能同时在不同地方进行修改 一个函数是否可重入： 1.是否对全局性的数据进行修改操作（malloc是用全局链表来管理堆的） 2.这个操作是否是原子性的]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程信号之自定义处理]]></title>
    <url>%2F2018%2F11%2F10%2F%E8%BF%9B%E7%A8%8B%E4%BF%A1%E5%8F%B7%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[信号的捕捉流程：主要是针对信号的自定义处理方式 信号并不是立即处理的，而是选择一个合适的时机去处理，合适的时机就是当前程序从内核态切换到用户态的时候 注意：程序如何从用户态切换到内核态? 答：1.程序异常的时候 2.发起系统调用的时候 3.中断的时候 信号的捕捉是当我们发起系统调用/程序异常/中断当前程序从内核态运行切换到用户态，去处理这些事情，处理完毕之后，要从内核态返回用户态，但是在返回之前会看一下是否有信号需要被处理，如果有就处理信号（切换到用户态执行信号的自定义处理方式），处理完毕之后再次返回内核态，判断没有信号要处理了就调用sys_sigreturn返回用户态（我们程序之前运行的位置）（就像我们课堂上布置的作业不会立即写） 注意：在使用这个接口时可能会因为该函数是库函数，而在Linux下的系统版本下会有细微差异 多是使用此函数所调用的系统调用接口sigaction 123456789int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);signum:指定给哪个信号去自定义处理方式act：新的处理方式oldact：保存新自定义之前的原本的操作 12345678910111213141516171819struct sigaction &#123;//都是信号的回调函数（取决于flags），任意指定其一 void (*sa_handler)(int); void (*sa_sigaction)(int, siginfo_t *, void *);//传递信号并同时携带参数//当处理时不希望被别的信号所影响，所以使用sa_mask来指定需要暂时阻塞的信号 sigset_t sa_mask;//当flags被指定为SA_SIGINFO这个参数时回调的是sa_sigaction，否则都是调用handler int sa_flags; void (*sa_restorer)(void); &#125;; 下边是一个sigaction的使用demo： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143 1 /* 2 * 因为signal这个接口有linux版本的差异性，因此可以使用sigaction这个接口来替代signal函数， 3 * 它的功能也是自定义信号的处理方式，并且signal函数内部也是通过sigaction来实现的 4 * 5 * 6 */ 7 8 /* struct sigaction &#123; 9 void (*sa_handler)(int);//处理函数 10 void (*sa_sigaction)(int, siginfo_t *, void *);//处理函数（当flags被指定为SA_SIGINFO这个参数时回调） 11 sigset_t sa_mask;//在处理信号时通过这个mask暂时阻塞一些信号，处理完之后还原 12 int sa_flags;//决定使用哪个处理接口 13 void (*sa_restorer)(void); 14 &#125;;*/ 15 16 17 #include&lt;stdio.h&gt; 18 #include&lt;unistd.h&gt; 19 #include&lt;signal.h&gt; 20 21 void sigcb(int signo) 22 &#123; 23 printf(&quot;rec signal:%d\n&quot;,signo); 24 &#125; 25 26 void sigcb1(int signo,siginfo_t* info,void* context)//context为预留的，不是传的参数，暂时不管它 27 &#123; 28 printf(&quot;rec signo:%d---param:%d\n&quot;,signo,info-&gt;si_int); 29 &#125; 30 31 32 int main() 33 &#123;34 struct sigaction new_act; 35 struct sigaction old_act; 36 //重新定义处理方式的信号为SIGINT SINQUIT 37 //int sigaction(int signum, const struct sigaction *act, 38 // struct sigaction *oldact); 39 //signum:信号编号 40 //act:新的处理方式 41 //oldact:保存原有的处理方式 42 43 //这个操作时一般性的更改一个信号的处理方式，sa_flags =0代表使用的回调接口为sa_handler 44 sigemptyset(&amp;new_act.sa_mask); 45 new_act.sa_flags = 0; 46 new_act.sa_handler = sigcb; 47 sigaction(SIGINT,&amp;new_act,&amp;old_act); 48 49 //这个操作是用于传递信号同时携带参数的情况，sa_flags需要被指定为sa_SIGINFO,并且调用的接口是sa_sigaction 50 sigemptyset(&amp;new_act.sa_mask); 51 new_act.sa_flags = SA_SIGINFO; 52 new_act.sa_sigaction = sigcb1; 53 sigaction(SIGQUIT,&amp;new_act,&amp;old_act); 54 while(1) 55 &#123; 56 sleep(1); 57 kill(getpid(),SIGINT); 58 //int sigqueue(pid_t pid, int sig, const union sigval value); //这个函数不仅可以发送信号，还可以 //顺便携带一 个信号 59 // pid:进程ID 60 // sig:信号编号 61 // sigval:参数 62 /* union sigval &#123; 63 int sival_int; 64 void *sival_ptr; 65 &#125;;*/ 66 union sigval val; 67 val.sival_int = 999; 68 sigqueue(getpid(),SIGQUIT,val);//传参函数 69 &#125; 70 return 0; 71 &#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件权限]]></title>
    <url>%2F2018%2F11%2F08%2FLinux%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[​ 在Linux系统下，一切皆文件，而对于一个文件必定需要权限去对其进行访问和操作，那么对于用户来说，可以通过哪些权限来访问文件呢？ ​ 首先，我们需要对Linux系统下文件访问权限有一定的了解：​ 文件权限值的表示方法： ​ 1.字符表示法： ​ 2.8进制数值表示法 那么如何设置且更改文件的访问权限呢？ ​ 使用chmod命令：格式为chmod[参数]权限 文件名 1.用户标识符+-=权限字符 ​ +：向权限范围增加权限代号所表示的权限 ​ -： 向权限范围取消权限代号所表示的权限 ​ =: 向权限范围赋予权限代号所表示的权限 ​ 用户符号： ​ u：拥有着 ​ g：拥有者同组用 ​ o：其他用户 ​ a：所有用户 chmod u+w /home/abc/txt chmod o-x /home/abc/txt chmod a=x /home/abc/txt 2.三位8进制数字 chmod 664 /home/abc/txt chmod 640 /home/abc/txt 下面进行具体的操作： 1.创建一个目录，并将其权限改为000 ​ 2.此时进入目录发现权限不够 3.给该目录所有者加上读权限，并尝试进入目录，发现权限不够 4.将该目录所有者的读权限取掉，加上写权限，进入目录，发现权限不够 5.将该目录所有者的写权限取掉，加上执行权限，进入目录，可以进入 由此可得： 1.读（r/4）：Read对文件而言，具有读取文件内容的权限 ​ 对于目录来说，具有浏览该目录信息的权限 2.写（w/2）：Write对文件而言，具有修改文件内容的权限 ​ 对于目录来货，具有删除移动目录内文件的权限 3.执行（x/1）：Execute对文件而言，具有执行文件的权限 ​ 对于文件而言，具有执行文件的权限 ​ 对于目录来说，具有进入**目录**的权限]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程信号之信号周期]]></title>
    <url>%2F2018%2F11%2F08%2F%E8%BF%9B%E7%A8%8B%E4%BF%A1%E5%8F%B7%E4%B9%8B%E4%BF%A1%E5%8F%B7%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[信号是为了通知进程发生了某个事件，因为事件比较紧急，因此会打断当前进程正在执行的工作，然后去处理事件，事件处理完毕之后进程回到原先运行位置继续运行信号更多的是通知事件发生，如红绿灯 在LInux下，用户输入命令在Shell下启动一个前台进程，而当按下ctrl+C时，产生一个硬中断，如果说CPU当前正在执行这个进程的代码，则该进程的用户空间代码暂停执行，CPU从用户态切换到内核态处理硬件中断（终端驱动程序将 ctrl+c 解释成一个SIGINT信号，记在其进程的PCB中(也可以说是发送了一个SIGINT信号给该进程)),而当要从内核返回到进程的用户空间代码继续执行之前，首先处理PCB中记录的信号，此时会发现有一个SIGINT信号待处理，而这个信号的默认处理动作是终止进程，所以直接终止进程而不再返回它的用户空间代码执行 信号产生之后第一时间也不是直接处理而是先存储下来，处理信号 信号的生命周期：信号的产生 =》信号的注册 =》信号的注销 =》(信号的阻塞（只是不处理）) =》信号的处理 信号处理常见方式：1.忽略此信号2.执行该信号的默认处理动作3.提供一个对信号处理的函数，要求内核在处理该信号时切换到用户状态执行这个函数（捕捉信号） 信号分了两类：1.非实时信号（不可靠信号）1~31 实时信号 (可靠信号) 34~64 信号的产生：1.通过硬件中断产生 （ctrl+c）2.程序异常产生 SIGFPE SIGSEGV3.软件条件(代码)产生软件条件产生：1.直接使用kill命令：kill并不是真的杀死进程，而是向一个进程发送一个信号（SIGTERM）kill -15 PID kill -15 PID2.kill接口int kill(pid_t pid, int sig); 向指定的进程发送指定的信号int raise(int sig); 发送一个信号给自身void abort(void); 使当前进程接受到信号而异常终止(像exit一样总会成功，所以没有返回值) unsigned int alarm(unsigned int seconds);在second秒之后，给进程发送一个STGALRM信号，在函数中可以多次调用如：设置一个定时器，取消上一个定时器，并且返回上一个定时器剩余时间 信号的注册：信号的注册（给一个进程发送信号），就是修改这个进程pcb中关于信号的pending位图，将相应的信号位置1 信号的阻塞：暂时不处理信号，并不是不接收信号，实际是暂时阻止信号的递达原理：要阻塞一个信号，那么就是修改pcb中关于信号的block位图，将相应的信号位置1，这个位图就像是 一个备注说明如果接收到这个信号暂时不处理注意：1.实际执行信号的处理动作称之为信号递达（动作）2.信号从产生到递达之间的状态，称之为信号未决（状态）3.进程可以选择阻塞某个信号4.被阻塞的信号产生时将保持在未决状态，知道进程解除对该信号的阻塞才执行递达动作5.阻塞和忽略时不同的，阻塞就不会递达，而忽略则是在递达之后可选的一种处理的动作 sigprocmask：int sigprocmask(int how, const sigset_t set, sigset_t oldset);调用sigprcmask（）接口，要么阻塞函数，要么对信号进行解除阻塞set：要阻塞或解除阻塞的集合oldset：保存原先阻塞集合中的信号如果oset非空，则读取进程当前的信号屏蔽字通过oset传出；若set非空，则根据how参数指示更改进程的信号屏蔽字；（解除阻塞或者设置阻塞）若oset和set均非空，则将原来的信号屏蔽字备份到oset中，然后根据how参数更改信号屏蔽字how参数：SIGBLOCKSIG_UNBLOCKSIG_SETMASKint sigemptyset(sigset_t set); int sigfillset(sigset_t set); int sigaddset(sigset_t set, int signum); int sigdelset(sigset_t set, int signum)； int sigismember(const sigset_t *set, int signum);123456789101112131415161718192021222324252627282930313233343536373839404142/* 这是一个演示信号阻塞的demo 2 */ 3 4 #include&lt;stdio.h&gt; 5 #include&lt;unistd.h&gt; 6 #include&lt;signal.h&gt; 7 8 int main() 9 &#123;10 //我要阻塞这个集合中的信号11 sigset_t new_block;12 //用于保存原来阻塞集合中的信号,防止后续要将阻塞集合还原回去13 sigset_t old_block;14 15 //int sigemptyset(sigset_t *set);16 //清空一个信号集合17 sigemptyset(&amp;new_block);18 //int sigfillset(sigset_t *set);19 //将所有的信号添加到set集合中20 // int sigaddset(sigset_t *set, int signum);21 //添加指定的单个信号到set集合中22 //int sigdelset(sigset_t *set, int signum);23 //从集合中移除一个信号24 //int sigismember(const sigset_t *set, int signum);25 //判断一个信号是否在一个集合中 26 sigfillset(&amp;new_block);27 //int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);28 //阻塞信号或解除阻塞29 //SIGBLOCK 阻塞集合中的信号30 //SIG_UNBLOCK 对集合中的信号解除阻塞31 //SIG_SETMASK 将集合中的信号设置到阻塞集合中32 //set：要阻塞或解除阻塞的集合33 //oldset：保存原先阻塞集合中的信号34 sigprocmask(SIG_BLOCK,&amp;new_block,&amp;old_block);35 //不按回车不往下走36 getchar();37 //解除阻塞38 sigprocmask(SIG_UNBLOCK,&amp;new_block,NULL);39 //将原先阻塞集合中的信号还原回去40 //sigprocmask(SIG_BLOCK,&amp;old_block,NULL);41 return 0;42 &#125; 有两个信号是不会被阻塞的：1.SIGKILL 2. SIGSTOPsigpending：获取一个未决信号int sigpending(sigset_t *set);（如果调用了sigpending接口，并且传入了一个集合地址，那么就会将pending集合中所有数据返回回来，相当于有哪些信号没有被处理则会返回回来） 信号注销：就是从pending集合中将即将要处理的信号置0（从pcb的pending集合中移除）非可靠信号注册就是将相应pending位图置1，然后添加一个sigqueue链表结构到链表中（一意味着这个信号来过），之后如果有相同信号到来，一看位图已经置1了，就不做操作了（意味着后来的信号在前一个信号未处理之前不会重复注册，代表丢了）可靠信号注册不管之前有没有注册都要置1 ，并且添加节点到链表中，所以不会丢掉信号 非可靠注销就是删除链表结点，相应位图置0可靠信号注销就是删除节点，判断是否有相同信号节点，如果没有位图置0，如果有就不置0，位图该位置还为1，下次会还处理这个信号struct sigqueue； 信号处理：1.忽略此信号——-直接将信号丢掉2.执行该信号的默认处理动作——-按照操作系统中对信号事件的既定处理方式3.自定义———-用户自己提供一个对信号处理的函数，要求内核在处理该信号时切换到用户状态执行这个函数（捕捉信号）哪些接口可以供我们改变处理方式：1.signal #include &lt;signal.h&gt; typedef void (sighandler_t)(int); //函数指针的类型定义 sighandler_t signal(int signum, sighandler_t handler); signum:信号的ID，指定要改变的信号 sighandler_t handler：*信号的处理方式SIG_IGN（忽略信号） SIG_DFL（默认处理方式） or 自定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* 2 * 这是一个演示signal接口修改信号处理方式的demo 3 * 信号的处理方式有三种： 4 * 忽略 5 * 默认 6 * 自定义 7 */ 8 9 #include&lt;stdio.h&gt; 10 #include&lt;unistd.h&gt; 11 #include&lt;signal.h&gt; 12 13 14 void sigcb(int signo) 15 &#123; 16 printf(&quot;receive signo:%d\n&quot;,signo); 17 /* if(signo == SIGINT ) //因为可能有很多信号来调用这个函数，所以需要做出判断 18 &#123; 19 &#125; 20 else 21 &#123; 22 &#125; 23 */ 24 return; 25 &#125; 26 27 28 int main() 29 &#123; 30 // sighandler_t signal(int signum, sighandler_t handler); 31 //signum:信号的编号 32 //handler：处理方式 33 // SIG_IGN 忽略 34 // SIG_DFL 默认 35 int i = 0; 36 //signal(SIGINT,SIG_IGN); //提前备注，当这个信号到来时忽略它 37 signal(SIGINT,sigcb); //自定义方式处理 38 while(1) 39 &#123; 40 printf(&quot;--------------\n&quot;); 41 kill(getpid(),SIGINT); 42 if(++i == 3) 43 &#123; 44 signal(SIGINT,SIG_DFL); 45 &#125; 46 &#125; 47 return 0; 48 &#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Core Dump浅解析]]></title>
    <url>%2F2018%2F11%2F08%2FCore-Dump%E6%B5%85%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Core Dump（核心转储）：当一个进程要异常终止时，可以选择把进程的用户空间内存数据全部保存到磁盘上，文件名通常是core，叫做Core Dump(保存当前程序运行的数据以及调用栈信息)，可以用于错误原因定位调试 为什么不用gdb呢？答：如果程序运行错误，可以直接通过core文件来gdb调试（有些错误可能是偶然发生的，可能在gdb调试时并不会显露出来，只有在core dump记录之后才能快速定位进行调试） CoreDump默认关闭：确保隐私安全/资源占用，1.记录的信息里面可能有隐秘性信息（如用户名和密码）2.Core Dump 文件很大且不会自动清理CoreDump打开：ulimit -c （int）当这个值为0 时则关闭（一个进程产生多大的core文件取决于进程的Resource Limit(这个信息保存在PCB中),使用ulimit命令改变这个限制）ulimit命令实际是改变Shell进程的Resourse Limit 1.首先将Core Dump打开 2.运行死循环程序 3.新建窗口，查看PID，并kill该程序 4.重新回到程序运行界面，发现已经Core Dumped，而ls产生了一个CoreDump文件 5.使用Core Dump文件查看错误（core-file ./test.992） 此时查看调用栈信息可以看到：__kernel_vsyscall ()，即为因死循环终止]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new与delete的使用]]></title>
    <url>%2F2018%2F11%2F07%2Fnew%E4%B8%8Edelete%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[new运算符是给指针分配一片内存空间，与delete运算符一起使用，以达到直接进行动态内存分配和释放的目的new返回指定类型的一个指针，如果分配失败（如没有足够的内存空间），则返回012double *p；p = new double； 此时系统会根据double类型的空间大小来开辟一个内存空间，并将地址放在指针p中delete是释放new请求到的空间的 注意：1.delete必须来释放之前new分配的指针2.用new可以指定分配的内存大小1234int *p;p = new int(30); //为指针p开辟30个字节单元的内存单元...delete p; 3.new可以为数组分配内存，当释放时必须告诉delete数组中有多少元素1234int *p;p = new int[10];...delete [10] p ; 例：123456void Test()&#123;char* p;strcpy(p,&quot;china&quot;);cout &lt;&lt; p &lt;&lt; endl;&#125; 此时只是给变量p分配了一个地址空间，并没有给p所指向的分配空间，所以程序出错应改为：1234567void Test()&#123;char *p;p = new char(10);strcpy(p,&quot;china&quot;);cout &lt;&lt; p &lt;&lt; endl;&#125; 注意：对于用new运算符创建的对象，必须使用delete才能调用析构函数问题：看以下代码：12A *pa = new A[10];delete pa; 则类A的构造函数和析构函数分别执行了几次（）答：构造函数执行了10次，析构函数构造了1次]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类中默认成员函数浅析（二）]]></title>
    <url>%2F2018%2F11%2F05%2F%E7%B1%BB%E4%B8%AD%E9%BB%98%E8%AE%A4%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%B5%85%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[运算符重载： operator + 合法的运算符 构成函数名（举例：重载&lt;运算符的函数名：operator&lt; ）。 重载运算符以后，不能改变运算符的 优先级/结合性/操作数个数。3.若成员变量为共有的，则可以重载为全局函数；若为私有的，重载为成员函数编译器对于==运算符的重载进行的操作： 5个C++不能重载的运算符是哪些？1..* 2. :: 3.sizeof 4.?: 5..注意：1.不能通过连接其他符号来创建新的操作符：如operator@2.重载操作符必须有一个类类型或者枚举类型的操作数3.用于内置类型的操作符，其含义不能改变，如不能将+重载为-4.作为类成员的重载函数，其形参看起来比操作数少1，因为操作符一个默认的形参this，限定为第一个形参 赋值运算符的重载：1.赋值运算符的重载是对一个已存在的对象进行拷贝赋值 。2.当程序没有显式地提供一个以本类或本类的引用为参数的赋值运算符重载函数时，编译器会自动生成这样一个赋 值运算符重载函数思考：为什么operator=赋值函数需要一个 Date&amp;的返回值， 使用void做返回值可以吗？//void Date&amp; operator=(const Date&amp; d) //引用效率较高,优先考虑引用 { _year = d._year; _month = d._month; _day = d._day; return this; }d1 = d2 = d3;需要注意：1.类型参数 2.返回值 3.检测是否自己给自己赋值 4.返回this 类的const成员函数：const修饰普通变量在C++中，const修饰的变量已经为一个常量，具有宏的属性，即在编译期间，编译器会将const所修饰的常量进行替换。const修饰类成员 const修饰类成员变量时，该成员变量必须在构造函数的初始化列表中初始化 const修饰类成员函数，实际修饰该成员函数隐含的this指针，该成员函数中不能对类的任何成员进行修改（ const Test* const）注意：在const成员函数中不能修改类的“成员变量”，因为const在此处修饰的是this指针指向空间中的内容，若需要对类的某个成员变量进行修改，该成员变量只需被mutable关键字修饰即可 思考：首先明确一点：非const函数实际是可读可写当前对象的函数，如SetData()，而const函数只能读取当前对象的内容,如GetData() const对象可以调用非const成员函数和const成员函数吗？答：不能调用普通非const类型成员函数，可以调用const类型成员函数(只读不可写) 非const对象可以调用非const成员函数和const成员函数吗？答： 可以，非const对象本身就具有可读属性，完全可以使用const函数 const成员函数内可以调用其它的const成员函数和非const成员函数吗？答：不能调用非const函数，可以调用const类型成员函数 非const成员函数内可以调用其它的const成员函数和非const成员函数吗？答：可以 类的取地址操作符重载 &amp; const修饰的取地址操作符重载 ：这两个默认成员函数一般不用重新定义 ，编译器默认会生成。当想让别人获取到你指定的内容才会需要你自己重载这两个操作符Test operator&amp;(){cout &lt;&lt; this &lt;&lt; endl;return this;} const Date operator&amp;() const{ return this ; }Test operator&amp;(); 和 const Test opertor&amp;();形成重载原因是：默认隐藏参数this指针类型不同，第一个是Test const，第二个是const Test const]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[for循环的基础练习]]></title>
    <url>%2F2018%2F11%2F01%2Ffor%E5%BE%AA%E7%8E%AF%E7%9A%84%E5%9F%BA%E7%A1%80%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[无论是对于编程菜鸟或者是大牛来说，for循环是一个不可或缺的C语言语句，在这里其定义如何且按下不表，只是单纯的放几个for循环的适用场景来感受一下。for(表达式1；表达式2；表达式3)，请对应于下图来认真体会一下好的，多说无益，还是上上手来实际操作一下第一题：打印100~200 之间的素数在做这道题的时候，个人建议自己先想清楚什么是素数，如何判断一个数是不是素数，切忌没有想清楚就直接上手，建议在实操之前先写一下伪代码以下提供三种方式来处理这个问题：1.有多少个数就判断多少次，这种方法简单明了，一眼即懂，但是大大增加了代码的循环次数123456789101112131415void IsPrime1()&#123; int i = 100; for(i=101;i&lt;200;i++) &#123; int j = 2; for(j=2;j&lt;i;j++) &#123; if(i%j == 0) break; &#125; if(j &gt;= i) printf(&quot;%d &quot;,i); &#125;&#125; 2.这一种较第一种减少了大概一般的循环次数，提高了代码效率123456789101112131415void IsPrime2()&#123; int i = 100; for(i=101;i&lt;200;i++) &#123; int j = 2; for(j=2;j&lt;200/2;j++) &#123; if(i%j == 0) break; &#125; if(j &gt;= (i/2)) printf(&quot;%d &quot;,i); &#125;&#125; 3.此时的循环次数由n级数骤降到了sqrt(n)级上,但是针对这一种算法，一定要拎清楚输出的条件123456789101112131415void IsPrime3()&#123; int i = 100; for(i=101;i&lt;200;i+=2) &#123; int j = 2; for(j=2;j&lt;sqrt(1.0*i);j++) &#123; if(i%j == 0) break; &#125; if(j &gt;= sqrt(1.0*i)) printf(&quot;%d &quot;,i); &#125;&#125; sqrt()是C语言函数库中封装好的函数，其在库中对参数分别为double,float,long double，有着三种不同的重载方式，此段代码中sqrt()中参数为1.0*i即是为了满足参数，方能调用该函数，切记要加头文件&lt;math.h&gt;二.输出乘法口诀表因为要输出成如图界面，一定要注意循环终止条件1234567891011121314void mul()&#123; int i = 0; for(i=1;i&lt;=9;i++) &#123; int j = 0; for(j=1;j&lt;=i;j++) &#123; int k = i*j; printf( &quot;%d*%d = %2d &quot;,j,i,k); &#125; printf(&quot;\n&quot;); &#125;&#125; 三. 判断1000年—2000年之间的闰年1234567891011void IsLeapYear()&#123; int year; for (year = 1000; year &lt;= 2000; year++) &#123; if (year % 400 == 0 || year % 4 == 0 &amp;&amp; year % 100 != 0 ) &#123; printf(&quot;%d &quot;, year); &#125; &#125;&#125;]]></content>
      <tags>
        <tag>C初阶基本练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类中默认成员函数浅析（一）]]></title>
    <url>%2F2018%2F10%2F30%2F%E7%B1%BB%E4%B8%AD%E9%BB%98%E8%AE%A4%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%B5%85%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[构造函数：是一个特殊的成员函数（随着对象创建而自动被调用的），用于来初始化对象，在对象的生命周期中只调用一次特征：1.名字与类名相同2.无返回值（并不等同于void）3.可以重载（类可以有多个构造函数，其名字都必须相同但参数列表可以不同）4.类对象创建时自动执行！！！5.构造函数可以在类中定义，也可以在类外定义（在类中定义的成员函数，编译器可能会将其当成内联函数来处理）class Date(){public：/Date() //无参数，形成重载{_year = 1997;_month = 01;_day = 01;}/Date(int year,int month,int day) //无返回值类型，并不是void{_year = year;_month = month;_day = day;}private:int _year;int _month;int _day;} 注意：1.若一个类没有定义构造函数，则会自动生成一个不带参数的默认构造函数Date(){}; 此时创建Date d对象会报错，如何解决？答：将Date(int year,int month,int day)给上缺省值，即Date(int year = 1997,int month = 01,int day = 01)，使得对象若没有参数则直接使用缺省值（无参的和带有全缺省的构造函数只能存在一个，即Date（）{}；和Date(int year = 1997,int month = 01,int day = 01只能存在一个) 析构函数：与构造函数功能相反（~），在对象被销毁时编译器自动调用，析构函数体做一些对象删除前的相关资源清理工作（不是删除对象）特征： 析构函数名是在类名前加上字符 ~。 无参数无返回值。 一个类有且只有一个析构函数。若未显式定义，系统会自动生成默认的析构函数注意：对于用new运算符动态创建的对象，只有用delete释放对象时才调用析构函数 拷贝构造函数：用已经存在的对象创建新的对象只有单个形参，该形参是对本类类型对象的引用（因为是拷贝，不需要更改原对象的任何参数，为了安全起见一般常用const修饰）特征： 拷贝构造函数其实是一个构造函数的重载。 拷贝构造函数的参数只有一个且必须使用引用传参（使用传值方式会引发无穷递归调用） 若未显示定义，系统会默认生成默认的拷贝构造函数。 默认的拷贝构造函数会按照成员的声明顺序依次拷贝类成员进行初始化（默认方式下是原封不动完全拷贝，包括地址）Date(const Date&amp; d){_year = d._year;_month = d._month;_day = d._day;}哪些类的拷贝构造函数用户一定要提供？对象中有资源（动态的顺序表，若拷贝s1到s2时，因为要进行free，先free的是s2，在free之后s2指向空间已经被销毁而s1并不知道，所以在s1 free的时候出错）]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
